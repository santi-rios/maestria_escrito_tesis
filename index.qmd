---
title: "Caracterización de los efectos de la Fluoxetina sobre el aprendizaje espacial y la flexibilidad cognitiva en un modelo de estrés crónico en ratón"
# subtitle: ""
# description: ""
# abstract: |
#     El estrés crónico tiene efectos profundos sobre distintos aspectos de la cognición, incluyendo la flexibilidad cognitiva dependiente del hipocampo (Tafet y Nemeroff, 2016). Estos impactos cognitivos pueden ser estudiados en modelos de roedores utilizando el Laberinto Acuático de Morris (MWM) (Hernández-Mercado y Zepeda, 2022).  Sin embargo, estos estudios han dependido predominantemente del análisis de métricas y métodos estadísticos que no necesariamente modelan la relación entre el estrés crónico y la flexibilidad cognitiva dependiente del hipocampo. Aunque estos métodos han aportado valiosas perspectivas, sus limitaciones para manejar conjuntos de datos biológicos complejos son cada vez más reconocidos. Esta problemática se observa en la creciente literatura que no ha logrado encontrar una relación clara entre el estrés crónico, mecanismos cognitivos afectados a nivel de hipocampo y el efecto antidepresivo de fármacos como fluoxetina (David et al., 2009). Este estudio explora las ventajas de utilizar técnicas de análisis que modelen mejor la relación para el estudio de la flexibilidad cognitiva. A través de un análisis comparativo que involucra a ratones sometidos a estrés crónico y tratamiento farmacológico con fluoxetina, demostramos cómo estos enfoques pueden proporcionar interpretaciones más matizadas de los datos, acomodando la variabilidad individual y la estructura jerárquica de los diseños experimentales comúnmente utilizados en esta área. Nuestros hallazgos revelan que estos enfoques no solo ofrecen una mayor flexibilidad y precisión predictiva, sino que también mejoran la comprensión de los efectos cognitivos del estrés y la eficacia de posibles intervenciones. Al integrar metodologías estadísticas avanzadas con protocolos experimentales rigurosos, esta investigación contribuye al perfeccionamiento de los modelos de neurociencia cognitiva y apoya el desarrollo de estrategias terapéuticas dirigidas para las alteraciones cognitivas relacionadas con el estrés.
# keywords: |
#     Morris Water Maze, Cognitive Flexibility, Mixed Models.
title-block-banner: true
author:
  - name: Garcia Rios Santiago
    email: santiago_gr@ciencias.unam.mx
    affiliations:
      - name: Facultad de Ciencias
        url: https://www.fciencias.unam.mx/
format: 
  html:
    lang: es  # figure, note, warning, code
    embed-resources: true # self-contained file
    # code-fold: true # retraer código
    # code-summary: "Mostrar código"
    theme: "journal" # cyborg, quartz, slate, solar, superhero, vapor,sandstone,lux,flaty,cosmo, journal, materia, minty,morph,pulse
    page-layout: full
    anchor-sections: true
    code-link: true
    # smooth-scroll: true
  docx:
    toc: true
    number-sections: true
    highlight-style: github
    lang: es 
    execute:
      echo: false
date: "today"
editor: source
  # markdown: 
  #   wrap: 72
# markdown:
#     wrap: sentence
# editor_options: 
#   chunk_output_type: console
# fig-cap-location: top
tbl-cap-location: bottom
crossref:
  fig-title: '**Figura**'
  fig-labels: arabic
  title-delim: "**.**"
  tbl-title: '**Tabla**'
  tbl-labels: arabic
execute:
  echo: true  
  warning: false
  cache: true
toc: true
# toc-title: Contents
number-sections: true
comments:
  hypothesis: true
lightbox: true
glossary:
  path:  glossary.yml
  popup: hover
  show: true
# bibliography: references.bib
bibliography: zotlib.bib
---

```{r librerias}
#| include: false

# Básicas 
library(tidyverse)

# plots
library(gridExtra)
library(grid)
library(plotly)
# library(viridis)
library(viridisLite)
library(patchwork)
library(hexbin)


# Bayes
library(brms)
library(modelbased)
library(see)
library(bayesplot)
library(bayestestR)


# Regresion
library(lme4)
library(emmeans)
library(modelr)
library(sjPlot)
library(gtsummary)
library(performance)
library(ggeffects)

# Tablas
library(flextable)
library(webshot)
library(report)

# Estadistica
library(rstatix)
library(ggpubr)

```

```{r datafrmaes}
#| include: false


df_wm <- read.csv("./datos/df_wm_clean.csv")

# recodificar a factores
df_wm$tratamientos <- as.factor(df_wm$tratamientos)
df_wm$id <- as.factor(df_wm$id)
df_wm$stage <- as.factor(df_wm$stage)
df_wm$prueba <- as.factor(df_wm$prueba)

# table(df_ent_post$tratamientos) ver tratamientos



df_wm_flx <- df_wm |> 
  dplyr::filter(tratamientos %in% c("Flx","Flx-CUMS", "Sal-CUMS-F"))

# table(df_wm_flx$tratamientos)

df_wm_otros <- df_wm |> 
  dplyr::filter(tratamientos %in% c("Ctrl","Ket-CUMS", "Sal-CUMS-K"))

# table(df_wm_otros$tratamientos)

df_wm_flx$tratamientos = factor(df_wm_flx$tratamientos, 
                            levels=c("Flx","Flx-CUMS", "Sal-CUMS-F"))

df_wm_otros$tratamientos = factor(df_wm_otros$tratamientos, 
                            levels=c("Ctrl", "Ket-CUMS", "Sal-CUMS-K"))
```

```{r datafrmaesLatencias}
#| include: false

latencias_pre <- df_wm_flx |> 
  select(latencia, id, tratamientos, stage, dia, tiempo, prueba) |> 
  dplyr::filter(str_detect(prueba, "Entr"))


latencias_post <- df_wm_flx |> 
  select(latencia, id, tratamientos, stage, dia, tiempo, prueba) |> 
  dplyr::filter(str_detect(prueba, "Reversa"))


latencias_pre$censurado = ifelse(latencias_pre$latencia== 60, 1, 0)
latencias_pre$Censurado = ifelse(latencias_pre$latencia==60, "SI", "NO")

latencias_post$censurado = ifelse(latencias_post$latencia== 60, 1, 0)
latencias_post$Censurado = ifelse(latencias_post$latencia==60, "SI", "NO")


```



```{r modeladosestadistica}
#| include: false

contrasts(latencias_pre$tratamientos) = contr.sum(3) # contrast encoding - represent categorical variable numerically
contrasts(latencias_post$tratamientos) = contr.sum(3) # contrast encoding - represent categorical variable numerically

latencias_pre$tiempo_centrado = latencias_pre$tiempo - mean(latencias_pre$tiempo) # centrar variable de día (0 = mean of variable) coefficients easier, convergence, reduce multicol
latencias_post$tiempo_centrado = latencias_post$tiempo - mean(latencias_post$tiempo) # centrar variable de día (0 = mean of variable) coefficients easier, convergence, reduce multicol

### PRIORS

priors = c(
  prior("student_t(3, 4.5, .25)", class = "Intercept"),
  prior("student_t(3, 0, .25)", class = "sd"),
  prior(
    "student_t(3, 0, .1)",
    class = "sd",
    coef = "tiempo_centrado",
    group = "id" ## o sera treatment?
  ),
  prior_string(
    "student_t(3, 0, 0.5)",
    class = "b",
    coef = paste("tratamientos", 1:2, sep = "")
  ),
  prior_string("student_t(3,-.2, .1)", class = "b", coef = "tiempo_centrado"),
  prior_string(
    "student_t(3, 0, 0.1)",
    class = "b",
    coef = paste("tiempo_centrado:tratamientos", 1:2, sep = "")
  )
)


### Bayes con distribución Gamma

b1.c <-
  brm(
    latencia |
      cens(censurado) ~ tiempo_centrado * tratamientos + (tiempo_centrado |
                                                      id),
    family = Gamma(link = "log"),
    data = latencias_post,
    init = "0",
    iter = 4000,
    prior = priors,
    save_pars = save_pars(all = TRUE),
    control = list(adapt_delta = 0.95)
  )

b1.c.pre <-
  brm(
    latencia |
      cens(censurado) ~ tiempo_centrado * tratamientos + (tiempo_centrado |
                                                      id),
    family = Gamma(link = "log"),
    data = latencias_pre,
    init = "0",
    iter = 4000,
    prior = priors,
    save_pars = save_pars(all = TRUE),
    control = list(adapt_delta = 0.95)
  )


### GLM

b1.ignore <-
  brm(
    latencia ~ tiempo_centrado * tratamientos + (tiempo_centrado |
                                              id),
    family = Gamma(link = "log"),
    data = latencias_post,
    init = "0",
    iter = 4000,
    prior = priors,
    save_pars = save_pars(all = TRUE),
    control = list(adapt_delta = 0.95)
  )

b1.ignore.pre <-
  brm(
    latencia ~ tiempo_centrado * tratamientos + (tiempo_centrado |
                                              id),
    family = Gamma(link = "log"),
    data = latencias_pre,
    init = "0",
    iter = 4000,
    prior = priors,
    save_pars = save_pars(all = TRUE),
    control = list(adapt_delta = 0.95)
  )


#### EFECTOS MIXTOS 

priors = c(
  prior("student_t(3, 90, 45)", class = "Intercept"),
  prior_string(
    "student_t(3, 0, 35)",
    class = "b",
    coef = paste("tratamientos", 1:2, sep = "")
  ),
  prior_string("student_t(3,-5, 5)", class = "b", coef = "tiempo_centrado"),
  prior_string(
    "student_t(3, 0, 5)",
    class = "b",
    coef = paste("tiempo_centrado:tratamientos", 1:2, sep = "")
  )
)

bn <- brm(
  latencia ~ tiempo_centrado * tratamientos + (tiempo_centrado | id),
  data = latencias_post,
  init = "0",
  iter = 4000,
  prior = c(set_prior("student_t(3,-25,25)", class = "b")),
  save_pars = save_pars(all = TRUE)
)


bn.pre <- brm(
  latencia ~ tiempo_centrado * tratamientos + (tiempo_centrado | id),
  data = latencias_pre,
  init = "0",
  iter = 4000,
  prior = c(set_prior("student_t(3,-25,25)", class = "b")),
  save_pars = save_pars(all = TRUE)
)


##### ANOVA

library(gt)

myData.mean.lat.pre <- aggregate(latencias_pre$latencia,
                                 by = list(latencias_pre$prueba, 
                                           latencias_pre$tratamientos,
                                           latencias_pre$id),
                                 FUN = 'mean')

myData.mean.lat.post <- aggregate(latencias_post$latencia,
                         by = list(latencias_post$prueba, 
                                   latencias_post$tratamientos,
                                   latencias_post$id),
                         FUN = 'mean')

colnames(myData.mean.lat.pre) <- c("prueba","tratamientos","id","latencia")

colnames(myData.mean.lat.post) <- c("prueba","tratamientos","id","latencia")

## Modelo 

aov_latencias_pre <- aov(latencia ~ tratamientos * prueba + Error(id), 
                          data = myData.mean.lat.pre)

aov_latencias_post <- aov(latencia ~ tratamientos * prueba + Error(id), 
                          data = myData.mean.lat.post)



```

```{r dataframesEstrategias}
#| echo: false

estrategias_df <- read.csv("./datos/rtrack/exportado_estrategias_final.csv") |> 
  # exportado_estrategias_final_thresholded.csv
  janitor::clean_names() |> 
  dplyr::select(x_target_id, x_day, x_trial, stage, tratamiento, name) |> 
  
  dplyr::mutate(estrategias = case_when(name %in% c("corrected path", "direct path", "directed search") ~ 1, # hipocampo_dependientes 
                                        name %in% c("chaining",  "random path", "scanning", "thigmotaxis") ~ 0, # hipocampo_independientes
                                        name %in% c("perseverance") ~ 3)
  ) |> 
  
  dplyr::mutate(estrategias_hipo = case_when(name %in% c("corrected path", "direct path", "directed search") ~ "hipocampo_dependientes",   
                                             name %in% c("chaining",  "random path", "scanning", "thigmotaxis") ~ "hipocampo_independientes", # 
                                             name %in% c("perseverance") ~ "perseverancia")
  )

## ---- porcentajes-summary
## counts how many times each strategy was used by each group on each day


estrategias_porcentajes_df_pre <- estrategias_df |> 
  dplyr::filter(str_detect(stage, "entrenamiento")) |>
  dplyr::filter(!str_detect(stage, "entrenamiento_rev")) |>
  dplyr::filter(!str_detect(tratamiento, "K")) |>
  dplyr::group_by(stage, tratamiento, estrategias_hipo) |>
  dplyr::summarise(cnt = n()) |> 
  dplyr::mutate(freq = round(cnt / sum(cnt), 3),
         # dia = case_when(stage == "entrenamiento_rev_1" ~ 1,
                         # stage == "entrenamiento_rev_2" ~ 2),
         porcentaje = freq * 100) |> 
  dplyr::ungroup()


estrategias_porcentajes_df <- estrategias_df |> 
  dplyr::filter(str_detect(stage, "entrenamiento_rev")) |>
  dplyr::filter(!str_detect(tratamiento, "K")) |>
  dplyr::group_by(stage, tratamiento, estrategias_hipo) |>
  dplyr::summarise(cnt = n()) |> 
  dplyr::mutate(freq = round(cnt / sum(cnt), 3),
                dia = case_when(stage == "entrenamiento_rev_1" ~ 1,
                                stage == "entrenamiento_rev_2" ~ 2),
                porcentaje = freq * 100) |> 
  dplyr::ungroup()



```

```{r bayeslatenciasplotspredict}
#| include: false
#| output: false


b1.c_effects_plot.pre <- plot(conditional_effects(b1.c.pre, effects = "tiempo_centrado:tratamientos", prob=.66))[[1]]

b1.ignore_effects_plot.pre <- plot(conditional_effects(b1.ignore.pre, effects = "tiempo_centrado:tratamientos", prob=.66))[[1]] 

bn_effects_plot.pre <- plot(conditional_effects(bn.pre, effects = "tiempo_centrado:tratamientos", prob=.66))[[1]] 

b1.c_effects_plot <- plot(conditional_effects(b1.c, effects = "tiempo_centrado:tratamientos", prob=.66))[[1]] 

b1.ignore_effects_plot <- plot(conditional_effects(b1.ignore, effects = "tiempo_centrado:tratamientos", prob=.66))[[1]]

bn_effects_plot <- plot(conditional_effects(bn, effects = "tiempo_centrado:tratamientos", prob=.66))[[1]]



```

```{r bayesSlopes}
#| eval: false
#| echo: false


table(latencias_post$tiempo_centrado)

emmeans(b1.c.pre, ~tratamientos, type="response", at=list(tiempo_centrado= -1.86950549450549))

emmeans(b1.c.pre, ~tratamientos, type="response", at=list(tiempo_centrado= 1.88049450549451))

emmeans(b1.c, ~tratamientos, type="response", at=list(tiempo_centrado= -0.875))

emmeans(b1.c, ~tratamientos, type="response", at=list(tiempo_centrado= 0.375))
  # as.tibble() |>
  # flextable()
#   
# slopes
emtrends(b1.c.pre, ~tratamientos, var="tiempo_centrado") 

emtrends(b1.c, ~tratamientos, var="tiempo_centrado") 
  # as.tibble() |>
  # flextable()


```

```{r posissoncheckmodel}
#| eval: false
#| include: false
performance::check_model(model, colors = c("#222831", "#00ADB5", "#FF2E63"))

# "all", "vif", "qq", "normality", "linearity", "ncv", "homogeneity", "outliers", "reqq", "pp_check", "binned_residuals" or "overdispersion"

# base_size, title_size, axis_title_size

# theme
# package::theme_name


```

```{r PoissonReport}
#| echo: false
#| eval: false

report::report(glme.poisson.pre)
report::report(glme.poisson.post)

```

```{r poissondataFrames}
#| echo: false

##### FLX Originales
estrategias.poisson.flx.pre <- estrategias_df |> 
  dplyr::filter(str_detect(stage, "entr")) |> 
  dplyr::filter(!str_detect(stage, "entrenamiento_rev")) |> 
  mutate(
    dia = case_when(stage == "entrenamiento_1" ~ 1,
                    stage == "entrenamiento_2" ~ 2,
                    stage == "entrenamiento_3" ~ 3,
                    stage == "entrenamiento_4" ~ 4),
    experimento = case_when(tratamiento %in% c("Flx", "Flx-CUMS","Sal-CUMS-F") ~ "Flx",
                            tratamiento %in% c("Ket-CUMS","Sal-CUMS-K") ~ "Ket")) |> 
  dplyr::filter(str_detect(experimento, "Flx")) |>
  dplyr::select(dia, tratamiento, estrategias_hipo, x_target_id)

estrategias.poisson.flx.pre$tratamiento <- as.factor(estrategias.poisson.flx.pre$tratamiento)

estrategias.poisson.flx.pre$estrategias_hipo <- as.factor(estrategias.poisson.flx.pre$estrategias_hipo)

estrategias.poisson.flx.pre$x_target_id <- as.factor(estrategias.poisson.flx.pre$x_target_id)

estrategias.poisson.flx.pre$count <- 1

estrategias.poisson.flx.pre.agrupado <- estrategias.poisson.flx.pre %>%
  dplyr::group_by(dia, tratamiento, estrategias_hipo, x_target_id) %>%
  dplyr::summarise(count = n(), .groups = 'drop')



#### FLX Reversa

estrategias.poisson.flx.post <- estrategias_df |> 
  dplyr::filter(str_detect(stage, "entrenamiento_rev")) |> 
  mutate(
    dia = case_when(stage == "entrenamiento_rev_1" ~ 1,
                    stage == "entrenamiento_rev_2" ~ 2,
                    stage == "entrenamiento_1" ~ 0,
                    stage == "entrenamiento_2" ~ 1,
                    stage == "entrenamiento_3" ~ 2,
                    stage == "entrenamiento_4" ~ 3
                    ),
    dia_completo = case_when(
      ### E-1 ###
      # stage =="entrenamiento_1" & trial == 1 ~ 0,
      # stage =="entrenamiento_1" & trial == 2 ~ 0.25,
      # stage =="entrenamiento_1" & trial == 3 ~ 0.5,
      # stage =="entrenamiento_1" & trial == 4 ~ 0.75,
      # ### E-2 ###
      # stage =="entrenamiento_2" & trial == 1 ~ 1,
      # stage =="entrenamiento_2" & trial == 2 ~ 1.25,
      # stage =="entrenamiento_2" & trial == 3 ~ 1.5,
      # stage =="entrenamiento_2" & trial == 4 ~ 1.75,
      # ### E-3 ###
      # stage =="entrenamiento_3" & trial == 1 ~ 2,
      # stage =="entrenamiento_3" & trial == 2 ~ 2.25,
      # stage =="entrenamiento_3" & trial == 3 ~ 2.5,
      # stage =="entrenamiento_3" & trial == 4 ~ 2.75,
      # ### E-4 ###
      # stage =="entrenamiento_4" & trial == 1 ~ 3,
      # stage =="entrenamiento_4" & trial == 2 ~ 3.25,
      # stage =="entrenamiento_4" & trial == 3 ~ 3.5,
      # stage =="entrenamiento_4" & trial == 4 ~ 3.75,
      ### E_R-1 ###
      stage =="entrenamiento_rev_1" & x_trial == 1 ~ 0,
      stage =="entrenamiento_rev_1" & x_trial == 2 ~ 0.25,
      stage =="entrenamiento_rev_1" & x_trial == 3 ~ 0.5,
      stage =="entrenamiento_rev_1" & x_trial == 4 ~ 0.75,
      ### E_R-2 ###
      stage =="entrenamiento_rev_2" & x_trial == 1 ~ 1,
      stage =="entrenamiento_rev_2" & x_trial == 2 ~ 1.25,
      stage =="entrenamiento_rev_2" & x_trial == 3 ~ 1.5,
      stage =="entrenamiento_rev_2" & x_trial == 4 ~ 1.75,
    ),
    experimento = case_when(tratamiento %in% c("Flx", "Flx-CUMS","Sal-CUMS-F") ~ "Flx",
                            tratamiento %in% c("Ket-CUMS","Sal-CUMS-K") ~ "Ket")) |>
  dplyr::filter(str_detect(experimento, "Flx")) |>
  dplyr::select(dia_completo, tratamiento, estrategias_hipo, x_target_id, dia)


estrategias.poisson.flx.post$tratamiento <- as.factor(estrategias.poisson.flx.post$tratamiento)

estrategias.poisson.flx.post$estrategias_hipo <- as.factor(estrategias.poisson.flx.post$estrategias_hipo)

estrategias.poisson.flx.post$x_target_id <- as.factor(estrategias.poisson.flx.post$x_target_id)

# Crear cuenta de columna para cada tipo de estrategia

estrategias.poisson.flx.post$count <- 1

# Agrupar datos y resumir cuentas (counts)
estrategias.poisson.flx.post.agrupado <- estrategias.poisson.flx.post %>%
  dplyr::group_by(dia, tratamiento, estrategias_hipo, x_target_id) %>%
  # dplyr::group_by(dia, tratamiento, estrategias_hipo) %>%
  dplyr::summarise(count = n(), .groups = 'drop')

estrategias.poisson.flx.post$count <- 1

estrategias.poisson.flx.post.agrupado.2 <- estrategias.poisson.flx.post %>%
  dplyr::group_by(dia, tratamiento, estrategias_hipo) %>%
  # dplyr::group_by(dia, tratamiento, estrategias_hipo) %>%
  dplyr::summarise(count = n(), .groups = 'drop')

```

```{r poissonModelado}
#| echo: false



glme.poisson.pre <- glmer(count ~ dia * tratamiento * estrategias_hipo +
                            (1 | x_target_id),
                          family = poisson(link = "log"), 
                          data = estrategias.poisson.flx.pre.agrupado)

glme.poisson.post <- glmer(count ~ dia * tratamiento * estrategias_hipo +
                           (1 | x_target_id),
                           family = poisson(link = "log"),
                           data = estrategias.poisson.flx.post.agrupado)

glm.poisson.post <- glm(count ~ dia * tratamiento * estrategias_hipo,
                           family = poisson(link = "log"),
                           data = estrategias.poisson.flx.post.agrupado.2)


```


```{r rtrack}
#| echo: false

load("./datos/rtrack/final_experiment.RData")

estrategias_rtrack <-  Rtrack::call_strategy(rtrack_experimento)


# ---- P1 
flx_p1_metrics =
  rtrack_experimento$metrics[rtrack_experimento$factors$Tratamiento == "Flx" &
                               (rtrack_experimento$factors$`_Day` == 5)]
# Flx-CUMS
flx_CUMS_p1_metrics =
  rtrack_experimento$metrics[rtrack_experimento$factors$Tratamiento == "Flx-CUMS" &
                               (rtrack_experimento$factors$`_Day` == 5)]
# Sal-CUMS-F
sal_cums_f_p1_metrics =
  rtrack_experimento$metrics[rtrack_experimento$factors$Tratamiento == "Sal-CUMS-F" &
                               (rtrack_experimento$factors$`_Day` == 5)]
# Ket-CUMS
ket_cums_p1_metrics =
  rtrack_experimento$metrics[rtrack_experimento$factors$Tratamiento == "Ket-CUMS" &
                               (rtrack_experimento$factors$`_Day` == 5)]
# Sal-CUMS-K
sal_cums_k_p1_metrics =
  rtrack_experimento$metrics[rtrack_experimento$factors$Tratamiento == "Sal-CUMS-K" &
                               (rtrack_experimento$factors$`_Day` == 5)]




# ---- P2 
flx_p2_metrics =
  rtrack_experimento$metrics[rtrack_experimento$factors$Tratamiento == "Flx" &
                               (rtrack_experimento$factors$`_Day` == 6)]
# Flx-CUMS
flx_CUMS_p2_metrics =
  rtrack_experimento$metrics[rtrack_experimento$factors$Tratamiento == "Flx-CUMS" &
                               (rtrack_experimento$factors$`_Day` == 6)]
# Sal-CUMS-F
sal_cums_f_p2_metrics =
  rtrack_experimento$metrics[rtrack_experimento$factors$Tratamiento == "Sal-CUMS-F" &
                               (rtrack_experimento$factors$`_Day` == 6)]
# Ket-CUMS
ket_cums_p2_metrics =
  rtrack_experimento$metrics[rtrack_experimento$factors$Tratamiento == "Ket-CUMS" &
                               (rtrack_experimento$factors$`_Day` == 6)]
# Sal-CUMS-K
sal_cums_k_p2_metrics =
  rtrack_experimento$metrics[rtrack_experimento$factors$Tratamiento == "Sal-CUMS-K" &
                               (rtrack_experimento$factors$`_Day` == 6)]


# ---- P-Rev 

flx_rev_metrics =
  rtrack_experimento$metrics[rtrack_experimento$factors$Tratamiento == "Flx" &
                               (rtrack_experimento$factors$`_Day` == 9)]
# Flx-CUMS
flx_CUMS_rev_metrics =
  rtrack_experimento$metrics[rtrack_experimento$factors$Tratamiento == "Flx-CUMS" &
                               (rtrack_experimento$factors$`_Day` == 9)]
# Sal-CUMS-F
sal_cums_f_rev_metrics =
  rtrack_experimento$metrics[rtrack_experimento$factors$Tratamiento == "Sal-CUMS-F" &
                               (rtrack_experimento$factors$`_Day` == 9)]
# Ket-CUMS
ket_cums_rev_metrics =
  rtrack_experimento$metrics[rtrack_experimento$factors$Tratamiento == "Ket-CUMS" &
                               (rtrack_experimento$factors$`_Day` == 9)]
# Sal-CUMS-K
sal_cums_k_rev_metrics =
  rtrack_experimento$metrics[rtrack_experimento$factors$Tratamiento == "Sal-CUMS-K" &
                               (rtrack_experimento$factors$`_Day` == 9)]


```


```{r dfDistMedPrueb}
#| echo: false

df.distancia.media.pruebas.flx <- 
  df_wm_flx |> 
  # df_wm_otros |> 
  dplyr::select(distancia_media_blanco, distancia_annulus_so, distancia_annulus_ne, tratamientos, id, prueba, dia) |> 
  # dplyr::filter(str_detect(prueba, "Ent")) |> 
  dplyr::filter(str_detect(prueba, "P")) 


df.meandist.media.pruebas <- aggregate(df.distancia.media.pruebas.flx$distancia_media_blanco,
                                       by = list(df.distancia.media.pruebas.flx$prueba, 
                                                 df.distancia.media.pruebas.flx$tratamientos,
                                                 df.distancia.media.pruebas.flx$id),
                                       FUN = 'mean')

colnames(df.meandist.media.pruebas) <- c("prueba","tratamientos","id","distancia_media_blanco")

```

```{r ModeladoDistanciaMedia}
#| echo: false


lmer.dist.media.pruebas <- lmer(
  distancia_media_blanco ~ prueba * tratamientos + (1 | id),
  data = df.distancia.media.pruebas.flx
)




# aov_latencias_post <- aov(latencia ~ tratamientos * stage + Error(id/stage), 
#                           data = aov_latencias_post.df)

aov.dist.media.pruebas <- aov(distancia_media_blanco ~ tratamientos * prueba + Error(id), 
             data = df.meandist.media.pruebas)


```

```{r dfEntropi}
#| echo: false

entropia_df_filtrado <- read.csv("./datos/entropia/entropia_clean.csv") |> 
  # dplyr::filter(!str_detect(Id, "gris-2")) |>
  # dplyr::filter(!str_detect(Id, "2-1")) |>
  dplyr::filter(!str_detect(Id, "2b")) |>
  # dplyr::filter(!str_detect(Id, "1b")) |>
  # dplyr::filter(!str_detect(Id, "negro-2")) |>
  janitor::clean_names()  |> 
  mutate(dia = case_when (stage == "prueba_1" ~ 1,
                           stage == "prueba_2" ~ 2,
                           stage == "prueba_rev" ~ 3
                ), 
         entropia_blanco = case_when(
           stage == "prueba_1" ~ entropia_ne,
           stage == "prueba_2" ~ entropia_ne,
           stage == "prueba_rev" ~ entropia_so
         ))



entropia_df_filtrado_fluox <- entropia_df_filtrado |>
  janitor::clean_names() |> 
  dplyr::filter(!str_detect(experimento, "Keta"))

# table(entropia_df_filtrado_fluox$tratamiento)

entropia_df_filtrado_fluox$tratamiento <- as.factor(entropia_df_filtrado_fluox$tratamiento)

entropia_df_filtrado_fluox$tratamiento = factor(entropia_df_filtrado_fluox$tratamiento, 
                                levels=c("Flx","Fluoxetina-CUMS", "Salina-CUMS-F"))

# entropia_df_filtrado_fluox$tratamiento = factor(entropia_df_filtrado_fluox$tratamiento, 
#                                 levels=c("Flx","Fluoxetina-CUMS", "Salina-CUMS-F",
#                                          "Ketamina-CUMS", "Salina-CUMS-K"))


# df_wm_otros$tratamientos = factor(df_wm_otros$tratamientos, 
#                                   levels=c("Ctrl", "Ket-CUMS", "Sal-CUMS-K"))


df.mean.entropia <- aggregate(entropia_df_filtrado_fluox$entropia_blanco,
                     by = list(entropia_df_filtrado_fluox$stage, 
                               entropia_df_filtrado_fluox$tratamiento,
                               entropia_df_filtrado_fluox$id),
                     FUN = 'mean')

colnames(df.mean.entropia) <- c("prueba","tratamientos","id","entropia_blanco")


```

```{r entropiaModelado}
#| echo: false

entropia.lmer.flx <- lmer(
  entropia_blanco ~ stage * tratamiento + (1 | tratamiento/id),
  data = entropia_df_filtrado_fluox
)



aov.entropia <- aov(entropia_blanco ~ tratamientos * prueba + Error(id/prueba), 
             data = df.mean.entropia)
```

```{r dfTiempoCuad}
#| echo: false

df.cuadrantes <- df_wm_flx |> 
  select(cuadrante_so, cuadrante_ne, cuadrante_no, cuadrante_se, 
         id, tratamientos, stage, dia, prueba) |> 
  dplyr::filter(str_detect(prueba, "P")) 



df.cuadrantes.long <- df.cuadrantes |> 
  pivot_longer(
    cols = starts_with("cuadrante"), 
    names_to = "cuadrante",
    values_to = "tiempo_cuadrante",
    values_drop_na = TRUE
  )

df.cuadrantes.long$cuadrante <- as.factor(df.cuadrantes.long$cuadrante)


###

df.mean.cuadrantes <- aggregate(df.cuadrantes.long$tiempo_cuadrante,
                     by = list(df.cuadrantes.long$prueba, 
                               df.cuadrantes.long$tratamientos,
                               df.cuadrantes.long$id,
                               df.cuadrantes.long$cuadrante),
                     FUN = 'mean')

colnames(df.mean.cuadrantes) <- c("prueba","tratamientos","id","cuadrante", "tiempo_cuadrante")

```

```{r CuadrantesModelado}
#| echo: false


lmer.cuadrantes <- lmer(
  tiempo_cuadrante ~ prueba * tratamientos * cuadrante + (1 | id),
  data = df.cuadrantes.long
)



aov.cuadrantes <- aov(tiempo_cuadrante ~ tratamientos * prueba * cuadrante + Error(id), 
                      data = df.mean.cuadrantes)


# library(rstatix)
# res.aov <- anova_test(
#   data = df.mean, dv = distancia_media_blanco, wid = id,
#   within = c(tratamientos, prueba)
# )
# get_anova_table(aov.1)
```


# Introducción

## Estrés, Depresión y Flexibilidad Cognitiva

### Estrés

Richard Lazarus define al estrés en torno a una relación entre el individuo y el ambiente, en el cual un estímulo no placentero, aversivo y/o amenazante para la homeostasis de un individuo es experimentado de manera que excede los recursos para lidiar con él [@folkman2013; @lazarus2006].

En presencia de estresores crónicos, impredecibles e incontrolables, la capacidad fisiológica de lidiar con estos no será suficiente, contribuyendo al desarrollo de desórdenes depresivos y de ansiedad [@hill2012]. Diversos factores afectan la respuesta al estrés y la susceptibilidad de que desencadene trastornos depresivos o de ansiedad. Estos van desde aspectos psicológicos (experiencia subjetiva del estrés, recursos para lidiar con estresores), hasta biológicos (cascadas neuroendócrinas, procesamiento de información) [@tafet2016]. 



#### Respuesta fisiológica al estrés

El estrés regula el eje hipotalámico-pituitario-adrenal (HPA) a través de una serie de mecanismos neuroendocrinos complejos. Ante un estresor, el hipotálamo secreta hormona liberadora de corticotropina (CRH), que estimula la pituitaria anterior para liberar hormona adrenocorticotropica (ACTH). La ACTH viaja a través del torrente sanguíneo hasta las glándulas suprarrenales, donde promueve la liberación de glucocorticoides, principalmente cortisol en humanos. El cortisol también retroalimenta negativamente al hipotálamo y la pituitaria para inhibir la liberación de CRH y ACTH, regulando así la actividad del eje HPA. Sin embargo, el estrés crónico puede conducir a una disfunción del eje HPA, resultando en niveles persistentemente elevados de cortisol, lo que puede tener consecuencias negativas para la salud.

Niveles elevados de cortisol, como los observados durante el estrés crónico, provocan una disminución en los niveles de serotonina (5-HT) del sistema nervioso  debido a la actividad reducida de la enzima limitante de la síntesis de serotonina, la triptófano hidroxilasa [@chen2017b; @shimomura2019]. A pesar de que niveles bajos de serotonina no se han asociado directamente al desarrollo de trastornos emocionales [@moncrieff2022], este neurotransmisor regula otros procesos fisiológicos que son clave en las conductas en respuesta a estresores [@evrensel2020]. 


##### Papel de Neurotransmisores

**Serotonina**

La mayoría de las neuronas serotoninérgicas en el SNC se encuentran dentro de los límites de los "núcleos del rafé". El núcleo dorsal del rafe tiene proyecciones a la corteza prefrontal, amígdala, núcleo accumbens e hipocampo ventral, entre otras estructuras del  prosencéfalo. Adicionalmente, el núcleo de rafé medial proyecta al hipocampo dorsal [@tafet2016]. Se cree que la administración crónica de antidepresivos del tipo "Inhibidores selectivos de la recaptura de serotonina" (ISRS) y el subsecuente aumento de 5-HT en el espacio sináptico como consecuencia de esta administración, juegan un papel en la acción antidepresiva y ansiolítica de estos fármacos [@latest_lin_2023].

```{r serotoninatab}
#| echo: false
#| label: tbl-serotoninatab
#| tbl-cap: "Estructuras relacionadas a las proyecciones del núcleo de rafe y su importancia en la respuesta al estrés. Información tomada de @tafet2016"

serotoninatab <- data.frame(Estructura=c("Corteza Prefrontal", 
                                         "Amígdala", 
                                         "Núcleo accumbens", 
                                         "Hipocampo"),
                            "Respuesta al Estrés" =c('evaluación y el control de las reacciones emocionales y la planificación de respuestas adecuadas a situaciones estresantes', 'procesamiento de emociones, especialmente el miedo y la ansiedad', 'evaluación de recompensas y la motivación para superar situaciones estresantes. Puede influir en la percepción de estrés y en las conductas de afrontamiento', ' Participa en la formación y recuperación de recuerdos relacionados con el estrés.')
                            
                            )
serotoninatab |> gt() 

```



**Dopamina**

La dopamina está relacionada con la regulación del eje HPA, así como en la fisiopatología de la depresión. Los principales grupos de neuronas dopaminérgicas en el SNC incluyen el campo retro-rubro (A8), la *substantia nigra pars compacta*  (A9) y el área tegmental ventral (A10), de donde emergen las vías mesolímbica y mesocortical [@tafet2016]. La vía mesolímbica se proyecta principalmente hacia el núcleo accumbens y otras estructuras del sistema límbico, incluyendo la amígdala, el hipocampo, el núcleo de la estría terminal y el septum, y está implicada en el procesamiento y refuerzo de estímulos gratificantes, motivación y la experiencia subjetiva del placer. La vía mesocortical se proyecta principalmente hacia la corteza prefrontal, el cíngulo anterior y la corteza entorrinal, y juega un papel crucial en funciones cognitivas como la concentración y la memoria de trabajo [@rajmohan2007]. 


**Norepinefrina**

El principal grupo de neuronas que contienen norepinefrina en el SNC se localiza en el *locus coeruleus*, desde donde surgen diversas proyecciones que inervan áreas corticales y subcorticales, incluyendo la amígdala y el hipocampo [@tafet2016]. Las proyecciones al área tegmental ventral (VTA) han demostrado potenciar la liberación de dopamina, mientras que las proyecciones al núcleo del rafe regulan la liberación de serotonina (5-HT) [@ressler1999]. También se ha observado una regulación recíproca entre la norepinefrina y la 5-HT mediante estructuras del sistema límbico como el hipocampo [@mongeau1997]. En respuesta a estresores agudos, se libera norepinefrina en diferentes estructuras del SNC, resultando en un aumento de la alerta y la hipervigilancia en el contexto de respuestas adaptativas al estrés [@seki2018]. Sin embargo, si el estresor se mantiene de forma continua, las neuronas del *locus coeruleus* presentan una mayor actividad que mantiene un estado de alerta constante, similar al observado en la ansiedad [@schmidt2019; @malta2021].


#### Estrés Crónico y sus Efectos en el Hipocampo

El hipocampo es una estructura cerebral situada en el lóbulo temporal medial fundamental en los procesos de consolidación de memorias (de corto a largo plazo), navegación espacial y regulación emocional [@anand2012]. Anatómicamente, el hipocampo se compone de varias subregiones interconectadas, incluyendo el giro dentado, el CA3, el CA1 y el subículo, cada una con funciones específicas en la procesación de información y la transmisión de señales neuronales [@andersen2007] (se expande más en @sec-hipocampo). El GD es particularmente interesante por la presencia de neurogénesis hipocampal adulta (NHA) descrita en diversos mamíferos, un proceso que permite la integración de nuevas neuronas en esta estructura a partir de progenitores neuronales [@surget2022]. 

El estrés crónico se ha asociado a cambios en el volumen de varias regiones cerebrales, incluido el hipocampo [@cobb2013]. Sin embargo, no está claro si la pérdida de volumen del hipocampo refleja una causa o una consecuencia de los trastornos emocionales. De acuerdo a la "hipótesis de vulnerabilidad a glucocorticoides" [@conrad2008], una elevada y constante concentración de glucocorticoides genera daños en esta estructura que pueden ser observados como alteraciones en la cognición. Estos daños incluyen: atrofia de dendritas en CA3 [@fuchs1998], menor densidad sináptica en el GD [@cater2006] y reducción en las tasas de NHA en el GD [@hill2015].  En conjunto, estos daños se observan en los hipocampos con menores volúmenes en pacientes que experimentan constantemente estrés crónico [@anand2012]. Por otro lado, pacientes con trastornos depresivos tratados con antidepresivos clásicos (ISRS) tienen un mayor volumen hipocampal en comparación de pacientes no tratados [@cobb2013; @boldrini2013]. 

A nivel cognitivo, los efectos del estrés crónico sobre el hipocampo se observan como dificultad en la formación de memorias explícitas (recordar información de manera consciente y deliberada, como hechos, eventos y conceptos) y dificultades en adaptar pensamientos y conductas de forma flexible [@sandi2013] (se expande del tema en @sec-flexibilidadcognitiva). A nivel emocional, estas alteraciones cognitivas contribuyen y mantienen los síntomas de estrés y ansiedad que dificultan la recuperación de un paciente [@anacker2017].


#### Modelo de Estrés Crónico Impredecible

El modelo de estrés crónico moderado impredecible (CUMS por sus siglas en inglés) fue desarrollado como un modelo animal de depresión hace más de 20 años. @katz1981 y colegas demostraron a principios de los ochentas que exponer a ratones a estrsores de manera crónica inducía una reducción en los roedores de un estímulo reforzante (sucrosa). En las décadas posteriores, diversas investigaciones lideradas por Paul Willner [resumidas en @willner2017c]  expandieron en las conductas que este modelo inducía en los roedores: afectaba el sueño, patrones de acicalamiento, conductas sexuales, conductas de agresión, entre muchas otras. Gracias a la caracterización de este investigador en este protocolo, se ha establecido como un modelo válido para el estudio de conductas de tipo depresivas en roedores. 

Este modelo ha sido utilizado para examinar variables neurobiológicas asociadas a la depresión, aunque no siempre es fácil validar exactamente cuales cambios neurobiológicos inducidos por el CUMS son paralelos a los documentados en el trastorno depresivo. Sin embargo, es un protocolo que provoca una serie de cambios neurobiológicos que reflejan aquellos vistos en los trastornos depresivos y puede ser una herramienta adecuada para investigar nuevos sistemas que podrían estar alterados en la depresión, y así ayudar en el desarrollo de nuevos objetivos para el tratamiento de la depresión [@hill2012]. Como revisa @willner2017c, el CUMS tiene *validez de predicción* (el rendimiento en el protocolo predice el rendimiento que queremos modelar), *validez de apariencia* (similitudes fenomenológicas) y *validez de constructo* (modelo tiene bases teóricas razonables).


##### Efectos del CUMS sobre cognición

El CUMS tiene efectos sobre varios aspectos de la Cognición (habilidad de procesar información, valorarla y utilizar el conocimiento por medio de conductas dirigidas, aprendizaje, memoria, atención, razonamiento, sentimientos, toma de desiciones) [@bondi2008]. Una consecuencia de estos efectos cognitivos, es la aparición de conductas maladaptativas en las pruebas de conducta, como la dificultad de reaprender una tarea (falta de flexibilidad cognitiva) [@maramis2021].

Debido a que el Hipocampo regula distintos aspectos de la cognición, esta estructura está íntimamente relacionada con las alteraciones cognitivas producidas por el CUMS. @el-aziz2022 reportan que el CUMS tiene efectos sobre la adquisición de una memoria espacial (evaluada a través del laberinto acuático de Morris), la cual depende en gran medida de la integridad del hipocampo. Sin embargo, poco se ha estudiado sobre la relación de el CUMS con un proceso específico de la cognición, la flexibilidad cognitiva y cómo se relaciona con el hipocampo y el protocolo de CUMS.


## Hipocampo {#sec-hipocampo}

Anatómicamente, el término formación hipocampal generalmente se refiere al giro dentado (GD), el cornu ammonis (CA) y subiculum. Además, CA se divide en tres subregiones, siendo CA1 y CA3 las más prominentes y CA2 que forma una zona intermedia pequeña entre estas dos. También hay una zona polimórfica en el giro dentado que contiene tanto células troncales e inhibitorias como excitatorias musgosas [@andersen2007].

El hipocampo está implicado en diversas funciones cognitivas, incluyendo el aprendizaje contextual [@amelchenko2023], la navegación espacial [@place_morris_1982], la separación de patrones [@nakashiba2012] y los procesos de memoria que surgen como resultado de la integración, separación y completación de la información proyectada y transmitida a través de sus distintas subregiones anatómicas [@mcavoy2015]. Como demostraron Penfield y Milner, es una estructura fundamental para la adquisición de memorias explícitas. En este artículo, reportan el caso del paciente H.M., al cual se le removió la mayoría de su hipocampo, cortezas parahipocampales, corteza entorrinal, corteza piriformes y amígdala en un intento de tratar sus ataques epilépticos. Después de la cirugía, su memoria de trabajo y procedural no se vieron afectadas. Sin embargo, el paciente presentó una inhabilidad de formar nuevas memorias episódicas (amnesia anterógrada). Este caso ayudo a entender cómo las memorias se formaban y almacenaban, estableciendo la formación de memorias al hipocampo [@penfield1958].


### neurogénesis hipocampal adulta

La **neurogénesis hipocampal adulta** (NHA) es un fenómeno que desafía la antigua creencia que el cerebro adulto es incapaz de generar nuevas neuronas a lo largo de la vida. Esta creencia proviene desde la propuesta de la "doctrina de la neurona" a partir del trabajo de Santiago Ramón y Cajal. En 1913, Ramón y Cajal escribió: "En el adulto, las terminales nerviosas son fijas e inmutables. Todo puede morir, pero nada se puede regenerar" [historia del concepto revisada en @kumar2019]. La NHA implica la proliferación de células progenitoras neurales, su diferenciación en neuronas, y su integración eventual en circuitos neuronales. Este fenómeno no solo es crucial para la plasticidad hipocampal [@toda2018] y probablemente la adquisición de memorias dependientes del hipocampo [@suarez-pereira2015], sino que también se ha vinculado con la regulación del estado de ánimo y la respuesta al estrés [@anacker2017].

En roedores la neurogénesis adulta está bien descrita en dos zonas: "zona subventricular" y "zona subgranular" en el "giro dentado". En la zona subventricular, las células troncales neurales se diferencian en neuronas olfativas. En el giro dentado, las células madre neurales producen neuronas glutamatérgicas que se integran en la capa granular y proyectan sus axones hacia la región de CA3 del hipocampo [@formation_denothlippuner_2021].

Utilizando timidina tritiada, el estudio pionero de @altman1965 presentó la primera evidencia de la presencia de células no diferenciadas en la capa granular del giro dentado en el hipocampo de ratas adultas. Décadas después, utilizando técnicas de inmunihistoquímica en cerebros post-mortem, @neurogenesis_eriksson_1998 fue el primero en presentar evidencia de bromodeuxyridina (BRDU) análogo de timidina icorporado en neuronas s en el giro dentado de humanos. 

Sin embargo, la existencia de la neurogénesis hipocampal en adultos humanos ha sido un tema controvertido en los últimos años. Por un lado, algunos estudios, como el de @sorrells2018, no han encontrado evidencia de neurogénesis en adultos. Por otro lado, investigaciones como las de @human_boldrini_2018 han llegado a la conclusión opuesta. Estas discrepancias se deben en gran medida a las diferencias en las metodologías utilizadas para detectar la neurogénesis y a las diversas interpretaciones de los resultados. Es probable que este debate continúe en los próximos años hasta que se desarrollen metodologías más precisas y confiables que permitan estudiar la dinámica de la NHA en humanos. 

Por ejemplo, @dynamics_spalding_2013 observaron una asociación entre NHA (evaluada por medio de C-14 incorporado al DNA como consecuencia de bombas nucleares) y la edad. Sin embargo, el método utilizado solo observó neuronas maduras, por lo que la dinámica de la proliferación de neuroblastos y diferenciación no puede ser integrado con este método [@ihunwo2016]. Como discute @paredes2018, los estudios que reportan neurogénesis en humanos son inconsistentes entre ellos: @dynamics_spalding_2013 reportan altos niveles de neurogénesis todavía en edades avanzadas, mientras que @dennis2016 reporta muy bajos niveles de NHA en adultos. De acuerdo al comentario de @paredes2018, quedan muchas dudas sobre la dinámica de la NHA en humanos, en especial de las células troncales neurales que no siempre son detectadas en los estudios de NHA en humanos. 

Respecto a las células troncales neurales, un reciente estudio [@franjic2022] utilizó secuenciación de células individuales en puercos, macacos y humanos adultos para tratar de identificar estos progenitores en el giro dentado. Sin embargo, su estudio no identificó señales de estos progenitores en los humanos, pero si en los otros animales. Debido a que todavía no se conoce del todo la dinámica de la NHA en humanos, esta introducción y el trabajo se enfocarán en la NHA de roedores, la cual está mucho mejor descrita [@kempermann2018a].  Al menos en roedores, esta NHA involucra la presencia de células troncales neurales a lo largo de la vida del roedor que constantemente regulan la dinámica del hipocampo [@zhang2023].  

![Neurogénesis Hipocampal Adulta en roedores. En este corte coronal se resalta al giro dentado, el cuál contiene las células troncales neurales y representa el nicho neurogénico. En el panel derecho, se describe la secuencia de la célula troncal a una neurona madura, pasando por estadíos intermedios y eventualmente madurando.](figuras/nha.png){fig-align="center"}



### NHA y flexibilidad cognitiva {#sec-flexibilidadcognitiva}


El hipocampo juega un papel crucial en la flexibilidad cognitiva, que es la capacidad de adaptarse a nuevas situaciones y cambiar de estrategia cuando las condiciones cambian. Este vínculo se debe a las funciones del hipocampo en la formación y recuperación de recuerdos contextuales y espaciales, así como en la integración de nueva información con experiencias pasadas [@epp2016; @martinez-canabal2019; @scott2021]. La plasticidad sináptica del hipocampo, especialmente a través de procesos como la potenciación a largo plazo (LTP), facilita la reorganización de redes neuronales que subyacen a la adaptación cognitiva. Además, el hipocampo interactúa con la corteza prefrontal, una región clave para la toma de decisiones y la implementación de estrategias flexibles. Las disfunciones en estas interacciones, como las observadas en trastornos neurológicos y psiquiátricos, suelen resultar en una disminución de la flexibilidad cognitiva, evidenciando la importancia del hipocampo en este proceso [@anacker2017a].

La flexibilidad cognitiva es una parte importante de la **función ejecutiva**, un conjunto de habilidades cognitivas que nos permiten planificar, organizar, tomar decisiones, mantener la atención, y regular el comportamiento. De acuerdo a la definición de @formation_denothlippuner_2021, algunos elementos clave de la flexibilidad cognitiva incluyen:

• Adaptabilidad: La capacidad de cambiar de estrategia o enfoque en respuesta a nueva información o cambios en el entorno.

• Tolerancia a la ambigüedad: La capacidad de manejar la incertidumbre o la ambigüedad sin experimentar un estrés excesivo.

• Multitarea: La habilidad de manejar y procesar varias tareas o informaciones a la vez.

• Cambio de perspectiva: La capacidad de ver las cosas desde diferentes ángulos o puntos de vista.

• Pensamiento divergente: La capacidad de generar una variedad de ideas o soluciones aun problema.


En humanos con síntomas depresivos y ansiosos, la falta de flexibilidad cognitiva se manifiesta en la presencia de pensamientos negativos recurrentes y persistentes (engramas viejos), así como en la ansiedad generalizada en diferentes contextos [@cognitive_uddin_2021]. Por otro lado, la flexibilidad cognitiva está asociada con una mejora de estos síntomas, facilitando el enfrentamiento de problemas desde diferentes enfoques o permitiendo el reaprendizaje de experiencias negativas desde una perspectiva de autocompasión (engramas nuevos) [@guler2022]. 

La neurogénesis hipocampal adulta (NHA) desempeña un papel fundamental en la flexibilidad cognitiva, aunque los mecanismos exactos de esta relación aún no se comprenden completamente. Se sugiere que las terminales sinápticas de las nuevas neuronas compiten con las neuronas viejas, que pueden representar engramas antiguos, hasta desplazar estructuralmente estas conexiones. Esto facilita el reaprendizaje al inducir una degradación de engramas previos mediante la interferencia sináptica. En ausencia de nuevas neuronas, no se eliminan los engramas viejos, lo que genera un conflicto entre engramas antiguos y nuevos, impidiendo el reaprendizaje [@akers2014].

Adicionalmente, las neuronas inmaduras pueden reclutar interneuronas que inhiben a las neuronas maduras del giro dentado, mientras que una baja neurogénesis mantiene una alta excitabilidad en esta región. Esta elevada excitabilidad, asociada a una baja NHA, podría resultar en una mayor activación de engramas (tanto viejos como nuevos), manifestándose como una disminución en la flexibilidad cognitiva [@groisman2020]. 

Un estudio por @vila-ballo2017a evidencía el papel del giro dentado en el aprendizaje reversa, un tipo de manifestación de la flexibilidad cognitiva. Este estudio comparó a mujeres con esclerósis hipocampal (pérdida de células y gliosis en el hipocampo) y mujeres con epilepsia del lóbulo temporal contra mujeres controles en una prueba de aprendizaje reversa llamada prueba de aprendizaje probabilístico. En esta tarea, se pide a los participantes que aprendan cuál de dos patrones es más probable que esté asociado con una recompensa. En cada prueba, se presentan simultáneamente dos patrones visuales abstractos y los participantes deben adivinar cuál es más probable que sea recompensado, recibiendo retroalimentación (correcto o incorrecto) después de cada elección. Se les informa que ningún estímulo es recompensado todo el tiempo y que el estímulo "recompensado" cambia ocasionalmente. Los participantes deben mantenerse con su elección hasta que sientan que el estímulo más probable de ser recompensado ha cambiado. La tarea comienza con una fase de adquisición inicial, donde uno de los estímulos es reforzado el 80% del tiempo. Una vez que alcanzan un criterio de 9 elecciones correctas en un bloque de diez ensayos (dentro de un máximo de 50 ensayos), las contingencias de refuerzo se invierten (aprendizaje reversa). Para alcanzar el criterio en la fase de reversión, los participantes deben elegir el nuevo estímulo más probable de ser recompensado 9/10 veces en un bloque de ensayos. Si logran alcanzar el criterio, las contingencias de refuerzo se invierten una vez más, y deben aprender a elegir el estímulo originalmente más probable de ser recompensado. La conclusión del estudio fue que las mujeres con daño al hipocampo tenían dificultades para adoptar estrategias anticipatorias en el aprendizaje reversa. 


La flexibilidad conductual es la manifestación física de la flexibilidad cognitiva. Como se explica en la siguiente sección, esta flexibilidad puede ser evaluada mediante protocolos de aprendizaje reversa, los cuales son sensibles a protocolos de estrés [@hurtubise2017].


#### Laberinto acuático de Morris

Una forma de estudiar la relación entre flexibilidad cognitiva y la NHA en roedores es utilizando el protocolo de laberinto acuático de Morris (MWM) [@hernandez-mercado2022]. Este laberinto fue desarollado en 1981 por el científico Richard G. M. Morris [@morris1981] y hasta la fecha sigue siendo utilizando para evaluar distintos aspectos de la memoria en sus diversos protocolos [@othman2022]. 

En este laberinto, la flexibilidad cognitiva se estudia a través de un "aprendizaje reversa", donde se evalúa la capacidad de reaprendizaje cuando la plataforma de escape se traslada a una nueva posición. Las pruebas de aprendizaje reversa son útiles para evaluar la flexibilidad cognitiva en roedores, primates no humanos y humanos [@cognitive_uddin_2021]. 

De acuerdo a este paradigma, @garthe2009a utilizó este laberinto para investigar cómo la supresión de la neurogénesis adulta con temozolomida (TMZ) afectaba el rendimiento en esta prueba. Este tratamiento farmacológico condujo a un déficit de aprendizaje un aprendizaje espacial preciso, afectando particularmente la capacidad de adaptarse a nuevas condiciones dentro de tareas aprendidas, sugiriendo que las nuevas neuronas en el giro dentado son cruciales para el aprendizaje y la memoria espacial flexibles y precisos. Los resultados concuerdan con la hipótesis de que el giro dentado contribuye no solo a un mapa configuracional del entorno, sino que desempeña un papel crítico en los procesos de aprendizaje dinámicos, destacando el impacto significativo de la neurogénesis adulta en la plasticidad hipocampal.

A pesar que el laberinto acuático de Morris representa el estándar de facto para probar la función del hipocampo en roedores de laboratorio, el uso de este paradigma para evaluar la relevancia funcional de las nuevas neuronas ha dado resultados sorprendentemente inconsistentes [@garthe2013]. Existe una inconsistencia en los resultados debido a la diversidad en los protocolos, configuraciones experimentales y análisis estadísticos utilizados [@overall2020]. Muchos autores han expresado sus preocupaciones sobre cómo los parámetros clásicos de medición en el laberinto pueden no ser adecuados para identificar los cambios funcionales específicos generados por la modulación de la neurogénesis hipocampal adulta [@maei2009a]. En este sentido, existe una necesidad de evaluar parámetros más específicos y sensibles que reflejen la funcionalidad única del hipocampo.

Por ejemplo, @maei2009 reportan que la mayoría de los artículos que utilizan el MWM evalúan las pruebas con métricas no óptimas para evaluar el aprendizaje espacial. La principal razón de estudiar métricas menos sensibles (tiempo en cuadrante, conteo de cruces a localización de plataforma) sobre otras más sensibles al aprendizaje espacial (entropía, distancia media) parece ser solo por simplicidad y facilidad, más que por otra cuestión.

Sumado a esto, también existen críticas a los análisis estadísticos clásicamente utilizados. Como recalca [@young2009] y [@young2021], los entrenamientos del MWM suelen ser evaluados con el análisis de varianza de medidas repetidas tradicional. Sin embargo, otros modelados que incluyan regresiones con efectos mixtos (lineales, generalizados o bayesianos) son más efectivos en detectar tendencias reales de aprendizaje y ofrecen mejores ajustes de los datos. Mejorar la interpretación de los datos obtenidos en el MWM es crucial para el entendimiento de los impactos cognitivos que tiene el estrés crónico.


## Fármacos Antidepresivos

Los primeros antidepresivos desarrollados fueron los inhibidores de la monoamino oxidasa (catalizan la oxidación de monoaminas), que mejoraban el ánimo a costa de efectos secundarios importantes, como toxicidad hepática y crisis hipertensivas [@lopez-munoz2009]. Posteriormente, se desarrollaron los antidepresivos tricíclicos (ATCs) como la imipramina y la clomipramina, que actúan principalmente bloqueando la recaptura de serotonina y noradrenalina. Debido a su falta de especificidad y efectos secundarios, los ATCs se prescriben actualmente para casos muy particulares de depresión [@hillhouse2015]. A finales de los años 80, surgieron los antidepresivos de segunda generación, incluyendo los inhibidores selectivos de la recaptación de serotonina (ISRS), los inhibidores de la recaptación de serotonina y noradrenalina (IRSN), antidepresivos serotonérgicos específicos y otros fármacos relacionados. Los ISRS, como el escitalopram, la fluoxetina y la sertralina, son los medicamentos más recetados para los trastornos de depresión y ansiedad, siendo la primera línea farmacológica debido a su tolerabilidad y eficacia [@hanson2011].

Actualmente, la depresión es tratada farmacológicamente utilizando medicamentos conocidos los ISRS como primera línea terapéutica. Su mecanismo de acción inmediato es a través de la regularización del sistema serotoninérgico mediante el incremento de la concentración de serotonina en el espacio sináptico. Sin embargo, su mecanismo de acción antidepresiva parece involucrar otros mecanismos, como la neurogénesis hipocampal adulta [@haroon2017].

Adicionalmente, los ISRS se utilizan en el tratamiento del trastorno de pánico y el trastorno obsesivo-compulsivo. Sin embargo, tienen el problema de generar efectos terapéuticos semanas o meses posteriores al inicio de su tratamiento, tener una efectividad comprometida, y un 70% de los pacientes responden de manera incompleta a los ISRS, siendo el resto difícil de tratar (pacientes con depresión resistente a los fármacos) [@latest_lin_2023].

Muchos autores han recalcado que hasta la fecha, no tenemos evidencia dura del efecto antidepresivo de los ISRS, recalcando que el efecto antidepresivo podría incluso deberse a un efecto placebo [@juul2021]. Otros autores señalan que la falta de efectividad proviene más bien del desconocimiento del mecanismo de acción de estos fármacos [@branchi2011]. 

La eficacia de los antidepresivos es otra línea de investigación que parece seguirá debatiéndose por más años. Por ejemplo, uno de los estudios más relevantes sobre el uso de antidepresivos, el STAR*D [@rush2004] sugiere que un 67% de los pacientes experimentan remisión (mejoras significativas en los síntomas depresivos) al ser medicados con ISRS en las primeras 14 semanas. Sin embargo, la falta de una definición de sus criterios de inclusión y exclusión (que fue reduciendo de 3,671 pacientes a solo 108) ha generado hasta la fecha una desconfianza en estos resultados [@pigott2023]. 

En otro estudio más reciente, @cipriani2018a publicaron una revisión sistemática que concluye que todos los antidepresivos incluidos en su estudio mejoraban los síntomas depresivos en adultos con trastorno depresivo en comparación del placebo. Otros autores critican el análisis estadístico de este estudio, los cuales podrían estar aumentando artificialmente las diferencias entre los grupos placebo con ISRS, de acuerdo a @latest_moncrieff_2018. Sin embargo, como se verá en la siguiente sección, los ISRS generan estados de plasticidad cerebral que podrían facilitar estados mentales que permitan la recuperación de trastornos depresivos o de ansiedad [@branchi2011].


### Mecanismo de acción

Como se mencionó previamente, varias terapias que en modelos murinos incrementan la neurogénesis (ejercicio aeróbico, fármacos antidepresivos, modelos transgénicos) parecen también reducir los síntomas depresivos [@anacker2017]. Varios fármacos antidepresivos (clásicos y no clásicos) podrían mitigar síntomas depresivos promoviendo la neurogénesis hipocampal, aunque podrían existir otros mecanismos de acción adicionales que contribuyan a esta acción (como efectos anti inflamatorios) [@hovorka2022].

Se ha demostrado en modelos murinos que el tratamiento crónico con fluoxetina (ISRS y agonista parcial de 5-HT2B) [@latest_lin_2023] promueve la neurogénesis hipocampal y reduce las conductas depresivas en modelos de estrés [@segi-nishida2017]. Sumado a estos efectos, se ha observado que el tratamiento crónico con fluoxetina promueve la flexibilidad cognitiva en ratones en una prueba conductual que involucra discriminación de patrones espaciales, búsqueda de recompensa y evitar castigos [@marwari2018].

Por último, hay que destacar que utilizando técnicas de inmunohistoquímica y electrofisiología en ratones [@kobayashi2011] y primates (*Callithrix jacchus*) [@ohira2019], se han descrito otros procesos de plasticidad hipocampal inducidos por antidepresivos que podrían jugar un papel sobre la flexibilidad cognitiva. Estos grupos han descrito que la fluoxetina puede revertir a neuronas granulares maduras del hipocampo a un fenotipo inmaduro, un fenómeno denominado "demaduración". En este fenómeno, las neuronas maduras expresan marcadores relacionados a inmaduridad (calretinina), reducen la expresión de marcadores de neuronas maduras (calbindina) y presentan propiedades electrofisiológicas características de una neurona inmadura, como aumento de excitabilidad. Al mismo tiempo, este fármaco parece reducir el número de neuronas con redes perineuronales (regiones de la matriz extracelular que regulan el desarrollo y la plasticidad de la conectividad de las neuronas) en el giro dentado, un fenómeno que promueve la plasticidad en el cerebro adulto. En conjunto, estos resultados podrían significar que existen otros mecanismos independientes de la NHA que reinstauren un estado de inmadurez al giro dentado que representa un sustrato importante en la cognición y regulación del comportamiento [@umemori2018].

De acuerdo con investigaciones lideradas por Igor Branchini [@branchi2022], los niveles altos de plasticidad inducidos por medicamentos, como los antidepresivos serotoninérgicos y los psicodélicos, no son beneficiosos por sí mismos. Estos fármacos inducen una alta plasticidad (a veces llamados psicoplastógenos) que hacen que el cerebro y el comportamiento sean más susceptibles a cambios según factores contextuales, como las condiciones de vida. Esta suceptibilidad puede ser benéfica si las condiciones de vida mejoran. 



## Antecedentes


Estudios postmortem han revelado que un menor volumen del hipocampo, particularmente en las áreas del giro dentado (GD), CA1 y CA3, está asociado con pacientes que sufren de depresión no medicada [@cobb2013, @huang2013]. Estos hallazgos resaltan la importancia del hipocampo en la modulación de los síntomas depresivos.

En modelos animales, se ha observado que el estrés crónico disminuye la NHA e induce conductas ansiosas y depresivas. Investigaciones con ratones transgénicos han demostrado que el aumento de la NHA puede disminuir estos síntomas, independientemente de la regulación del eje hipotálamo-pituitario-adrenal (HPA), subrayando así el efecto significativo de la neurogénesis en las emociones [@hill2015]. 

La relación entre la NHA y la flexibilidad cognitiva también ha sido demostrada. Por ejemplo, @akers2014 y colaboradores demostraron que el aumento de la neurogénesis después de la formación de una memoria puede inducir el olvido, lo que sugiere un papel crítico de la NHA en la adaptación y el reaprendizaje. En el contexto del laberinto acuático de Morris, se ha encontrado que la NHA es esencial para el aprendizaje y la memoria espacial flexibles, siendo crucial para adaptarse a nuevas condiciones [@garthe2009].

La fluoxetina, un inhibidor selectivo de la recaptación de serotonina (ISRS), ha mostrado efectos promisorios en la mejora de la flexibilidad cognitiva. Estudios recientes han investigado los efectos de los enantiómeros de la fluoxetina en paradigmas de comportamiento cognitivo y proliferación celular en el hipocampo de ratones. Se encontró que la (R)-fluoxetina mejoraba significativamente la adquisición de secuenciación conductual y la flexibilidad cognitiva en tareas de aprendizaje reverso, así como la proliferación celular en el giro dentado @marwari2018.

Por último, desde que Morris diseñó su protocolo del laberinto acuático, ha habido una búsqueda por encontrar métricas que modelen mejor el aprendizaje dependiente del hipocampo [@place_morris_1982]. Sin embargo, hasta la fecha se siguen utilizando principalmente métricas subóptimas para evaluar el aprendizaje espacial [@meenakshi2022] y la relevancia de las nuevas neuronas en este laberinto [@garthe2013]. Utilizar mejores métricas y modelamiento de la prueba ayuda a tener una mejor inferencia estadísticas que permita identificar las interacciones conductuales complejas entre fenómenos como el estrés, depresión y flexibilidad cognitiva.

Dados estos antecedentes, nuestra investigación se propone evaluar el impacto de la fluoxetina sobre la flexibilidad cognitiva en ratones sometidos a estrés crónico y determinar cómo la NHA afecta el aprendizaje en el laberinto acuático de Morris. El estudio pretende vincular directamente los efectos de la fluoxetina y la NHA con la mejora de la flexibilidad cognitiva y la reducción de conductas depresivas, proporcionando una base para potenciales enfoques terapéuticos en el tratamiento de la depresión y otros trastornos relacionados con la flexibilidad cognitiva.

# Objetivos

## General

Evaluar el impacto de la fluoxetina sobre la flexibilidad cognitiva en ratones con estrés crónico y determinar el papel de la neurogénesis hipocampal adulta en dicho impacto. 

### Específicos

i.	Investigar los efectos del estrés crónico y el tratamiento con fluoxetina sobre la flexibilidad cognitiva dependiente del hipocampo, utilizando el Laberinto Acuático de Morris.
i.	Analizar si el incremento de neurogénesis causada por el tratamiento de fluoxetina correlaciona con las mejoras en flexibilidad cognitiva. 
i. Contribuir al desarrollo de modelos más efectivos en neurociencia cognitiva que faciliten la comprensión de los mecanismos por los cuales la fluoxetina puede mitigar las alteraciones cognitivas causadas por el estrés.


# Hipótesis

Si el incremento de neurogénesis es conocido por facilitar la flexibilidad cognitiva, entonces el tratamiento crónico de fluoxetina podrá mejorar el desempeño en el reaprendizaje espacial de ratones sometidos a estrés crónico impredecible mediante un mecanismo dependiente de neurogénesis hipocampal. 

# Metodología

![Diseño Experimental](figuras/diseno_experimental.png){fig-align="center"}

## Animales

Todos los ratones utilizados en este experimento se obtendrán a partir de la cruza de ratones macho de la cepa C57BL/6 y hembras de la cepa BALB/c. Estos pies de cría serán proporcionados por el bioterio de la Facultad de Ciencias, UNAM, donde se tiene un convenio con la Comisión de Ética Académica y Responsabilidad Científica (CEARC) con Folio: PI_2020_12_03. Se utilizarán tanto ratones machos como hembras.

Los animales serán mantenidos de manera constante en cajas comunales de acrílico con rejilla de acero inoxidable, a una temperatura ambiente controlada de 20°C mediante un termostato y un calentador ambiental eléctrico de aceite. La humedad ambiental se regulará mediante un humidificador y se mantendrá alrededor del 50%, con un ciclo de luz/oscuridad de 12:12 horas. Los ratones serán alojados en una cama compuesta por una mezcla de viruta comercial para roedores y ocote molido de grano fino en una proporción de 1:1, con el fin de proporcionarles una cama cómoda y con capacidad extra de absorción de agua y amoniaco. El alimento será proporcionado ad libitum (LabDiet - 5001). Las camas se cambiarán y las cajas se lavarán dos veces por semana. Los ratones se mantendrán en colonias de entre 2 y 5 animales. Además, se les proporcionará material de enriquecimiento y nidificación (como tubos de cartón y papel picado) dentro de sus cajas.

Se utilizaron 7 ratones para el grupo de Fluoxetina (sin estrés), 9 para el grupo de fluoxetina-CUMS (fármaco y estrés) y 8 para el grupo de Salina-CUMS (inyección de salina con estrés).

## CUMS

Los ratones serán sometidos a un protocolo de estrés crónico moderado impredecible (CUMS) durante 21 días para inducir un estado depresivo. Los estresores utilizados en el protocolo de CUMS serán los siguientes:

- Privación de agua y comida (8 horas)
- Interrupción del ciclo luz/oscuridad
- Cama mojada (200 ml en 100 g de aserrín por 19 horas)
- Cajas inclinadas a 45 grados por 24 horas
- Levantamiento por la cola (5 minutos)
- Aislamiento en cajas individuales (2 horas)

Este protocolo se basará en el trabajo de @monteiro2015 y representa una forma confiable de inducir estados depresivos y ansiosos en ratones C57BL/6. De acuerdo con la revisión de @antoniuk2019, este tipo de estrés crónico reduce la neurogénesis hipocampal en roedores.

## Tratamiento con Fluoxetina

Se administrará un inhibidor de la recaptura de serotonina (fluoxetina, 15 mg/kg) para observar sus efectos sobre la flexibilidad cognitiva. El fármaco será administrado diariamente durante 3 semanas vía subcutánea, coincidiendo con la administración del protocolo de CUMS.

## MWM {#sec-mwmmetodo}

Posteriormente, se llevará a cabo un protocolo del Laberinto Acuático de Morris (MWM) para evaluar el desempeño cognitivo. Este protocolo consistirá en hacer nadar a los ratones durante 60 segundos en un recipiente con agua a 27℃. Durante estos 60 segundos, los ratones deberán encontrar una plataforma oculta guiándose únicamente por pistas visuales presentes en el cuarto de prueba. Esta prueba se realizará 4 veces seguidas por cada ratón durante 5 días. Al término de estas pruebas de entrenamiento, se realizarán 2 pruebas de retención de memoria, donde se dejará nadar al ratón durante 60 segundos en el mismo recipiente, pero ahora sin la plataforma oculta. Finalmente, se llevará a cabo una última prueba donde la plataforma se cambiará de lugar. Esta última prueba, conocida como prueba de aprendizaje de reversión, se utilizará para dilucidar la flexibilidad cognitiva en los ratones.


## Perfusión e inmunihistoquímica

Para obtener y analizar el tejido neuronal, los ratones serán sacrificados por perfusión. Se inyectará a los ratones con pentobarbital sódico a una dosis anestésica total irreversible. Este fármaco se adquirirá en una farmacia veterinaria bajo receta y autorización del M.V.Z encargado del bioterio de la Facultad de Ciencias. Se utilizará la marca Pet’s Pharma® N° de Registro: Q-7972-004, la cual se diluirá 1:3 en solución salina estéril (0.9%) para obtener 1 ml de solución por 100 g de peso del animal, que corresponde a 210 mg/kg. La inyección será administrada vía intraperitoneal. Tras 3 minutos, se observará si el animal ya no muestra locomoción, reflejo del párpado ante un soplo de aire y reflejo de movimiento corporal ante la presión mecánica sobre la cola. Solo hasta que ya no se observen dichos reflejos, se procederá a abrir la caja torácica y perfundir con 50 ml de solución de sacarosa al 30% y 50 ml de paraformaldehído al 3.7%. Los fluidos sobrantes (mezcla de sangre con las soluciones) serán almacenados y rotulados como desechos tóxicos y se desecharán de acuerdo con los procedimientos de la comisión de desechos peligrosos de la Facultad de Ciencias. El cerebro de los animales será colectado y el resto de los tejidos será almacenado en una bolsa etiquetada como desechos biológicos para su apropiada disposición en el congelador del bioterio de la Facultad de Ciencias, anotando el número de animales y la fecha en la bitácora oficial. Todos los procedimientos de perfusión se llevarán a cabo bajo la campana de extracción, utilizando guantes de nitrilo, bata, cofia y mascarilla con filtro para vapores orgánicos y aldehídos. Los cerebros, fijados en paraformaldehído, serán rebanados en congelación en un criostato y almacenados en anticongelante en un congelador hasta su uso para análisis posteriores.

Una vez que el cerebro del ratón esté incrustado en paraformaldehído, se cortará en secciones muy finas con un microtomo y se colocarán en un portaobjetos las secciones correspondientes al hipocampo. Para remover el paraformaldehído y rehidratar el tejido, se utilizará xileno, seguido de una serie de lavados de alcohol de concentraciones decrecientes para rehidratar el tejido. Para realizar la inmunotinción, se añadirá el anticuerpo primario, que está diseñado para unirse a la proteína de interés. En nuestro caso, se observará la expresión de doblecortina (anticuerpo a doblecortina policlonal - HPA036121-25UL Sigma-Aldrich), la cual es una proteína asociada a microtúbulos que solo se expresa en células neuronales precursoras o inmaduras. Finalmente, la muestra se examinará bajo un microscopio (Zeiss Primostar 3) y se analizará la intensidad y localización de la tinción.

## Modelado Estadístico

Debido a la naturaleza de los datos longitudinales y jerárquicos en el laberinto de Morris, se debe considerar en el modelado estadístico la naturaleza dependiente y estructurada de los datos. Los modelos con efectos mixtos, también conocidos como modelos lineales jerárquicos o modelos multinivel, son una herramienta poderosa para abordar estos desafíos. Estos modelos permiten la incorporación de variaciones tanto a nivel individual como grupal, proporcionando una mayor flexibilidad y precisión en el análisis. A pesar de la evidencia de utilizar estos modelos en el laberinto de Morris [@young2009], no muchos estudios los emplean para el análisis de datos de esta prueba [@young2021]. 

El uso de modelos que permitan incorporar efectos aleatorios, permite capturar la variabilidad intrínseca entre individuos o grupos a lo largo del tiempo. Tradicionalmente, para corregir las medidas no independientes en esta prueba se utiliza un análisis de ANOVA de medidas repetidas. Sin embargo, debido a la naturaleza de los resultados en el laberinto de Morris, los supuestos de este modelo son muy difíciles de cumplir. Estos van desde la normalidad y linealidad de la variable de respuesta, simetría de componentes (varianzas y covarianzas similares) y esfericidad de componentes (varianzas de las diferencias entre los niveles deben ser similares). En contraste, los modelos con efectos mixtos manejan naturalmente la dependencia entre mediciones repetidas de los mismos participantes, evitando los problemas de pseudoreplicación. Además, no requieren suposiciones estrictas como la simetría compuesta o la esfericidad. Los modelos con efectos mixtos pueden especificar diferentes estructuras de covarianza, adaptándose mejor a los datos reales. Otro punto es que son más robustos frente a violaciones de suposiciones estadísticas, reduciendo la probabilidad de errores de Tipo I y proporcionando resultados más fiables. Por último, pueden manejar eficientemente datos incompletos o no balanceados, una ventaja significativa en estudios longitudinales y experimentos con mediciones repetidas. [@magezi2015, @aarts2014]. 

Todos los análisis fueron realizados en el lenguaje de programación R. Se utilizó el paquete `lme4` [@bates2015] para las regresiones, excepto para el caso de la regresión bayesiana, el cuál utilizó el paquete `brms`[@burkner2017]. Para obtener las medias marginales de los modelos y realizar los contrastes de las medias se utilizó el paquete `emmeans`.

### Latencia de escape en los entrenamientos


Para modelar la latencia, se empleó un modelo de regresión bayesiana con efectos mixtos [@young2021]. Este modelo permite utilizar una distribución no normal que tenga un mínimo de $0$ (ya que las latencias no pueden ser menores o iguales a 0) y una cola superior prolongada [@]. Las distribuciones de latencia son típicamente sesgadas debido al aprendizaje (@fig-histogramasdensidad). Bajo estos supuestos, se pueden utilizar distribuciones Gamma o Weibull, las cuales se ajustan mejor a este tipo de datos.

Para la regresión bayesiana, se utilizó la "distribución de probabilidad a priori" propuesta por @young2021 (t-student, **location** = 4.50, **scale** = 0.25). El poder predictivo del modelo es substancial (`R2 = 0.53, 95% CI [0.50, 0.58]`). El modelo fue estimado con métodos de Montecarlo basados en cadenas de Markov (4 cadenas con 4000 iteraciones y 2000 de calentamiento). A partir de esta distribución a priori, es posible considerar los datos censurados y no reducir artificialmente las latencias ni varianzas. Como menciona Young, considerar esta censura de datos es relevante cuando estamos tratando de entender si existen diferencias en el aprendizaje del MWM en nuestros grupos experimentales.

Para tomar en cuenta estos datos censurados, ajustamos un modelo Bayesiano lineal generalizado (distribución Gamma) con efectos mixtos para predecir las latencias a través de los entrenamientos en los distintos tratamientos (fórmula `Latencia|censurados ~ tiempo * tratamientos`). El modelo incluye al tiempo y sujetos como efectos aleatorios (fórmula `1 + tiempo | id`). Es decir, la pendiente de la latencia en el tiempo puede variar por sujetos. Esto permite capturar el fenómeno donde la relación entre Latencia y tiempo puede diferir entre diferentes sujetos.

### Estrategias de búsqueda en los entrenamientos


Para calcular las estrategias de búsqueda en el MWM, se utilizó el paquete de R "*Rtrack*" [@overall2020]. Overall, en colaboración con Garthe y Kempermann, toman como base las estrategias definidas por @garthe2009, pero mejoran el algorítmo de clasificación al utiliza un clasificador de *machine learning* (random forest, previamente entrenado con 3111 datos).

Para facilitar el análisis y debido a la falta de una *n* mayor (tanto en animales, como en tiempos), se agruparon las estrategias en 3 tipos (enfoque similar a @amelchenko2023): 

- Estrategias egocéntricas: tigmotáxis, circulación, búsqueda aleatoria, encadenamiento y exploración (@fig-estrategiasrandom y @fig-estrategiachaining).

- Estrategias alocéntricas: búsqueda dirijida, búsqueda enfocada y nado directo (@fig-estrategiasalocentricas).

- Perseverancia. Se considera aparte debido a la importancia de este fenómeno en la evaluación de la flexibilidad cognitiva (@fig-estrategiasalocentricas). 

::: {#fig-entEstrategias layout-ncol=1}

![Estrategias Egocéntricas Aleatorias. Estas no están relacionadas con un intento a escapar del laberinto por medio de una búsqueda de la plataforma. En esta categoría se encuentran, de izquierda a derecha: tigmotaxis, aleatorio (caso 1), aleatorio (caso 2).](figuras/estrategias_random.jpg){#fig-estrategiasrandom}

![Estrategias Egocéntricas Procedurales. El contexto de la búsqueda es relativo al sujeto. En la izquierda, exploración (patrones repetitivos en un área), a la derecha, búsqueda en cadena (individuo sabe que la plataforma está a cierta distancia del muro y se mueve en circulos).](figuras/estrategias_chaining.jpg){#fig-estrategiachaining}

![Estrategias Alocéntricas. El individuo se mueve de forma dirigida y orientada a la plataforma. De izquierda a derecha: búsqueda dirigida (se mueve al blanco, aunque con errores que involucran cambios de orientación), búsqueda enfocada (se mueve casi sin errores hacia el blanco), nado directo (nada en línea recta hacia el blanco), perseverancia (búsqueda dirigida hacia blanco anterior). ](figuras/estrategias_directas.jpg){#fig-estrategiasalocentricas}

![Animación de perseverancia. El ratón persiste en la localización del annulus original antes de regresar al annulus reversa.](figuras/perseverancia.gif){#fig-perseverancia}

Estrategias de búsqueda en los entrenamientos del MWM. En A y B, estrategias independientes de hipocampo. En C, estrategias alocéntricas dependientes del hipocampo. En naranja se muestra la localización de la plataforma blanco. En gris se muestra la localización de la plataforma vieja (casos de entrenamiento reversa). El triángulo amarillo representa la zona ideal que debería de seguir el roedor para llegar al blanco. 

:::


Los criterios para definir las estrategias son las siguientes [@overall2020]:

- *Tigmotaxis*: Comportamiento relacionado con la ansiedad, caracterizado por un camino de nado que sigue la pared exterior o donde el sujeto entra repetidamente en contacto con la pared. No se mueve de manera dirigida hacia un objetivo, sino que intenta salir del área de prueba.
- *Circulación*:	El sujeto se mueve en círculos cerrados repetidos. Esto es distinto de uno o dos círculos completos que a veces se usan para escanear el entorno y reorientarse. La circulación puede estar relacionada con la ansiedad.
- *Aleatorio*:	El sujeto se mueve sin rumbo por el área sin intentar buscar un objetivo.
- *Exploración*:	El sujeto se mueve en patrones repetitivos, cubriendo una amplia región del área. Los patrones pueden ser un ‘bucle rodante’ donde el centro del bucle cambia continuamente, o un ‘zigzag’. Este comportamiento puede estar localizado pero fuera de objetivo o ser más enfocado en el objetivo.
- *Encadenamiento*:	El sujeto ha identificado que el objetivo está a una distancia específica de la pared y se mueve a esta distancia con la esperanza de encontrarlo. Puede ser difícil de detectar ya que el sujeto a menudo encuentra el objetivo en menos de un circuito completo del área.
- *Búsqueda dirigida*: al objetivo	El sujeto se mueve de manera orientada al objetivo, pero no siempre de manera correcta. Pueden haber bucles de orientación, correcciones de camino y retrocesos en el camino para reorientarse. Diferente del escaneo, el camino no es repetitivo ni cubre una gran área.
- *Búsqueda enfocada*:	El sujeto se mueve en un camino casi directo al objetivo, pero comete uno o dos errores que corrige reorientándose. Los errores pueden ser un pequeño bucle para escanear el entorno (‘bucle de orientación’), un cambio de rumbo (‘corrección de camino’) o un bucle mayor donde el sujeto regresa a un punto anterior del camino y vuelve a intentar la búsqueda (‘meandro de reorientación’).
- *Nado directo*:	El sujeto se mueve en línea directa hacia el objetivo.
- *Perseverancia*:	El patrón de búsqueda implica una repetida visita a una ubicación anterior del objetivo. Esta estrategia solo se denomina así cuando se define una antigua posición del objetivo. En caso de un cambio en la posición del annulus, como en los entrenamientos reversa, esta estrategia se denomina ‘perseverancia’.

Se determinó la preferencia de estrategias con una prueba de independencia de chi cuadrada para determinar los cambios de estrategias utilizadas por día (@fig-porcentajesEstrategiasPlots).

Para entender mejor la interacción entre variables categóricas (prueba, tipo de estrategia [cuenta] y tratamiento), ajustamos una regresión de Poisson con efectos mixtos (utilizando máxima verosimilitud) (@fig-poissonEquaciones). La variable de respuesta es el número de tipo de estrategias, y las variables predictoras son el tiempo y tratamiento. Se incluyeron a los ratones como efectos mixtos para tomar en cuenta la dependencia de los datos en el tiempo (medidas repetidas).


```{r reglogiEq}
#| echo: false
#| label: fig-poissonEquaciones
#| fig-cap: "Ecuación de regresión de Poisson."
#| layout-ncol: 1

equatiomatic::extract_eq(glme.poisson.pre, wrap = TRUE, terms_per_line = 1, operator_location = "start")

# equatiomatic::extract_eq(glme.poisson.post, wrap = TRUE, terms_per_line = 1, operator_location = "start")

```

### Distancia media en las pruebas


Esta métrica calcula la distancia promedio del roedor al centro de la plataforma. Como demostró @maei2009a, esta es una métrica muy sensible al aprendizaje espacial en el MWM. Esta métrica es más empleada para el análisis de las pruebas en el MWM, aunque se puede emplear para analizar los entrenamientos [@wolfer1998].

Ajustamos un modelo lineal mixto (estimado usando REML) para predecir la distancia media al blanco a partir de la prueba y tratamientos (fórmula: `distancia_media_blanco ~ prueba * tratamientos`). El modelo incluyó a los sujetos como efecto aleatorio (fórmula:` ~1 | id`). El poder explicativo total del modelo es sustancial (R2 condicional = 0.72) (@fig-EqDistanciaMedia). 


```{r EqDistanciaMedia}
#| echo: false
#| label: fig-EqDistanciaMedia
#| fig-cap: Ecuación de regresión Distancia Media.

equatiomatic::extract_eq(lmer.dist.media.pruebas, wrap = TRUE, terms_per_line = 4, operator_location = "start")

```

### Tiempo en cuadrantes en las pruebas

Ajustamos un modelo lineal mixto (estimado usando REML) para predecir el tiempo en cuadrantes a partir de la prueba, tratamientos y el tipo de cuadrante (noreste, noroeste, sureste, suroeste) (fórmula: `tiempo_cuadrante ~ prueba * tratamientos * cuadrante`) (@fig-EqCuadrantes). El modelo incluyó a los sujetos como efecto aleatorio (fórmula: `~1 | id`). El poder explicativo total del modelo es sustancial (R2 condicional = 0.59). 


```{r EqCuadrantes}
#| echo: false
#| label: fig-EqCuadrantes
#| fig-cap: Ecuación de regresión Tiempo en Cuadrantes.
equatiomatic::extract_eq(lmer.cuadrantes)

```

### Entropía

Ajustamos un modelo lineal mixto (estimado usando REML) para predecir la entropia a partir de la prueba y tratamientos (fórmula: `entropia_blanco ~ etapa * tratamiento`). El modelo incluyó a los sujetos como efecto aleatorio (fórmula:` ~1 | id`) (@fig-EqEntropia). El poder explicativo total del modelo es sustancial (R2 condicional = 0.49). Dentro de este modelo, el efecto de la prueba 2 × tratamiento [**Fluoxetina-CUMS**] es estadísticamente significativo y positivo (beta = 0.75, IC del 95% [0.06, 1.43], t(73) = 2.16, p = 0.034; beta estandarizado = 1.06, IC del 95% [0.08, 2.04]). 

```{r EqEntropia}
#| echo: false
#| label: fig-EqEntropia
#| tbl-cap: "Ecuación de regresión para modelar la Entropia al annulus blanco."
equatiomatic::extract_eq(entropia.lmer.flx, wrap = TRUE, terms_per_line = 4, operator_location = "start")
```

### Medias Marginales

Para visualizar las medias estimadas por los modelos estadísticos, se graficaron las medias marginales estimadas. Estas medias marginales se calculan ajustando por otros factores o covariables en el modelo [@aarts2014] (en nuestro caso, la interacción de tiempo y tratamientos). Esto significa que representan el efecto medio de un factor específico, controlando o ‘promediando’ los efectos de los otros factores. Esto es útil en experimentos con diseños complejos o con múltiples factores y niveles. 

Las medias marginales consideran toda la estructura del modelo, incluyendo efectos fijos y aleatorios. Esto las hace especialmente relevantes para la interpretación en modelos de efectos mixtos, donde los efectos aleatorios juegan un rol crucial. Además, proveen una base para hacer predicciones ajustadas y generalizables más allá del conjunto de datos actual, especialmente en modelos predictivos que incluyen variables aleatorias y fijas.

La gran diferencia con las medias calculadas, las cuales son simplemente el promedio aritmético de los datos observados dentro de cada grupo o nivel de factor, es que estas últimas no ajustan por la posible confusión de otros factores o la estructura de dependencia dentro de los datos (como en los datos agrupados o jerárquicos). Además, las medias calculadas pueden estar sesgadas porque el número de observaciones en cada grupo puede ser diferente.


# Resultados 



## Fluoxetina mejora el reaprendizaje en los ratones con CUMS

Para evaluar el rendimiento de los grupos en la primera fase de aprendizaje (previo al CUMS), se compararon las latencias de escape (tiempo que tardan los ratones en localizar la plataforma durante los días de entrenamiento) (@fig-bayeslatenciasplotspre). Como se observa en la @tbl-paramsbaypre, los estimados para la latencia inicial difieren entre los grupos, aunque la latencia final y la pendiente ("ritmo de aprendizaje") terminan siendo similares entre los tres grupos. El poder predictivo del modelo es substancial (R2 = 0.45). Todos los estimados del modelo convergieron con éxito (evaluada por Rhat) y los índices son confiables (evaluada por ESS). La interacción entre el tiempo y los tratamientos tiene un 24% de probabilidad de ser significativo ($> 0.05$). 


::: {#tbl-tables layout-ncol=1}

```{r bayeslatenciasplotspre}
#| echo: false
#| label: fig-bayeslatenciasplotspre
#| fig-cap: "Medias Marginales Estimadas para obtenidas a partir del Modelo Bayesiano de efectos mixtos tomando en cuenta los valores censurados. Graficados con intervalos de densidad más alta al 66% para resaltar los valores más probables del parámetro."



b1.c_effects_plot.pre <- b1.c_effects_plot.pre  +
  ggplot2::ylim(0,80) +
  theme_classic() +
  scale_color_manual(values = c("#222831", "#00ADB5", "#FF2E63", "#FF9800", "#8675A9", "#862B0D")) +
  scale_fill_manual(values = c("#222831", "#00ADB5", "#FF2E63", "#FF9800", "#8675A9", "#862B0D")) +
  labs(
    # caption = "Plotted with 66% Credible Intervals",
    color = "Tratamientos",
    fill = "Tratamientos",
    shape = "Tratamientos",
    x = "Dia",
    y = "Segundos") +
  theme(legend.position='top', axis.text = element_text(size = 12),axis.title = element_text(size = 15)) +
  scale_x_continuous(labels = c("0", "1", "2", "3", "4"))

b1.c_effects_plot.pre

# b1.ignore_effects_plot.pre <- b1.ignore_effects_plot.pre +
#   ggplot2::ylim(0,80)+
#   theme_classic() +
#   scale_color_manual(values = c("#222831", "#00ADB5", "#FF2E63", "#FF9800", "#8675A9", "#862B0D")) +
#   scale_fill_manual(values = c("#222831", "#00ADB5", "#FF2E63", "#FF9800", "#8675A9", "#862B0D")) +
#   labs(
#     # caption = "Plotted with 66% Credible Intervals",
#     color = "Tratamientos",
#     fill = "Tratamientos",
#     shape = "Tratamientos",
#     x = "Dia",
#     y = "Segundos") +
#   theme(legend.position='top', axis.text = element_text(size = 12),axis.title = element_text(size = 15))  +
#   scale_x_continuous(labels = c("0", "1", "2", "3", "4"))


# bn_effects_plot.pre <-  bn_effects_plot.pre  +
#   ggplot2::ylim(0,80)+
#   theme_classic() +
#   scale_color_manual(values = c("#222831", "#00ADB5", "#FF2E63", "#FF9800", "#8675A9", "#862B0D")) +
#   scale_fill_manual(values = c("#222831", "#00ADB5", "#FF2E63", "#FF9800", "#8675A9", "#862B0D")) +
#   labs(
#     # caption = "Plotted with 66% Credible Intervals",
#     color = "Tratamientos",
#     fill = "Tratamientos",
#     shape = "Tratamientos",
#     x = "Dia",
#     y = "Segundos") +
#   theme(legend.position='top', axis.text = element_text(size = 12),axis.title = element_text(size = 15)) +
#   scale_x_continuous(labels = c("0", "1", "2", "3", "4"))


# bay_effect_plots.pre <- b1.c_effects_plot.pre + b1.ignore_effects_plot.pre + bn_effects_plot.pre + 
#   plot_annotation(tag_levels = 'i') + 
#   plot_layout(guides = 'collect', axis_titles = 'collect') &
#   theme(legend.position = 'top')
# 
# bay_effect_plots.pre


```

```{r paramsbaypre}
#| echo: false
#| label: tbl-paramsbaypre
#| tbl-cap: "Parámetros estimados para las latencias originales a partir del modelo Bayesiano. "

paramsbaypre <- data.frame(Tratamiento=c("Flx", 
                                         "Flx-CUMS", 
                                         "Sal-CUMS-F"),
                           Latencia.Inicial =c(62.1, 32.8, 46.2),
                           Latencia.Final = c(10.96, 7.85, 12.86),
                           Pentiente = c("-0.464", "-0.381", "-0.340")
                            
                            )
paramsbaypre |> gt() 
```

Latencias en fase de aprendizaje inicial.
:::


Para comprobar que el aprendizaje en esta etapa fuera dependiente del hipocampo (mapa cognitivo), se analizaron las estrategias de búsqueda utilizadas en estos entrenamientos iniciales (@tbl-preestrategias). El analizáis de preferencia de estrategias (alocéntrica o egocéntrica) de un día a otro se determinó con una prueba de independencia de Xi-cuadrada, donde probamos la hipótesis de si existe una asociación (o independencia) entre día y estrategia utilizada (@fig-porcentajesEstrategiasPlots). Los p-values significativos los entrenamientos originales para todos los grupos (Flx *p* $>0.001$, Flx-CUMS *p* $>0.05$, Salina-CUMS Flx *p* $>0.001$) sugieren que hay diferencias significativas en la preferencia de estrategias entre los distintos días de los entrenamientos. Como se observa en la @fig-porcentajesEstrategiasPlots, parece que todos los grupos pasan de adoptar estrategias egocéntricas a estrategias alocéntricas. Para entender mejor la relación entre el uso de estrategias a través del tiempo en los distintos tratamientos, ajustamos una regresión de Poisson con efectos mixtos (utilizando máxima verosimilitud) (@fig-poisonplotsEmmeanspre). La variable de respuesta es el número de tipo de estrategias, y las variables predictoras son el tiempo y tratamiento. Se incluyeron a los ratones como efectos mixtos para tomar en cuenta la dependencia de los datos en el tiempo (medidas repetidas). El modelo de regresión no presentó sobre-dispersión (*dispersion ratio* = 0.375), por lo que cumple con el supuesto de homogeneidad de varianza en los datos y el modelo.


::: {#tbl-preestrategias layout-ncol=1}

```{r porcentajesEstrategiasPlots}
#| echo: false
#| label: fig-porcentajesEstrategiasPlots
#| fig-cap: "Porcentaje de Estrategias de búsqueda utilizadas."

estrategias_porcentajes_df_pre$estrategias_hipo = factor(estrategias_porcentajes_df_pre$estrategias_hipo, 
                                levels=c("hipocampo_dependientes","hipocampo_independientes"), 
                                labels = c("Alocéntricas","Egocéntricas"))

estrategias_porcentajes_df_pre$tratamiento = factor(estrategias_porcentajes_df_pre$tratamiento, 
                                levels=c("Flx","Flx-CUMS", "Sal-CUMS-F"), 
                                labels = c("Flx [***]","Flx-CUMS [*]", "Sal-CUMS-F [***]"))

estrategias_porcentajes_df_pre |> 
  # dplyr::filter(str_detect(experimento, "Flx")) |>
  ggplot(
    aes(
      x = stage,
      y = freq,
      color = estrategias_hipo,
      fill = estrategias_hipo
      # label = porcentaje
    )) +
  geom_col(position = position_stack(reverse = TRUE)) +
  geom_label(aes(label = scales::percent(freq)), size = 4, position = position_stack(reverse = TRUE, vjust = 0.5), color = "black", show.legend = FALSE) +
  # geom_bar(stat = "identity") +
  scale_color_manual(values = c("#046582", "#BBBFCA", "#C86B85")) +
  scale_fill_manual(values = c("#046582", "#BBBFCA", "#C86B85")) +
  facet_wrap(vars(tratamiento)) +
  scale_x_discrete(name = "Dia", labels = c("1", "2", "3", "4")) +
  scale_y_continuous(name = "", labels = scales::percent_format()) +
  labs(fill = "", color = "") +
  # ggthemes::theme_clean() +
  ggthemes::theme_base() +
  # ggthemes::theme_few() +
  theme(legend.position='top', axis.text = element_text(size = 12),axis.title = element_text(size = 15)) 
  # annotate(
  # "text",
  # label = "**",
  # x = 2.5,
  # y = 1.03,
  # size = 10,
  # colour =  "#00ADB5")
# ) +
#   annotate(
#     "text",
#     label = "**",
#     x = "P-Rev",
#     y = .50,
#     size = 8.5,
#     colour =  "#FF2E63"
#   ) +
#   annotate(
#     "text",
#     label = "**",
#     x = "P-Rev",
#     y = .50,
#     size = 8.5,
#     colour =  "#FF2E63"
#   )
```

```{r poisonplotsEmmeanspre}
#| echo: false
#| label: fig-poisonplotsEmmeanspre
#| fig-cap: "Medias Estimadas a partir de la regresión de Poisson. Las medias graficadas representan el estimado de estrategias utilizadas por tratamiento en cada día de los entrenamientos (4 pruebas por día). No se encontraron diferencias significativas en las medias. Las medias marginales están calculadas a tres niveles, prueba, tratamientos y tipo de estrategia. Graficado con Media + error estándar."

emm.estrategias.flx.pre <- emmeans(glme.poisson.pre, ~ dia | tratamiento | estrategias_hipo, cov.reduce = F,        
        type = "response") # displayed results to be back-transformed to the response scale
# trans = "log"


emm.estrategias.flx.pre.df <- as.data.frame(emm.estrategias.flx.pre) |> 
  dplyr::mutate(estrategias_hipo = recode(estrategias_hipo,
                                          "hipocampo_dependientes" = "Alocéntricas",
                                          "hipocampo_independientes" = "Egocéntricas"))

ggplot(emm.estrategias.flx.pre.df,
                    aes(
                      x = dia,
                      y = rate, # rate emmeans
                      group = tratamiento,
                      color = tratamiento
                    )) +
  geom_line(linewidth = 0.3, linetype = "dashed", position = position_dodge(0.1)) +
  geom_point(size = 4, position = position_dodge(0.1), aes(shape = tratamiento)) +
  # geom_point(size = 7, shape = 21, position = position_dodge(0.1)) +
  geom_pointrange(aes(ymin = rate-SE, ymax = rate+SE),
                  size = 0.75, position = position_dodge(0.1)) +
  scale_color_manual(values = c("#222831", "#00ADB5", "#FF2E63", "#FF9800", "#8675A9", "#862B0D")) +
  labs(
    # caption = "Graficado con error estándar",
    color = "Tratamientos",
    shape = "Tratamientos",
    x = "Entrenamiento",
    y = "Media Estimada") +
  ylim(0, 4) +
  # scale_x_discrete(labels=c("entrenamiento_rev_1"="1", "entrenamiento_rev_2"="2")) +
  # theme_classic() +
  # ggthemes::theme_base() +
  ggthemes::theme_clean() +
  facet_grid(~ estrategias_hipo) +
  theme(legend.position='top', axis.text = element_text(size = 10),axis.title = element_text(size = 15)) 




# latencias_post_emmeans_aov.df <- as.data.frame(latencias_post_emmeans_aov)


####### POST

# emm.estrategias.flx.post <- emmeans(glm.poisson.post, ~ dia | tratamiento | estrategias_hipo, cov.reduce = T)       
#         # type = "response") # displayed results to be back-transformed to the response scale
# # trans = "log"
# 
# 
# emm.estrategias.flx.post.df <- as.data.frame(emm.estrategias.flx.post) |> 
#   dplyr::mutate(estrategias_hipo = recode(estrategias_hipo,
#                                           "hipocampo_dependientes" = "Alocéntricas",
#                                           "hipocampo_independientes" = "Egocéntricas"))
# 
# ggplot(emm.estrategias.flx.post.df,
#                     aes(
#                       x = dia,
#                       y = emmean, # rate emmeans
#                       group = tratamiento,
#                       color = tratamiento
#                     )) +
#   geom_line(linewidth = 0.3, linetype = "dashed", position = position_dodge(0.1)) +
#   geom_point(size = 4, position = position_dodge(0.1), aes(shape = tratamiento)) +
#   # geom_point(size = 7, shape = 21, position = position_dodge(0.1)) +
#   geom_pointrange(aes(ymin = emmean-SE, ymax = emmean+SE),
#                   size = 0.75, position = position_dodge(0.1)) +
#   scale_color_manual(values = c("#222831", "#00ADB5", "#FF2E63", "#FF9800", "#8675A9", "#862B0D")) +
#   labs(
#     # caption = "Graficado con error estándar",
#     color = "Tratamientos",
#     shape = "Tratamientos",
#     x = "Entrenamiento",
#     y = "Media Estimada") +
#   ylim(0, 4) +
#   # scale_y_continuous(name, breaks, labels, limits, trans) +
#   scale_x_discrete( 
#                     limits=c("1","2")) +
#   # scale_x_discrete(labels=c("entrenamiento_rev_1"="1", "entrenamiento_rev_2"="2")) +
#   # theme_classic() +
#   # ggthemes::theme_base() +
#   ggthemes::theme_clean() +
#   facet_grid(~ estrategias_hipo) +
#   theme(legend.position='top', axis.text = element_text(size = 10),axis.title = element_text(size = 15)) 


######## COMPS EMMEANS

# emmeans(glm.poisson.post, ~ dia | tratamiento | estrategias_hipo, cov.reduce = F)
# 
# 
# aov_em_post <- emmeans(glm.poisson.post, pairwise ~ tratamiento | dia | estrategias_hipo, adjust = "fdr", cov.reduce = F)$contrasts |>
#   dplyr::as_tibble() |>  
#   dplyr::select(-df, -t.ratio) |>
#   dplyr::rename(Estimado = estimate) |> 
#   dplyr::filter(p.value <= 0.05) |>
#   tidyr::separate(contrast, into = c("Tratamiento_1", "Tratamiento_2"), sep = " - ") |> 
#   gt::gt()  |> 
#   tab_footnote("Comparaciones múltiples ajustadas con Tukey HSD") |> 
#   fmt_number(decimals = 3) |>
#   tab_style_body(
#     style = list(
#                  cell_text(color = "#222831")),
#     values = c("Flx")
#   ) |> 
#   tab_style_body(
#     style = list(
#                  cell_text(color = "#00ADB5")),
#     values = c("(Flx-CUMS)")) |>
#   tab_style_body(
#     style = list(
#                  cell_text(color = "#FF2E63")),
#     values = c(("(Sal-CUMS-F)"))
#     ) |> 
#   opt_stylize(style = 1) 
# 
# aov_em_post

```

:::

Inmediatamente después de los 4 días de entrenamientos iniciales, se realiza la prueba 1 de adquisición de la memoria espacial, seguido del protocolo de CUMS (21 días) y posteriormente la prueba 2 (retención de memoria) para finalizar con dos días de entrenamientos reversa y la última prueba de aprendizaje reversa. Las tres pruebas se presentan en conjunto después de los entrenamientos reversa para analizar a más detalle. Aunque se pueden presentar y analizar las pruebas por separado como evidencia que las medias previo al tratamiento no difieren, es preferible examinar el modelo completo con el término de interacción (tiempo x tratamiento) seguido de un análisis *post-hoc* para comprender y modelar correctamente las medias y términos de errores a través del tiempo [ @nieuwenhuis2011; @deboer2015; @garofalo2022].  


Para evaluar el rendimiento de los grupos en la segunda fase de aprendizaje (posterior al CUMS, entrenamientos de aprendizaje reversa), se compararon las latencias de escape (tiempo que tardan los ratones en localizar la plataforma durante los días de entrenamiento) (@fig-bayeslatenciasplotspost). Como se observa en la @tbl-paramsbaypost, los estimados para la latencia inicial difieren entre los grupos, aunque la latencia final y la pendiente ("ritmo de aprendizaje") terminan siendo similares entre los tres grupos. El poder predictivo del modelo es substancial (R2 = 0.53). Todos los estimados del modelo convergieron con éxito (evaluada por Rhat) y los índices son confiables (evaluada por ESS). La interacción entre el tiempo y los tratamientos tiene un 38.2% de probabilidad de ser significativo ($> 0.05$). 


::: {#fig-tablespost layout-ncol=1}


```{r bayeslatenciasplotspost}
#| echo: false
#| label: fig-bayeslatenciasplotspost
#| fig-cap: "Medias Marginales Estimadas para obtenidas a partir del Modelo Bayesiano de efectos mixtos tomando en cuenta los valores censurados. Graficados con intervalos de densidad más alta al 66% para resaltar los valores más probables del parámetro. Se grafica un día extra con el fin de predecir los valores posibles."



b1.c_effects_plot <- b1.c_effects_plot +
  ggplot2::ylim(0,180) +
  theme_classic() +
  scale_color_manual(values = c("#222831", "#00ADB5", "#FF2E63", "#FF9800", "#8675A9", "#862B0D")) +
  scale_fill_manual(values = c("#222831", "#00ADB5", "#FF2E63", "#FF9800", "#8675A9", "#862B0D")) +
  labs(
    # caption = "Plotted with 66% Credible Intervals",
    color = "Tratamientos",
    fill = "Tratamientos",
    shape = "Tratamientos",
    x = "Dia",
    y = "Segundos") +
  theme(legend.position='top', axis.text = element_text(size = 12),axis.title = element_text(size = 15))+
  scale_x_continuous(labels = c("0", "1", "2", "3", "4"))

b1.c_effects_plot



```

```{r paramsbaypost}
#| echo: false
#| label: tbl-paramsbaypost
#| tbl-cap: "Parámetros estimados para las latencias reversa a partir del modelo Bayesiano. "

paramsbaypost <- data.frame(Tratamiento=c("Flx", 
                                         "Flx-CUMS", 
                                         "Sal-CUMS-F"),
                           Latencia.Inicial =c(41.3, 65.2, 109.2),
                           Latencia.Final = c(3.85, 6.85, 8.38),
                           Pentiente = c("-1.91", "-1.82", "-2.05")
                            
                            )
paramsbaypost |> gt() 
```

Latencias en fase de aprendizaje Reversa.
:::



Para comprobar que el aprendizaje en esta etapa fuera dependiente del hipocampo (mapa cognitivo), se analizaron las estrategias de búsqueda utilizadas en estos entrenamientos iniciales (@tbl-posttrategias). El analizáis de preferencia de estrategias (alocéntrica, egocéntrica o perseverancia) de un día a otro se determinó con una prueba de independencia de Xi-cuadrada, donde probamos la hipótesis de si existe una asociación (o independencia) entre día y estrategia utilizada (@fig-porcentajesEstrategiasPlots). Los p-values significativos los entrenamientos originales para todos los grupos (Flx *p* $>0.001$, Flx-CUMS *p* $>0.05$, Salina-CUMS Flx *p* $>0.001$) sugieren que hay diferencias significativas en la preferencia de estrategias entre los distintos días de los entrenamientos. Como se observa en la @fig-porcentajesEstrategiasPlots, parece que todos los grupos pasan de adoptar estrategias egocéntricas a estrategias alocéntricas. Para entender mejor la relación entre el uso de estrategias a través del tiempo en los distintos tratamientos, ajustamos una regresión de Poisson con efectos mixtos (utilizando máxima verosimilitud) (@fig-poisonplotsEmmeanspost). La variable de respuesta es el número de tipo de estrategias, y las variables predictoras son el tiempo y tratamiento. Se incluyeron a los ratones como efectos mixtos para tomar en cuenta la dependencia de los datos en el tiempo (medidas repetidas). El modelo de regresión no presentó sobre-dispersión (*dispersion ratio* = 0.375), por lo que cumple con el supuesto de homogeneidad de varianza en los datos y el modelo.


::: {#tbl-posttrategias layout-ncol=1}

```{r porcentajesEstrategiasPlotspost}
#| echo: false
#| label: fig-porcentajesEstrategiasPlotspost
#| fig-cap: "Porcentaje de Estrategias de búsqueda utilizadas."

estrategias_porcentajes_df$estrategias_hipo = factor(estrategias_porcentajes_df$estrategias_hipo, 
                                levels=c("hipocampo_dependientes","hipocampo_independientes", "perseverancia"), 
                                labels = c("Alocéntricas","Egocéntricas", "Perseverancia"))

estrategias_porcentajes_df$tratamiento = factor(estrategias_porcentajes_df$tratamiento, 
                                levels=c("Flx","Flx-CUMS", "Sal-CUMS-F"), 
                                labels = c("Flx [ns]","Flx-CUMS [*]", "Sal-CUMS-F [**]"))

estrategias_porcentajes_df |> 
  ggplot(
    aes(
      x = stage,
      y = freq,
      color = estrategias_hipo,
      fill = estrategias_hipo,
      # label = porcentaje
    )) +
  geom_col(position = position_stack(reverse = TRUE)) +
  geom_label(aes(label = scales::percent(freq)), size = 4, position = position_stack(reverse = TRUE, vjust = 0.5), color = "black", show.legend = FALSE) +
  # geom_bar(stat = "identity") +
  scale_color_manual(values = c("#046582", "#BBBFCA", "#C86B85")) +
  scale_fill_manual(values = c("#046582", "#BBBFCA", "#C86B85")) +
  # scale_fill_paletteer_d("futurevisions::atomic_orange") +
  # scale_fill_paletteer_d("nbapalettes::hornets") +
  # scale_fill_paletteer_d("nbapalettes::timberwolves") +
  # scale_fill_paletteer_d("rockthemes::deelite") +
  # scale_color_paletteer_d("rockthemes::muse", direction = -1) +
  # scale_fill_paletteer_d("rockthemes::muse", direction = -1) +
  facet_wrap(vars(tratamiento)) +
  scale_x_discrete(name = "Dia", labels = c("1", "2")) +
  scale_y_continuous(name = "", labels = scales::percent_format()) +
  labs(fill = "", color = "") +
  ggthemes::theme_clean() +
  # ggthemes::theme_few() +
  theme(legend.position='top', axis.text = element_text(size = 12),axis.title = element_text(size = 15)) 
```


```{r poisonplotsEmmeanspost}
#| echo: false
#| label: fig-poisonplotsEmmeanspost
#| fig-cap: "Medias Estimadas a partir de la regresión de Poisson. Las medias graficadas representan el estimado de estrategias utilizadas por tratamiento en cada día de los entrenamientos (4 pruebas por día). No se encontraron diferencias significativas en las medias. Las medias marginales están calculadas a tres niveles, prueba, tratamientos y tipo de estrategia. Graficado con Media + error estándar."


emm.estrategias.flx.post <- emmeans(glm.poisson.post, ~ dia | tratamiento | estrategias_hipo, cov.reduce = T)       
        # type = "response") # displayed results to be back-transformed to the response scale
# trans = "log"


emm.estrategias.flx.post.df <- as.data.frame(emm.estrategias.flx.post) |> 
  dplyr::mutate(estrategias_hipo = recode(estrategias_hipo,
                                          "hipocampo_dependientes" = "Alocéntricas",
                                          "hipocampo_independientes" = "Egocéntricas",
                                          "perseverancia" = "Perseverancia"))

ggplot(emm.estrategias.flx.post.df,
                    aes(
                      x = dia,
                      y = emmean, # rate emmeans
                      group = tratamiento,
                      color = tratamiento
                    )) +
  geom_line(linewidth = 0.3, linetype = "dashed", position = position_dodge(0.1)) +
  geom_point(size = 4, position = position_dodge(0.1), aes(shape = tratamiento)) +
  # geom_point(size = 7, shape = 21, position = position_dodge(0.1)) +
  geom_pointrange(aes(ymin = emmean-SE, ymax = emmean+SE),
                  size = 0.75, position = position_dodge(0.1)) +
  scale_color_manual(values = c("#222831", "#00ADB5", "#FF2E63", "#FF9800", "#8675A9", "#862B0D")) +
  labs(
    # caption = "Graficado con error estándar",
    color = "Tratamientos",
    shape = "Tratamientos",
    x = "Entrenamiento",
    y = "Media Estimada") +
  ylim(0, 4) +
  # scale_y_continuous(name, breaks, labels, limits, trans) +
  scale_x_discrete( 
                    limits=c("1","2")) +
  # scale_x_discrete(labels=c("entrenamiento_rev_1"="1", "entrenamiento_rev_2"="2")) +
  # theme_classic() +
  # ggthemes::theme_base() +
  ggthemes::theme_clean() +
  facet_grid(~ estrategias_hipo) +
  theme(legend.position='top', axis.text = element_text(size = 10),axis.title = element_text(size = 15)) 


######## COMPS EMMEANS

# emmeans(glm.poisson.post, ~ dia | tratamiento | estrategias_hipo, cov.reduce = F)
# 
# 
# aov_em_post <- emmeans(glm.poisson.post, pairwise ~ tratamiento | dia | estrategias_hipo, adjust = "fdr", cov.reduce = F)$contrasts |>
#   dplyr::as_tibble() |>  
#   dplyr::select(-df, -t.ratio) |>
#   dplyr::rename(Estimado = estimate) |> 
#   dplyr::filter(p.value <= 0.05) |>
#   tidyr::separate(contrast, into = c("Tratamiento_1", "Tratamiento_2"), sep = " - ") |> 
#   gt::gt()  |> 
#   tab_footnote("Comparaciones múltiples ajustadas con Tukey HSD") |> 
#   fmt_number(decimals = 3) |>
#   tab_style_body(
#     style = list(
#                  cell_text(color = "#222831")),
#     values = c("Flx")
#   ) |> 
#   tab_style_body(
#     style = list(
#                  cell_text(color = "#00ADB5")),
#     values = c("(Flx-CUMS)")) |>
#   tab_style_body(
#     style = list(
#                  cell_text(color = "#FF2E63")),
#     values = c(("(Sal-CUMS-F)"))
#     ) |> 
#   opt_stylize(style = 1) 
# 
# aov_em_post

```

:::


```{r poisonCheckModel}
#| echo: false
#| eval: false

check_overdispersion(glme.poisson.pre)

check_overdispersion(glme.poisson.post)
```


Para analizar las tres pruebas del MWM, utilizamos dos métricas altamente sensibles al aprendizaje espacial, la distancia media al annulus y la entropía de Shannon. Como referencia, a continuación se presentan los mapas de calor de los tres grupos en las tres pruebas.

```{r mapascalorfluoxetina}
#| echo: false
#| label: fig-mapascalorfluox
#| fig-cap: "Mapas de Calor Fluoxetina."
#| fig-subcap: 
#|   - "Prueba-1"
#|   - "Prueba-2"
#|   - "Prueba-Reversa"
#| layout-ncol: 3

Rtrack::plot_density(
  flx_p1_metrics,
  title = "FLX P-1",
  col = viridis(300), # 738
  resolution = 900,
  feature.col = "#E87FB0",
  feature.lwd = 4,
  legend = F
)


Rtrack::plot_density(
  flx_p2_metrics,
  title = "FLX P-2",
  col = viridis(300), # 738
  resolution = 900,
  feature.col = "#E87FB0",
  feature.lwd = 4,
  legend = F
)

Rtrack::plot_density(
  flx_rev_metrics,
  title = "FLX Reversa",
  col = viridis(300), # 738
  resolution = 900,
  feature.col = "#E87FB0",
  feature.lwd = 4,
  legend = F
)

```

```{r fluoxetinaCumsMapa}
#| echo: false
#| label: fig-fluoxetinaCumsMapa
#| fig-cap: "Mapas de Calor Fluoxetina-CUMS."
#| fig-subcap: 
#|   - "Prueba-1"
#|   - "Prueba-2"
#|   - "Prueba-Reversa"
#| layout-ncol: 3

Rtrack::plot_density(
  flx_CUMS_p1_metrics,
  title = "FLX-CUMS P-1",
  col = viridis(300), # 738
  resolution = 900,
  feature.col = "#E87FB0",
  feature.lwd = 4,
  legend = F
)


Rtrack::plot_density(
  flx_CUMS_p2_metrics,
  title = "FLX-CUMS P-2",
  col = viridis(300), # 738
  resolution = 900,
  feature.col = "#E87FB0",
  feature.lwd = 4,
  legend = F
)

Rtrack::plot_density(
  flx_CUMS_rev_metrics,
  title = "Flx-CUMS Reversa",
  col = viridis(300), # 738
  resolution = 900,
  feature.col = "#E87FB0",
  feature.lwd = 4,
  legend = F
)

```

```{r salinaCUMSfMapa}
#| echo: false
#| label: fig-salinaCUMSfMapa
#| fig-cap: "Mapas de Calor Salina-CUMS-Fluoxetina."
#| fig-subcap: 
#|   - "Prueba-1"
#|   - "Prueba-2"
#|   - "Prueba-Reversa"
#| layout-ncol: 3

Rtrack::plot_density(
  sal_cums_f_p1_metrics,
  title = "Sal-CUMS-FLX P1",
  col = viridis(300), # 738
  resolution = 900,
  feature.col = "#E87FB0",
  feature.lwd = 4,
  legend = F
)

Rtrack::plot_density(
  sal_cums_f_p2_metrics,
  title = "Sal-CUMS-FLX P-2",
  col = viridis(300), # 738
  resolution = 900,
  feature.col = "#E87FB0",
  feature.lwd = 4,
  legend = F
)

Rtrack::plot_density(
  sal_cums_f_rev_metrics,
  title = "Sal-CUMS-F Reversa",
  col = viridis(300), # 738
  resolution = 900,
  feature.col = "#E87FB0",
  feature.lwd = 4,
  legend = F
)



```


Ajustamos un modelo lineal mixto (estimado usando REML) para predecir la distancia media al blanco a partir de la prueba y tratamientos (fórmula: distancia_media_blanco ~ prueba * tratamientos). El modelo incluyó a los sujetos como efecto aleatorio (fórmula:~1 | id). El poder explicativo del modelo es sustancial (R2 condicional = 0.72). La prueba de razón de verosimilitud o *likelihood ratio* ($X^2 (4) = 22.87, p = 0.0001$) determinó que la interacción entre `Prueba x Tratamiento` es significativa. Esta prueba compara el modelo sin el término de interacción ($H_0$) *versus* el modelo con interacción ($H_a$). Se prefiere este método para probar los términos de interacción en los modelos de efectos mixtos sobre el método de descomponer la varianza de la variable de respuesta en sus componentes asociados para cada predictor y sus interacciones (ANOVA). La principal razón es que para los modelos mixtos, no hay un método exacto de calcular los grados de libertad para estimar la varianza de los parámetros, además de que la prueba de verosimilitud toma en cuenta los efectos aleatorios del modelo, mientras que un ANOVA solo toma en cuenta los efectos fijos del modelo [@bates2015]. La prueba de comparaciones múltiples (ajustada con Tukey HSD, fórmula `~ tratamientos | prueba`)  indica que en la **Prueba 2**, el grupo de `Flx-CUMS` difiere significativamente del grupo `Flx` ($p = 0.01$) y del grupo `Sal-CUMS` ($p = 0.04$). en la **Prueba reversa**, el grupo `Sal-CUMS` difiere significativamente del grupo `Flx` ($p < 0.001$) y del grupo `Flx-CUMS` ($p = 0.002$). 


```{r DMedPlotEmmeanPruebas}
#| echo: false
#| label: fig-DMedPlotEmmeanPruebas
#| fig-cap: "Distancia Media al annulus blanco en las tres Pruebas. Graficado con Media + error estándar. La prueba de comparaciones múltiples (ajustada con Tukey HSD, fórmula `~ tratamientos | prueba`)  indica que en la **Prueba 2**, el grupo de `Flx-CUMS` difiere significativamente del grupo `Flx` ($p = 0.01$) y del grupo `Sal-CUMS` ($p = 0.04$). en la **Prueba reversa**, el grupo `Sal-CUMS` difiere significativamente del grupo `Flx` ($p < 0.001$) y del grupo `Flx-CUMS` ($p = 0.002$)."


lmer.dist.media.pruebas.emm <- emmeans(lmer.dist.media.pruebas,  
                        ~ tratamientos | prueba, cov.reduce = FALSE)


lmer.dist.media.pruebas.emm.df <- as.data.frame(lmer.dist.media.pruebas.emm)

lmer.dist.media.plot <- ggplot(lmer.dist.media.pruebas.emm.df,
                    aes(
                      x = prueba,
                      y = emmean,
                      group = tratamientos,
                      color = tratamientos
                    )) +
  geom_line(linewidth = 0.3, linetype = "dashed", position = position_dodge(0.1)) +
  geom_point(size = 4, position = position_dodge(0.1), aes(shape = tratamientos)) +
  # geom_point(size = 7, shape = 21, position = position_dodge(0.1)) +
  geom_pointrange(aes(ymin = emmean-SE, ymax = emmean+SE),
                  size = 0.75, position = position_dodge(0.1)) +
  scale_color_manual(values = c("#222831", "#00ADB5", "#FF2E63", "#FF9800", "#8675A9", "#862B0D")) +
  labs(
    # caption = "Plotted with SEM",
    color = "Tratamientos",
    shape = "Tratamientos",
    x = "Prueba",
    y = "Distancia (m)") +
  # ylim(0, 60) +
  # scale_x_discrete(labels=c("entrenamiento_rev_1"="1", "entrenamiento_rev_2"="2")) +
  # theme_classic()
  # ggthemes::theme_clean() +
  ggthemes::theme_clean() + 
  theme(legend.position='top', axis.text = element_text(size = 12),axis.title = element_text(size = 15)) 

lmer.dist.media.plot  + annotate(
  "text",
  label = "*",
  x = "P-2",
  y = .50,
  size = 8.5,
  colour =  "#00ADB5"
) +
  annotate(
    "text",
    label = "**",
    x = "P-Rev",
    y = .50,
    size = 8.5,
    colour =  "#FF2E63"
  )




```

```{r DMedPCompsEmmeans}
#| echo: false
#| eval: false
# label: tbl-DMedPCompsEmmeans
# tbl-cap: "Contrastes significativos en Distancia Media."



emmeans(lmer.dist.media.pruebas, pairwise ~ tratamientos | prueba, adjust = "tukey",  cov.reduce = FALSE)$contrasts |>
  as_tibble() |>
  dplyr::select( -t.ratio) |>
  dplyr::rename(Estimado = estimate) |>
  dplyr::filter(p.value <= 0.05) |>
  tidyr::separate(contrast, into = c("1", "2"), sep = " - ")  |> 
  gt::gt()  |> 
  tab_footnote("Comparaciones múltiples ajustadas con Tukey HSD") |> 
  fmt_number(decimals = 3) |>
  tab_style_body(
    style = list(
                 cell_text(color = "#222831")),
    values = c("Flx")
  ) |> 
  tab_style_body(
    style = list(
                 cell_text(color = "#00ADB5")),
    values = c("(Flx-CUMS)")) |>
  tab_style_body(
    style = list(
                 cell_text(color = "#FF2E63")),
    values = c(("(Sal-CUMS-F)"))
    ) |> 
  opt_stylize(style = 1)

emm <- emmeans(lmer.dist.media.pruebas, pairwise ~ tratamientos | prueba)
eff_size(emm, sigma = sigma(lmer.dist.media.pruebas), edf = df.residual(lmer.dist.media.pruebas))
# emmeans(aov.dist.media.pruebas, pairwise ~ tratamientos | prueba, adjust = "tukey",  cov.reduce = FALSE)$contrasts |>
#   as_tibble() |>
#   dplyr::select(-df, -t.ratio) |>
#   dplyr::rename(Estimado = estimate) |>
#   dplyr::filter(p.value <= 0.05) |>
#   tidyr::separate(contrast, into = c("1", "2"), sep = " - ")  |> 
#   gt::gt()  |> 
#   tab_footnote("Comparaciones múltiples ajustadas con Tukey HSD") |> 
#   fmt_number(decimals = 3) |>
#   tab_style_body(
#     style = list(
#                  cell_text(color = "#222831")),
#     values = c("Flx")
#   ) |> 
#   tab_style_body(
#     style = list(
#                  cell_text(color = "#00ADB5")),
#     values = c("(Flx-CUMS)")) |>
#   tab_style_body(
#     style = list(
#                  cell_text(color = "#FF2E63")),
#     values = c(("(Sal-CUMS-F)"))
#     ) |> 
#   opt_stylize(style = 1)
  

```

```{r}
#| echo: false
#| eval: false
lmer.dist.media.pruebas.2 <- lmer(
  distancia_media_blanco ~ prueba + tratamientos + (1 | id),
  data = df.distancia.media.pruebas.flx
)

anova(lmer.dist.media.pruebas, lmer.dist.media.pruebas.2)
```


Para predecir la entropia a partir de la prueba y tratamientos (fórmula: entropia_blanco ~ etapa * tratamiento), ajustamos un modelo lineal mixto (estimado usando REML) . El modelo incluyó a los sujetos como efecto aleatorio (fórmula:~1 | id). El poder explicativo total del modelo es sustancial (R2 condicional = 0.49).  El poder explicativo del modelo es sustancial (R2 condicional = 0.72). La prueba de razón de verosimilitud o *likelihood ratio* ($X^2 (4) = 8.9, p = 0.06$) determinó que la interacción entre `Prueba x Tratamiento` no es significativa. 


```{r entromodelsum}
#| echo: false
#| eval: false

anova(lmerTest::lmer(entropia_blanco ~ stage * tratamiento + (1 | id) + (1 | stage),
  data = entropia_df_filtrado_fluox))

plot_model(entropia.lmer.flx, type = "int")

tbl_regression(entropia.lmer.flx, 
               pvalue_fun = ~ style_pvalue(.x, digits = 3)) %>%
  add_global_p() |> 
  bold_p(t = 0.05) %>%
  bold_labels() %>%
  modify_header(label = "**Variable**") %>%
  as_gt()

tab_model(entropia.lmer.flx)

report(entropia.lmer.flx)
```

```{r}
#| echo: false
#| eval: false
entropia.lmer.flx.2 <- lmer(
  entropia_blanco ~ stage + tratamiento + (1 | tratamiento/id),
  data = entropia_df_filtrado_fluox
)

anova(entropia.lmer.flx, entropia.lmer.flx.2)
```



```{r RegrTabEntropia}
#| echo: false
#| eval: false
#| label: tbl-RegrTabEntropia


sjPlot::tab_model(entropia.lmer.flx, aov.entropia)


# sjPlot::tab_model(lmer.1, aov.1, 
#                   # auto.label = TRUE,
#                   # show.se = T,
#                   show.obs = F,
#                   # show.fstat = T)
#                   # show.reflvl = F, # nivel de referencia para factores
#                   show.intercept = F,
#                   show.r2 = F,
#                   rm.terms = "Residuals",
#                   # show.df = T
#                   p.style = "numeric_stars",
#                   # title = "Latencias Reversa Efectos Mixtos",
#                   string.pred = "Predictores",
#                   string.est = "Estimados",
#                   pred.labels = c("Prueba-2", "Prueba-Rev",
#                                   "Flx-CUMS", "Sal-CUMS-F",
#                                   "Prueba-2 x Flx-CUMS", "Prueba-Rev x Flx-CUMS",
#                                   "Prueba-2 x Sal-CUMS-F", "Prueba-Rev x Sal-CUMS-F",
#                                   "Tratamientos", "Prueba", "Tratamientos x Prueba"
#                   ),
#                   dv.labels = c("Efectos Mixtos lineal", "RM-ANOVA"),
#                   file = "./tablas/entropia_blanco.html"
#                   # string.se = "SEM"
# )

```

```{r PlotEntropialmer}
#| echo: false
#| label: fig-PlotEntropialmer
#| fig-cap: "Medias marginales estimadas para la variable de Entropia al annulus blanco. Graficado con media +- error estándar."

entropia.lmer.flx.emmeans <- emmeans(entropia.lmer.flx,  
                        ~ tratamiento | stage, cov.reduce = FALSE)


entropia.lmer.flx.emmeans.df <- as.data.frame(entropia.lmer.flx.emmeans)

entropia.flx.emmeans.plot <- ggplot(entropia.lmer.flx.emmeans.df,
                    aes(
                      x = stage,
                      y = emmean,
                      group = tratamiento,
                      color = tratamiento
                    )) +
  geom_line(linewidth = 0.3, linetype = "dashed", position = position_dodge(0.1)) +
  geom_point(size = 5.5, position = position_dodge(0.1), shape = 21) +
  # geom_point(size = 7, shape = 21, position = position_dodge(0.1)) +
  geom_pointrange(aes(ymin = emmean-SE, ymax = emmean+SE),
                  size = 0.75, position = position_dodge(0.1)) +
  scale_color_manual(values = c("#222831", "#00ADB5", "#FF2E63", "#FF9800", "#8675A9", "#862B0D")) +
  labs(
    # caption = "Plotted with SEM",
    color = "Tratamientos",
    shape = "Tratamientos",
    x = "Prueba",
    y = "H") +
  # ylim(0, 60) +
  scale_x_discrete(labels=c("prueba_1"="P-1", "prueba_2"="P-2", "prueba_rev"="P-Rev")) +
  # theme_classic()
  # ggthemes::theme_clean() +
  ggthemes::theme_clean() + 
  theme(legend.position='top', axis.text = element_text(size = 12),axis.title = element_text(size = 15)) 

entropia.flx.emmeans.plot


###
###
###

# entropia.emmeans.aov <- emmeans(aov.entropia,  
                        # ~ tratamientos | prueba)


# entropia.emmeans.aov.df <- as.data.frame(entropia.emmeans.aov)
# 
# entropia.aov.flx.emmeans.plot <- ggplot(entropia.emmeans.aov.df,
#                     aes(
#                       x = prueba,
#                       y = emmean,
#                       group = tratamientos,
#                       color = tratamientos
#                     )) +
#   geom_line(linewidth = 0.3, linetype = "dashed", position = position_dodge(0.1)) +
#   geom_point(size = 5.5, position = position_dodge(0.1), shape = 21) +
#   # geom_point(size = 7, shape = 21, position = position_dodge(0.1)) +
#   geom_pointrange(aes(ymin = emmean-SE, ymax = emmean+SE),
#                   size = 0.75, position = position_dodge(0.1)) +
#   scale_color_manual(values = c("#222831", "#00ADB5", "#FF2E63", "#FF9800", "#8675A9", "#862B0D")) +
#   labs(
#     caption = "Plotted with SEM",
#     color = "Tratamientos",
#     shape = "Tratamientos",
#     x = "Prueba",
#     y = "H") +
#   # ylim(0, 60) +
#   scale_x_discrete(labels=c("prueba_1"="P-1", "prueba_2"="P-2", "prueba_rev"="P-Rev")) +
#   # theme_classic()
#   # ggthemes::theme_clean() +
#   ggthemes::theme_clean() + 
#   theme(legend.position='top', axis.text = element_text(size = 12),axis.title = element_text(size = 15)) 

# entropia.aov.flx.emmeans.plot
```

```{r ContrastestEntropialmer}
#| echo: false
#| eval: false
# label: tbl-ContrastestEntropialmer
# tbl-cap: "Contrastes múltiples para las pruebas de entropía."


emmeans(entropia.lmer.flx, pairwise ~ tratamiento | stage, adjust = "none",  cov.reduce = FALSE)$contrasts |>
  as_tibble() |>
  # dplyr::filter(!str_detect(contrast, "K")) |>
  select(-df, -t.ratio, -SE) |>
  dplyr::rename(
    # prueba = dia,
         Estimado = estimate) |>
  dplyr::filter(p.value <= 0.05) |>
  separate(contrast, into = c("1", "2"), sep = " - ") |>
  gt::gt()  |> 
  # tab_footnote("Comparaciones múltiples ajustadas con Tukey HSD") |> 
  fmt_number(decimals = 3) |>
  tab_style_body(
    style = list(
      cell_text(color = "#222831")),
    values = c("Flx")
  ) |> 
  tab_style_body(
    style = list(
      cell_text(color = "#00ADB5")),
    values = c("(Flx-CUMS)")) |>
  tab_style_body(
    style = list(
      cell_text(color = "#FF2E63")),
    values = c(("(Sal-CUMS-F)"))
  ) |> 
  opt_stylize(style = 1)


# emmeans(aov.entropia, pairwise ~ tratamientos | prueba, adjust = "none",  cov.reduce = FALSE)$contrasts |>
#   as_tibble() |>
#   # dplyr::filter(!str_detect(contrast, "K")) |>
#   select(-df, -t.ratio, -SE) |>
#   dplyr::rename(
#     # prueba = dia,
#          Estimado = estimate) |>
#   dplyr::filter(p.value <= 0.05) |>
#   separate(contrast, into = c("1", "2"), sep = " - ") |>
#   gt::gt()  |> 
#   # tab_footnote("Comparaciones múltiples ajustadas con Tukey HSD") |> 
#   fmt_number(decimals = 3) |>
#   tab_style_body(
#     style = list(
#       cell_text(color = "#222831")),
#     values = c("Flx")
#   ) |> 
#   tab_style_body(
#     style = list(
#       cell_text(color = "#00ADB5")),
#     values = c("(Flx-CUMS)")) |>
#   tab_style_body(
#     style = list(
#       cell_text(color = "#FF2E63")),
#     values = c(("(Sal-CUMS-F)"))
#   ) |> 
#   opt_stylize(style = 1)

```

Por último, ajustamos un modelo lineal mixto (estimado usando REML) para predecir el tiempo en cuadrantes a partir de la prueba y tratamientos  (fórmula: tiempo cuadrante ~ prueba * tratamientos * cuadrante). El modelo incluyó a los sujetos como efecto aleatorio (fórmula: ~1 | id). El poder explicativo total del modelo es sustancial (R2 condicional = 0.59). Los cuadrantes corresponden a las divisiones de la @fig-cuadrantes.


::: {#fig-cuadrantes layout-ncol=2}

![Cuadrante original](figuras/wm_cuadrantes.png){#fig-cuadrantenorte}

![Cuadrante reversa](figuras/wm_cuadrante_rev.png){#fig-cuadrantereversa}

Cuadrantes en el Laberinto Acuático de Morris.

:::
La prueba de razón de verosimilitud o *likelihood ratio* ($X^2 (28) = 220.86, p < 0.001$) determinó que la interacción entre `Prueba x Tratamiento x Cuadrante` es significativa. La prueba de comparaciones múltiples (ajustada con Tukey HSD, fórmula `~ tratamientos | prueba | cuadrante`)  indica que en la **Prueba 1**, el grupo de `Sal-CUMS` difiere significativamente del grupo `Flx` ($p = 0.01$) en la preferencia por el cuadrante blanco (annulus original). En la **Prueba reversa**, el grupo `Sal-CUMS` difiere significativamente del grupo `Flx-CUMS` ($p = 0.016$) en la preferencia por el cuadrante blanco original, del grupo `Flx-CUMS` ($p < 0.001$) en la preferencia por el cuadrante Reversa y del grupo  `Flx` ($p < 0.001$) en la preferencia por el cuadrante Reversa. 


```{r}
#| echo: false
#| eval: false
lmer.cuadrantes.2 <- lmer(
  tiempo_cuadrante ~ prueba + tratamientos + cuadrante + (1 | id),
  data = df.cuadrantes.long
)

anova(lmer.cuadrantes, lmer.cuadrantes.2)
```

```{r cuadrmodelsum}
#| echo: false
#| eval: false

anova(lmerTest::lmer(tiempo_cuadrante ~ prueba * tratamientos * cuadrante + (1 | id),
  data = df.cuadrantes.long))

plot_model(lmer.cuadrantes, type = "int")

tbl_regression(lmer.cuadrantes, 
               pvalue_fun = ~ style_pvalue(.x, digits = 3)) %>%
  add_global_p() |> 
  bold_p(t = 0.05) %>%
  bold_labels() %>%
  modify_header(label = "**Variable**") %>%
  as_gt()

tab_model(lmer.cuadrantes)

report(lmer.cuadrantes)
```

```{r CuadTab}
#| echo: false
#| eval: false

sjPlot::tab_model(lmer.cuadrantes)

# sjPlot::tab_model(lmer.2, aov.1$Within,
#                   # auto.label = TRUE,
#                   # show.se = T,
#                   show.obs = F,
#                   # show.fstat = T,
#                   # show.reflvl = T, # nivel de referencia para factores
#                   show.intercept = F,
#                   show.r2 = F,
#                   show.ci = F,
#                   rm.terms = "Residuals",
#                   # show.df = T,
#                   p.style = "numeric_stars",
#                   # title = "Latencias Reversa Efectos Mixtos",
#                   string.pred = "Predictores",
#                   string.est = "Estimados",
#                   # pred.labels = c("Prueba-2", 
#                   #                 "Prueba-Reversa",
#                   #                 "Flx-CUMS", "Sal-CUMS-F",
#                   #                 "Cuadrante-Adyacente-1", "Cuadrante-Adyacente-2", "Cuadrante-Reversa", 
#                   #                 "Prueba-2 x Flx-CUMS", "Prueba-Rev x Flx-CUMS",
#                   #                 "Prueba-2 x Sal-CUMS-F", "Prueba-Rev x Sal-CUMS-F",
#                   #                 "Tratamientos", "Prueba", "Cuadrante",
#                   #                 "Tratamientos:Prueba", "Tratamientos:Cuadrante", "Prueba:Cuadrante",
#                   #                 "Tratamientos:Prueba:Cuadrante"
#                   # ),
#                   dv.labels = c("Efectos Mixtos lineal", "RM-ANOVA"),
#                   file = "./tablas/cuadrantes_fluox.html"
#                   # string.se = "SEM"
# )
```


```{r CuadPlot}
#| echo: false
#| label: fig-CuadPlot
#| fig-cap: "Medias estimadas para los cuatro cuadrantes a lo largo de las tres pruebas. Con linea punteada se marca el tiempo de 15 segundos, el cual representa un 25% del tiempo total en dicho cuadrante (es decir, preferencia por dicho cuadrante). El total de la prueba es de 60 segundos. En la Prueba 1, el grupo de `Sal-CUMS` difiere significativamente del grupo `Flx` ($p = 0.01$) en la preferencia por el cuadrante blanco (annulus original). En la Prueba reversa, el grupo `Sal-CUMS` difiere significativamente del grupo `Flx-CUMS` ($p = 0.016$) en la preferencia por el cuadrante blanco original, del grupo `Flx-CUMS` ($p < 0.001$) en la preferencia por el cuadrante Reversa y del grupo  `Flx` ($p < 0.001$) en la preferencia por el cuadrante Reversa"

cuadrantes.emmeans.lmer <- emmeans(lmer.cuadrantes,  
                        ~ tratamientos | prueba | cuadrante, cov.reduce = FALSE)


cuadrantes.emmeans.lmer.df <- as.data.frame(cuadrantes.emmeans.lmer)

cuadrantes.emmeans.lmer.df$cuadrante = factor(cuadrantes.emmeans.lmer.df$cuadrante, 
                                levels=c("cuadrante_no","cuadrante_ne", 
                                         "cuadrante_so", "cuadrante_se"), 
                                labels = c("Opuesto 1","BLANCO Original", 
                                           "BLANCO Reversa", "Opuesto 2"))


 
library(gghighlight)

cuadrantes.lmer.plot <- ggplot(cuadrantes.emmeans.lmer.df,
                    aes(
                      x = prueba,
                      y = emmean,
                      group = tratamientos,
                      color = tratamientos
                    )) +
  geom_line(linewidth = 0.3, linetype = "dashed", position = position_dodge(0.1)) +
  geom_point(size = 3, position = position_dodge(0.1), aes(shape = tratamientos)) +
  # geom_point(size = 7, shape = 21, position = position_dodge(0.1)) +
  geom_pointrange(aes(ymin = emmean-SE, ymax = emmean+SE),
                  size = 0.75, position = position_dodge(0.1)) +
  scale_color_manual(values = c("#222831", "#00ADB5", "#FF2E63", "#FF9800", "#8675A9", "#862B0D")) +
  facet_wrap( ~ cuadrante, axis.labels = "all_x") +
  gghighlight(emmean > 15, calculate_per_facet = T, use_direct_label = FALSE,
              unhighlighted_params = list(colour = NULL, alpha = 0.3)) +
  geom_hline(yintercept=15, linetype="dashed", color = "#006769", linewidth = 0.6) +
  labs(
    # caption = "Plotted with SEM",
    color = "Tratamientos",
    shape = "Tratamientos",
    x = "Prueba",
    y = "Segundos (s)") +
  ylim(0, 40) +
  # scale_x_discrete(labels=c("entrenamiento_rev_1"="1", "entrenamiento_rev_2"="2")) +
  # theme_classic() +
  # ggthemes::theme_base() +
  ggthemes::theme_clean() +
  # ggthemes::theme_clean() + 
  theme(legend.position='top', axis.text = element_text(size = 12),axis.title = element_text(size = 15)) 




cuadrantes.lmer.plot
```


```{r CuadrantesComps}
#| echo: false
#| eval: false
# label: tbl-CuadrantesComps
# tbl-cap: "Contrastes significativos en Latencias de escape."


emmeans(lmer.cuadrantes, pairwise ~ tratamientos | prueba | cuadrante, adjust = "tukey",  cov.reduce = FALSE)$contrasts |>
  as_tibble() |>
  # dplyr::filter(!str_detect(contrast, "K")) |>
  select(-t.ratio, -SE) |>
  dplyr::rename(
    # prueba = dia,
    Estimado = estimate) |>
  dplyr::filter(p.value <= 0.05) |>
  separate(contrast, into = c("1", "2"), sep = " - ") |>
  gt::gt()  |> 
  tab_footnote("Comparaciones múltiples ajustadas con Tukey HSD") |> 
  fmt_number(decimals = 3) |>
  tab_style_body(
    style = list(
                 cell_text(color = "#222831")),
    values = c("Flx")
  ) |> 
  tab_style_body(
    style = list(
                 cell_text(color = "#00ADB5")),
    values = c("(Flx-CUMS)")) |>
  tab_style_body(
    style = list(
                 cell_text(color = "#FF2E63")),
    values = c(("(Sal-CUMS-F)"))
    ) |> 
  opt_stylize(style = 1)


# emmeans(aov.cuadrantes, pairwise ~ tratamientos | prueba | cuadrante, adjust = "tukey",  cov.reduce = FALSE)$contrasts |> 
#   as_tibble() |>
#   # dplyr::filter(!str_detect(contrast, "K")) |>
#   select(-t.ratio, -SE) |>
#   dplyr::rename(
#     # prueba = dia,
#     Estimado = estimate) |>
#   dplyr::filter(p.value <= 0.05) |>
#   separate(contrast, into = c("1", "2"), sep = " - ") |>
#   gt::gt()  |> 
#   tab_footnote("Comparaciones múltiples ajustadas con Tukey HSD") |> 
#   fmt_number(decimals = 3) |>
#   tab_style_body(
#     style = list(
#                  cell_text(color = "#222831")),
#     values = c("Flx")
#   ) |> 
#   tab_style_body(
#     style = list(
#                  cell_text(color = "#00ADB5")),
#     values = c("(Flx-CUMS)")) |>
#   tab_style_body(
#     style = list(
#                  cell_text(color = "#FF2E63")),
#     values = c(("(Sal-CUMS-F)"))
#     ) |> 
#   opt_stylize(style = 1)
```



## Las métricas y análisis tradicionales del MWM no ajustan correctamente los parámetros

En los entrenamientos, las latencias de escape típicamente son evaluadas por medio de regresiones lineales tradicionales [@young2021] que violan los supuestos de normalidad (@fig-histogramasdensidad), además de subestimar las medias y varianza al no tomar en cuenta los datos censurados (@fig-latenciascensurados).

```{r distribucioneslatencias}
#| echo: false
#| label: fig-histogramasdensidad
#| fig-cap: "Densidad de los valores de latencia (versión suavizada de un histograma). Se observa cómo los datos claramente no siguen una distribución normal. Líneas puntadas marcan la media."
#| fig-subcap: 
#|   - "Entrenamientos Originales"
#|   - "Entrenamientos Reversa"
#| layout-ncol: 2

# mean
library(plyr)

cdat <- ddply(latencias_pre, "tratamientos", summarise, rating.mean=mean(latencia))


latencias_pre |> 
  ggplot(aes(x = latencia, color = tratamientos, fill = tratamientos)) +
  geom_density(alpha = 0.15) +
  geom_vline(data=cdat, aes(xintercept=rating.mean,  colour=tratamientos),
               linetype="dashed", size=1) +
  ylim(0, 0.06) +
  scale_color_manual(values = c("#222831", "#00ADB5", "#FF2E63", "#FF9800", "#8675A9", "#F2AFEF")) +
  scale_fill_manual(values = c("#222831", "#00ADB5", "#FF2E63", "#FF9800", "#8675A9", "#F2AFEF")) +
  labs(
    # title = "Latencias Entrenamientos Originales",
    # caption = "Líneas puntadas marcan la media",
    color = "Tratamientos",
    fill = "Tratamientos",
    x = "Valor de Latencia (s)",
    y = "Densidad") +
  # ggthemes::theme_base() +
  ggthemes::theme_clean() +
  theme(legend.position='top', axis.text = element_text(size = 12),axis.title = element_text(size = 15))


cdatpost <- ddply(latencias_post, "tratamientos", summarise, rating.mean=mean(latencia))


latencias_post |> 
  ggplot(aes(x = latencia, color = tratamientos, fill = tratamientos)) +
  geom_density(alpha = 0.15) +
  ylim(0, 0.06) +
  geom_vline(data=cdatpost, aes(xintercept=rating.mean,  colour=tratamientos),
               linetype="dashed", size=1) +
  scale_color_manual(values = c("#222831", "#00ADB5", "#FF2E63", "#FF9800", "#8675A9", "#F2AFEF")) +
  scale_fill_manual(values = c("#222831", "#00ADB5", "#FF2E63", "#FF9800", "#8675A9", "#F2AFEF")) +
  labs(
    # title = "Latencias Entrenamientos Reversa",
    # caption = "Líneas puntadas marcan la media",
    color = "Tratamientos",
    fill = "Tratamientos",
    x = "Valor de Latencia (s)",
    y = "Densidad") +
  # ggthemes::theme_base() +
  ggthemes::theme_clean() +
  theme(legend.position='top', axis.text = element_text(size = 12),axis.title = element_text(size = 15))



```


::: {#fig-latenciascensurados layout-ncol=2}

![Entrenamientos Originales](figuras/latencias_scatviolin_pre.png){#fig-latenciascencuradospre}


![Entrenamientos Reversa](figuras/latencias_scatviolin_post.png){#fig-scatviolinpost}

Censura de datos en latencias de escape. En la parte superior, el gráfico de dispersión muestra en rojo los datos censurados. En la parte inferior, una alta densidad en la marca de 60 segundos resalta la censura de datos. 
:::

Se compararon las latencias con tres modelos: regresión bayesiana (toma en cuenta datos censurados y distribución gamma), modelo generalizado (distribución Gamma sin datos censurados) y una regresión lineal tradicional (distribución normal sin datos censurados) (@fig-latenciabayesjuntos). Al comparar los tres modelos a partir de distintos criterios de información (@tbl-regbayscomps) [@gelman2014], se comprobó que el modelo bayesiano ajusta mejor los datos, seguido del modelo generalizado y por último el modelo lineal. Estos criterios son evidencia que los estimados obtenidos a partir del modelo bayesiano, seguido del generalizado, serán más confiables que con los otros modelos. Además, el coeficiente de determinación $R^2$ (proporción de la variación en la variable dependiente que puede ser explicado por las variables independientes) también mejora al considerar el modelo Bayesiano (R2 = 0.6), seguido del modelo generalizado (R2 = 0.5) y finalmente el modelo lineal tradicional (R2 = 0.4). Utilizando un algoritmo de Machine Learning de random forest [@ludecke2021] se determinó que la distribución de nuestros datos de latencia tienen una mayor probailidad de seguir una distribución beta (44%), weibull (28%) y gamma (16%). @young2021 sugiere que cualquiera de estas tres distribuciones produce estimados muy similares en la regresión de latencias, aunque sugiere utilizar una distribución gamma para muestras pequeñas. Por último, el índice de correlación de intraclase (*Intraclass correlation*) de 0.89 soporta la alta correlación de nuestros, soportando el uso de efectos mixtos [@chen2017a].

```{r latenciabayesjuntos}
#| echo: false
#| label: fig-latenciabayesjuntos
#| fig-cap: "Medias Marginales Estimadas para obtenidas a partir del Modelo Bayesiano de efectos mixtos tomando en cuenta los valores censurados, Modelo generalizado sin datos censurados, y modelo lineal. Graficados con intervalos de densidad más alta al 66% para resaltar los valores más probables del parámetro."



b1.c_effects_plot <- b1.c_effects_plot  +
  ggplot2::ylim(0,80) +
  theme_classic() +
  scale_color_manual(values = c("#222831", "#00ADB5", "#FF2E63", "#FF9800", "#8675A9", "#862B0D")) +
  scale_fill_manual(values = c("#222831", "#00ADB5", "#FF2E63", "#FF9800", "#8675A9", "#862B0D")) +
  labs(
    # caption = "Plotted with 66% Credible Intervals",
    color = "Tratamientos",
    fill = "Tratamientos",
    shape = "Tratamientos",
    x = "Dia",
    y = "Segundos") +
  theme(legend.position='top', axis.text = element_text(size = 12),axis.title = element_text(size = 15)) +
  scale_x_continuous(labels = c("0", "1", "2", "3", "4"))


b1.ignore_effects_plot <- b1.ignore_effects_plot +
  ggplot2::ylim(0,80)+
  theme_classic() +
  scale_color_manual(values = c("#222831", "#00ADB5", "#FF2E63", "#FF9800", "#8675A9", "#862B0D")) +
  scale_fill_manual(values = c("#222831", "#00ADB5", "#FF2E63", "#FF9800", "#8675A9", "#862B0D")) +
  labs(
    # caption = "Plotted with 66% Credible Intervals",
    color = "Tratamientos",
    fill = "Tratamientos",
    shape = "Tratamientos",
    x = "Dia",
    y = "Segundos") +
  theme(legend.position='top', axis.text = element_text(size = 12),axis.title = element_text(size = 15))  +
  scale_x_continuous(labels = c("0", "1", "2", "3", "4"))


bn_effects_plot <-  bn_effects_plot  +
  ggplot2::ylim(0,80)+
  theme_classic() +
  scale_color_manual(values = c("#222831", "#00ADB5", "#FF2E63", "#FF9800", "#8675A9", "#862B0D")) +
  scale_fill_manual(values = c("#222831", "#00ADB5", "#FF2E63", "#FF9800", "#8675A9", "#862B0D")) +
  labs(
    # caption = "Plotted with 66% Credible Intervals",
    color = "Tratamientos",
    fill = "Tratamientos",
    shape = "Tratamientos",
    x = "Dia",
    y = "Segundos") +
  theme(legend.position='top', axis.text = element_text(size = 12),axis.title = element_text(size = 15)) +
  scale_x_continuous(labels = c("0", "1", "2", "3", "4"))


bay_effect_plots <- b1.c_effects_plot + b1.ignore_effects_plot + bn_effects_plot +
  plot_annotation(tag_levels = 'i') +
  plot_layout(guides = 'collect', axis_titles = 'collect') &
  theme(legend.position = 'top')
#
bay_effect_plots


```

| Modelo          | ELPD      | LOOIC  | WAIC   |
| --------------- | --------- | ------ | ------ |
| Bayes Censurado | \-529.248 | 1058.5 | 1049.7 |
| GLM             | \-629.861 | 1259.7 | 1253.0 |
| Modelo lineal   | \-769.128 | 1538.3 | 1536.0 |
: "Criterios de información para los tres modelos. Expected log predictive density (ELPD), donde un mayor número es lo deseado. Leave-one-out cross-validation information criterion (LOOIC),  donde un valor menor es deseado. Widely applicable information criterion (WAIC), donde un menor valor es deseado. En todos los criterios, el modelo Bayesiano tiene los mejores puntajes, seguido del GLM."  {#tbl-regbayscomps .striped .hover}


Por otro lado, la regresión de Poisson utilizada para modelar las estrategias utilizadas en los entrenamientos es una propuesta que a nuestro conocimiento no se ha utilizado en ningún otro estudio (@fig-poisonplotsEmmeanspost). Otros estudios [@garthe2016; @amelchenko2023b] han utilizado una regresión logística que permite comparar la probabilidad de utilizar más estrategias alocéntricas *versus* estrategias egocéntricas. Sin embargo, este enfoque no permite modelar la tercera variable de perseverancia, un tipo específico de estrategia alocéntrica que además refleja una falta de flexibilidad.  

En cuanto al análisis  de las pruebas, el uso de regresiones con efectos mixtos también presenta ventajas sobre los efectos lineales tradicionales (ANOVA de medidas repetidas). Para modelar la distancia media, incorporar efectos mixtos mejora la normalidad de los residuos (@fig-compsdistmedlemr y @fig-compsdistmedaovs) y la homogeneidad de varianza (@fig-compsdistmedaovsvar y @fig-compsdistmedaovsvar). 

::: {#fig-compsdistmed layout-ncol=2}

```{r compsdistmedlmer}
#| echo: false
#| label: fig-compsdistmedlemr
#| fig-cap: "Residuos del modelo de Distancia Media con efectos Mixtos. Todos los valores están dentro de los intervalos de confianza (95%) de normalidad."


# 
# # Plot a Q-Q plot of residuals
# ggplot(data.frame(sample = residuals_lmer), aes(sample = sample)) +
#   stat_qq() +
#   stat_qq_line(color = "red") +
#   theme_minimal() +
#   labs(title = "Q-Q Plot of Residuals (lmer)")

ggqqplot(residuals(lmer.dist.media.pruebas)) +
  ggthemes::theme_base() +
   labs(
    # caption = "Plotted with SEM",
    # color = "Tratamientos",
    # shape = "Tratamientos",
    x = "Teórico",
    y = "Muestra") +
  theme(
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank()
        )
```

```{r compsdistmedaovs}
#| echo: false
#| label: fig-compsdistmedaovs
#| fig-cap: "Residuos del modelo de Distancia Media con modelo de ANOVA. En los extremos se pueden visualizar valores que no están dentro de los intervalos de confianza (95%) de normalidad."


ggqqplot(residuals(aov.dist.media.pruebas$Within)) +
  ggthemes::theme_base() +
   labs(
    # caption = "Plotted with SEM",
    # color = "Tratamientos",
    # shape = "Tratamientos",
    x = "Teórico",
    y = "Muestra") +
  theme(
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank()
        )
```


```{r compsdistmedlemrvar}
#| echo: false
#| label: fig-compsdistmedlemrvar
#| fig-cap: "Residuos vs valores ajustados del Modelo con Efectos Mixtos. Los residuos están dispersos, sin ningún patrón evidente que sugiera un problema con la homogeneidad de varianza."
# Extract fitted values

# # Extract residuals
residuals_lmer <- resid(lmer.dist.media.pruebas)
fitted_lmer <- fitted(lmer.dist.media.pruebas)

# Plot residuals vs fitted values
ggplot(data.frame(fitted = fitted_lmer, residuals = residuals_lmer), aes(x = fitted, y = residuals)) +
  geom_point(color = "#046582") +
  geom_hline(yintercept = 0, color = "#C86B85") +
  ggthemes::theme_base() +
   labs(
    x = "Valores Ajustados",
    y = "Residuos") +
  theme(
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank()
        )



```


```{r compsdistmedaovsvar}
#| echo: false
#| label: fig-compsdistmedaovsvar
#| fig-cap: "Residuos vs valores ajustados del Modelo de ANOVA de medidas repetidas. Los residuos se ven dispersos sin ningún patrón evidente, aunque no se ven dispersos de manera homogénea."

residuals_aov <- resid(aov.dist.media.pruebas$Within)
# Extract fitted values
fitted_aov <- fitted(aov.dist.media.pruebas$Within)

# Plot residuals vs fitted values
ggplot(data.frame(fitted = fitted_aov, residuals = residuals_aov), aes(x = fitted, y = residuals)) +
  geom_point(color = "#046582") +
  geom_hline(yintercept = 0, color = "#C86B85") +
  ggthemes::theme_base() +
   labs(
    x = "Valores Ajustados",
    y = "Residuos") +
  theme(
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank()
        )
```

Supuestos de los Modelos para la variable de Distancia Media al Annulus en las pruebas del MWM.
:::

En el caso del análisis de cuadrantes, el modelo de efectos mixtos presenta intervalos de confianza más reducidos [@fig-compsdistmedlemrcuads] en comparación del modelo de ANOVA de medidas repetidas [@fig-compsdistmedaovscuads]. Sin embargo, la homogeneidad de varianza no es óptima en ninguno de los modelos [@fig-compsdistmedlemrvarcuads , @fig-compsdistmedaovsvarcuads]

::: {#fig-compscuads layout-ncol=2}

```{r compsdistmedlemrcuads}
#| echo: false
#| label: fig-compsdistmedlemrcuads
#| fig-cap: "Residuos del modelo de Tiempo en cuadrante con efectos Mixtos."


# # Plot a Q-Q plot of residuals
# ggplot(data.frame(sample = residuals_lmer), aes(sample = sample)) +
#   stat_qq() +
#   stat_qq_line(color = "red") +
#   theme_minimal() +
#   labs(title = "Q-Q Plot of Residuals (lmer)")

ggqqplot(residuals(lmer.cuadrantes)) +
  ggthemes::theme_base() +
   labs(
    # caption = "Plotted with SEM",
    # color = "Tratamientos",
    # shape = "Tratamientos",
    x = "Teórico",
    y = "Muestra") +
  theme(
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank()
        )
```

```{r compsdistmedaovscuads}
#| echo: false
#| label: fig-compsdistmedaovscuads
#| fig-cap: "Residuos del modelo de tiempo en cuadrante con ANOVA de medidas Repetidas."
ggqqplot(residuals(aov.cuadrantes$id)) +
  ggthemes::theme_base() +
   labs(
    # caption = "Plotted with SEM",
    # color = "Tratamientos",
    # shape = "Tratamientos",
    x = "Teórico",
    y = "Muestra") +
  theme(
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank()
        )
```


```{r compsdistmedlemrvarcuads}
#| echo: false
#| label: fig-compsdistmedlemrvarcuads
#| fig-cap: "Residuos vs valores ajustados del Modelo con Efectos Mixtos. Los residuos están dispersos, pero se observa un patrón que podría sugerir problemas de heterocedasticidad."
# # Extract residuals
residuals_lmer.cuads <- resid(lmer.cuadrantes)
# 

# Extract fitted values
fitted_lmer.cuads <- fitted(lmer.cuadrantes)

# Plot residuals vs fitted values
ggplot(data.frame(fitted = fitted_lmer.cuads, residuals = residuals_lmer.cuads), aes(x = fitted, y = residuals)) +
  geom_point(color = "blue") +
  geom_hline(yintercept = 0, color = "red") +
  theme_minimal() +
  labs(title = "Residuals vs Fitted Values (lmer)", x = "Fitted Values", y = "Residuals")

```

```{r compsdistmedaovsvarcuads}
#| echo: false
#| label: fig-compsdistmedaovsvarcuads
#| fig-cap: "Residuos vs valores ajustados del Modelo con ANOVA de medidas repetidas. No se observa ningún patrón, aunque tampoco se observa una dispersión homogénea."

residuals_aovs.cuads <- resid(aov.cuadrantes$id)

# Extract fitted values
fitted_aov.cuads <- fitted(aov.dist.media.pruebas$id)

# Plot residuals vs fitted values
ggplot(data.frame(fitted = fitted_aov.cuads, residuals = residuals_aovs.cuads), aes(x = fitted, y = residuals)) +
  geom_point(color = "#046582") +
  geom_hline(yintercept = 0, color = "#C86B85") +
  ggthemes::theme_base() +
   labs(
    x = "Valores Ajustados",
    y = "Residuos") +
  theme(
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank()
        )
```

Supuestos de los Modelos para la variable de Tiempo en cuadrante blanco en las pruebas del MWM.

:::

Por último, en el análisis de la distancia media, el coeficiente de determinación $R^2$ (proporción de la variación en la variable dependiente que puede ser explicado por las variables independientes) mejora al considerar los efectos mixtos (R2 = 0.725) en comparación del modelo de ANOVA de medidas repetidas (R2 = 0.33). En el modelado de los cuadrantes, el modelo con efectos mixtos (R2 = 0.59) también mejora en comparación con el modelo de ANOVA de medidas repetidas (R2 = 0.17).

## Derivación de la fórmula de entropía {#sec-entropiares}

Debido a que el código original de @maei2009 no está disponible ([link original](http://individual.utoronto.ca/kpetrov/Matlab-codes.zip)) desde hace varios años ([ver link](https://web.archive.org/web/20220808114843/http://individual.utoronto.ca/kpetrov/Matlab-codes.zip)), se derivó la formula a partir de la descripción en @maei2009 y @dajun2003. 

El cálculo de las distancias se compone de las coordenadas del animal (`Xraw, Yraw`), las diferencias del animal al punto de referencia (annulus blanco, `d_x, d_y`), el cuadrado de la distancia Euclidiana (`dist2 `), la distancia Euclidiana (`dist`) y el promedia de la distancia ($σ_d$, 'dis_ave'). Con estos parámetros, se calcula la distancia del animal a la plataforma en cada tiempo utilizando la distancia Euclidiana tomando en cuenta las coordenadas del animal ($x_a, y_a$) y de la plataforma planco ($x_b, y_b$).

$$
d = \sqrt{(x_a - x_b) + (y_a - y_b)^2} 
$$ {#eq-Distancia-Euclidiana}



```{r}
#| echo: true
#| eval: false
Xraw <- as.numeric(data$X)
Yraw <- as.numeric(data$Y)
d_x <- Xraw - plat_x
d_y <- Yraw - plat_y
dist2 <- d_x^2 + d_y^2
dist <- sqrt(dist2)
dist_ave <- mean(dist)
```

Las medias ponderadas y la matriz de varianza-covarianza se obtuvo con el siguiente código, donde la matriz de covarianza `Sig` se contruye con las medias ponderadas y la matriz de covarianza de valores Eigen se calcula para obtener la varianza $σ_a^2$ y $𝜎_b^2$. Con estos parámetros vamos a calcular la varianza de los vectores de las distancias del animal respecto a la plataforma.
 
```{r}
#| echo: true
#| eval: false
w <- 1
sw <- sum(w)
xm <- mean(w * d_x) / sw
ym <- mean(w * d_y) / sw
xxm <- mean(w * d_x * d_x) / sw
yym <- mean(w * d_y * d_y) / sw
xym <- mean(w * d_x * d_y) / sw
Sig <- matrix(c(xxm - xm^2, xym - xm * ym, xym - xm * ym, yym - ym^2), nrow=2)
eig_val <- eigen(Sig)$values
var_xy2 <- eig_val[1] * eig_val[2]
```

La matriz de covarianza se utiliza para capturar la vraianza y covarianza de los datos en más de una dimensión. Para el caso de dos dimensiones (coordenadas X y Y), la matriz de covarianza se representa como:

$$
Σ=\begin{pmatrix}
Var(x) & Cov(x,y)\\
Cov(x,y) & Var(y) 
\end{pmatrix}
$$
donde Var(x) representa la varianza de las coordenadas X, Var(y) representa la varianza de las coordenadas Y, y Cov(x,y) representa la covarianza entre las coordenadas de X y Y. Esta matriz de covarianza resume cómo las coordenadas varían entre ellas. Si las coordenadas X y Y están altamente correlacionadas, la covarianza será alta, indicando una relación linear alta. 

Los ejes principales o valores Eigen son las direcciones en las que los datos varían más. Estos ejes se encuentran realizando una descomposición en valores propios de la matriz de covarianza. Los valores propios y los vectores propios obtenidos de esta descomposición tienen las siguientes intepretaciones:

- Valores Propios: Representan la magnitud de la varianza a lo largo de los ejes principales.

- Vectores Propios: Indican la dirección de estos ejes principales.

Estos ejes pueden considerarse como los ejes mayor y menor de una elipse de error que mejor se ajusta a los datos. Ahora, se tiene que sumar los Logaritmos de las varianzas utilizando en el cálculo de la entropía para cuantificar la dispersión o el desorden de los datos en el plano, reflejando el producto de las varianzas a lo largo de los ejes principales

Para caulcular la media de la distancia al cuadrado y calcular la entropía se implementó el siguiente código, donde `mdist2` calcula la media de la distancia al cuadrado ($σ_2^d$). El cáulculo final de entropía se obtiene sumando los logarítmos de las medias cuadradas de la distancia y el producto de los valores Eigen. En resumen, calculamos $H_{error}$ basados en la fórmula $H_{error} = log(varianza_{distancia})$, calculamos la varianza de la trayectoria $var(X_a) + var(Y_a)$, calculamos la entropía de la trayectoria, realizamos la operación $H_{trayectoria} = log(var_{trayectoria})$ y finalmente calculamos la entropía total como $H_{total} = H_{error} + H_{trayectoria}$

```{r}
#| echo: true
#| eval: false
mdist2 <- mean(w * dist2) / sw
entropy <- log(mdist2) + 0.5 * log(var_xy2)

```

En la @fig-plotentropia, se ilustra el proceso del cálculo de entropía.

```{r plotentropia}
#| echo: false
#| label: fig-plotentropia
#| fig-cap: "Ilustración del cálculo de entropía. Los puntos azules representan la posición del animal. Se marca la distancia del animal respecto al punto de referencia (annulus blanco). Estas distancias se utilizan para calcular la matriz de covarianza que determina la forma y orientación del elipse que describe mejor los datos. Los ejes mayores y menores del elipse (derivados de los valores Eigen de la matriz de covarianza) corresponden a los ejes principales de la distribución de nuestros datos. El largo de los ejes de la elipse corresponden a $σ_a^2$ y $𝜎_b^2$. "

# Example data points
Xraw <- c(210, 215, 225, 230, 220, 225, 230, 235)
Yraw <- c(70, 75, 80, 85, 77, 80, 83, 85)
plat_x <- 220
plat_y <- 77

# Calculate differences
d_x <- Xraw - plat_x
d_y <- Yraw - plat_y

# Create a scatter plot
plot(Xraw, Yraw, xlim=c(200, 240), ylim=c(60, 100), xlab="X", ylab="Y", main="Coordenadas del ratón alrededor del annulus blanco")
points(plat_x, plat_y, col="red", pch=19)  # Reference point
text(plat_x, plat_y, labels="Annulus", pos=4, col="red")

# Draw lines from points to reference point
segments(Xraw, Yraw, plat_x, plat_y, col="blue")

# Draw error ellipse
library(car)
data_points <- data.frame(Xraw, Yraw)
ellipse_center <- c(plat_x, plat_y)
cov_matrix <- cov(data_points)
ellipse_centered <- ellipse(ellipse_center, shape=cov_matrix, radius=sqrt(qchisq(0.95, df=2)), col="#00ADB5", center.pch=19)

# Add principal axes
eig <- eigen(cov_matrix)
eig_vec <- eig$vectors
eig_val <- eig$values

# Scale eigenvectors for plotting
scale_factor <- 5
segments(plat_x, plat_y, plat_x + scale_factor * eig_vec[1,1] * sqrt(eig_val[1]), plat_y + scale_factor * eig_vec[2,1] * sqrt(eig_val[1]), col="#222831")
segments(plat_x, plat_y, plat_x + scale_factor * eig_vec[1,2] * sqrt(eig_val[2]), plat_y + scale_factor * eig_vec[2,2] * sqrt(eig_val[2]), col="#222831")

```


Para validar la métrica, se obtuvo el coeficiente de correlación (r) de los cálculos de entropía con otras métricas del MWM. Los resultados expresan una correlación alta entre nuestra métrica de entropía y las otras métricas clásicas del MWM @tbl-entropiacor.


|                     | Entropia |
| ------------------- | -------- |
| Distancia Media     | 0.97     |
| Tiempo en Zona      | 0.94     |
| Tiempo en Cuadrante | 0.85     |
: "Coefieciente de Correlación de entropía con otras métricas del MWM."  {#tbl-entropiacor .striped .hover}

Por último, se presenta el código para calcular la entropía del MWM traducido en Python:

```{python}
#| eval: false
#| echo: true

import os
import pandas as pd
import numpy as np

def wm_entropy_NE(dir):
    # Lista de archivos CSV en el directorio especificado que contienen "prueba" en su nombre
    csv_files = [os.path.join(dir, file) for file in os.listdir(dir) if "prueba" in file]
    
    entropy_data = []

    # Función para procesar cada archivo CSV
    def process_file(file):
        # Leer el archivo CSV
        data = pd.read_csv(file)
        
        # Limpiar nombres de columnas y renombrar columnas específicas
        data.columns = data.columns.str.lower().str.replace(' ', '_')
        data.rename(columns={'time_s': 'time', 'centre_position_x': 'x', 'centre_position_y': 'y'}, inplace=True)
        
        # Asignar puntos de referencia
        plat_x = 220
        plat_y = 77

        # Convertir columnas x e y a numpy arrays
        Xraw = data['x'].to_numpy()
        Yraw = data['y'].to_numpy()

        # Calcular las diferencias respecto a los puntos de referencia
        d_x = Xraw - plat_x
        d_y = Yraw - plat_y

        # Calcular la distancia euclidiana al cuadrado y la distancia euclidiana
        dist2 = d_x**2 + d_y**2
        dist = np.sqrt(dist2)
        
        # Calcular la distancia promedio
        dist_ave = np.mean(dist)

        # Inicializar el peso w
        w = 1
        sw = np.sum(w)

        # Calcular las medias ponderadas para d_x y d_y
        xm = np.mean(w * d_x) / sw
        ym = np.mean(w * d_y) / sw
        xxm = np.mean(w * d_x * d_x) / sw
        yym = np.mean(w * d_y * d_y) / sw
        xym = np.mean(w * d_x * d_y) / sw

        # Construir la matriz de covarianza
        Sig = np.array([[xxm - xm**2, xym - xm * ym],
                        [xym - xm * ym, yym - ym**2]])

        # Calcular los valores propios de la matriz de covarianza
        eig_val = np.linalg.eigvals(Sig)
        var_xy2 = eig_val[0] * eig_val[1]

        # Calcular la media ponderada de las distancias al cuadrado
        mdist2 = np.mean(w * dist2) / sw

        # Calcular la entropía
        entropy = np.log(mdist2) + 0.5 * np.log(var_xy2)

        # Añadir la entropía calculada a la lista de datos de entropía
        entropy_data.append({'entropy': entropy})

    # Aplicar la función a cada archivo CSV
    for file in csv_files:
        process_file(file)

    # Convertir la lista de datos de entropía en un DataFrame de pandas
    entropy_df = pd.DataFrame(entropy_data)
    
    return entropy_df

# Ejemplo de uso:
# dir_path = "ruta/al/directorio"
# result = wm_entropy_NE(dir_path)
# print(result)

```


# Discusión

Los resultados obtenidos en nuestro estudio proporcionan evidencia sobre el impacto de la fluoxetina en la flexibilidad cognitiva en ratones sometidos a estrés crónico. Utilizando varias métricas sensibles al aprendizaje espacial, presentamos evidencia que indican que la fluoxetina facilita el reaprendizaje reversa en el MWM en nuestro modelo de estrés crónico.   

## Efectos del Estrés Crónico y la Fluoxetina sobre la Flexibilidad Cognitiva Dependiente del Hipocampo

Uno de los hallazgos más importantes de este estudio es la demostración de que el estrés crónico induce deficiencias significativas en la flexibilidad cognitiva de los ratones. Los ratones sometidos a estrés crónico mostraron una disminución en su capacidad para adaptarse a nuevas configuraciones del laberinto, tal como se observa en las mayores latencia de escape en el primer día de la prueba (@fig-bayeslatenciasplotspost), una prevalencia mayor de perseverancia al annulus original (@fig-porcentajesEstrategiasPlots), una distancia promedio mayor al annulus reversa (@fig-DMedPlotEmmeanPruebas) y un menor tiempo en el cuadrante del annulus reversa y mayor tiempo en el annulus original (@fig-CuadPlot). 

El uso de métricas que evalúen específicamente la relevancia del hipocampo en el aprendizaje del MWM sugieren que existe una alteración en la función hipocampal, la cual es crucial para la flexibilidad cognitiva y el aprendizaje espacial.

La menor distancia media al annulus en la prueba reversa (@fig-DMedPlotEmmeanPruebas) para los grupos de Flx y Flx-CUMS, en comparación con el grupo Salina-CUMS, es evidencia que estos grupos "reaprenden" mejor la localización de la plataforma reversa. Esto se evidencía cuando comparamos el mapa de calor (@fig-salinaCUMSfMapa) del grupo de salina contra los grupos de fluoxetina. En conclusión, el tratamiento con fluoxetina parece prevenir la falta de flexibilidad cognitiva que observamos en el grupo de Salina cuando hay un protocolo de estrés crónico. De acuerdo a @garthe2016, esta flexibilidad cognitiva en el MWM está asociada a la integridad del hipocampo y potencialmente a la neurogénesis hipocampal adulta. 

De manera interesante, se observa que en la prueba 2 (@fig-DMedPlotEmmeanPruebas), los ratones del grupo de FLX-CUMS presentan una mayor distancia promedio al annulus blanco en comparación con los otros dos grupos. Debido a que muchas investigaciones [@akers2014; @epp2016; @scott2021; @lopez-oropeza2022] reportan que un aumento en neurogénesis induce interferencia en memorias dependientes del hipocampo, observadas como un olvido, es plausible que la neurogénesis hipocampal esté jugando un papel en este fenómeno. Además, el olvido se ha asociado con la hipótesis neurogénica de "limpieza de memorias" [@anacker2017], un fenómeno que facilita el reaprendizaje y la flexibilidad cognitvia [@akers2014; @epp2016].  


Por otro lado, también se cuantificó la entropía en las pruebas, definida como la incertidumbre con la que se conoce una variable. Esta incertidumbre reduce con información (aprendizaje). En este sentido, una certidumbre de "0" significaría que el ratón pasó todo el tiempo en la localización de la plataforma blanco. Por otro lado, si el ratón exploró todo el laberinto acuático durante la prueba, la entropía sería máxima. Esta métrica describe el grado en que la búsqueda se centra en la localización de la plataforma, así cómo el enfoque de esta búsqueda. Los roedores tienden a mejorar el enfoque de la búsqueda (más organizada) para localizar la plataforma cuando aprenden mejor.  

Al analizar las pruebas con esta métrica, no se detectó una diferencia en las medias marginales en la prueba reversa. Sin embargo, como señala @meenakshi2022, esta métrica evalúa más el grado de dispersión en la prueba, más que el grado de localización (como la distancia media) en la prueba. Es decir,  este parámetro estima el grado de "organización" en el rendimiento del MWM y no específicamente una propiedad espacial o de navegación. @smaldino2015 señala que la interpretación de la entropía en pruebas de aprendizaje se complica cuando se introduce más de una opción (más de un blanco en nuestro caso). En estos casos, un aumento de entropía podría significar cambios en los patrones de conducta que lleven al animal a tomar nuevas estrategias una vez que se identificó que la plataforma no está presente, más que una falta de aprendizaje. Debido a que muy pocos artículos exploran esta métrica (y hasta nuestro conocimiento ninguno en el contexto de aprendizaje reversa posterior a un protocolo de CUMS), es difícil comparar e interpretar nuestros resultados. 

Por último, evaluamos el tiempo que el roedor pasa en el cuadrante blanco (@fig-cuadrantes) ya que es la métrica más utilizada para analizar el aprendizaje en el MWM [@garthe2013]. Sin embargo, no es la métrica más sensible para representar el aprendizaje, como lo es la distancia media al annulus [@maei2009a]. 
Analizando esta métrica, se observa un olvido paulatino en la preferencia del Blanco original, en especial en los grupos de Flx (@fig-CuadPlot). Para la prueba reversa, el grupo de Salina-CUMS es el único que sigue presentando una preferencia por el cuadrante original, es decir, muestra perseverancia. Por otro lado, solo los grupos de Flx y Flx-CUMS presentan una preferencia por el blanco reversa en la prueba reversa, resaltando de nuevo que estos grupos presentan una mayor flexibilidad cognitiva. 


En resumen, los ratones tratados con fluoxetina mostraron una mejora notable en estas tareas en comparación con los ratones estresados no tratados. Estos resultados sugieren que la fluoxetina tiene un efecto mitigador sobre las alteraciones cognitivas inducidas por el estrés, restaurando en gran medida la flexibilidad cognitiva dependiente del hipocampo. Esto apoya la hipótesis de que la fluoxetina puede contrarrestar los efectos negativos del estrés crónico en las funciones cognitivas.

## Desarrollo de Modelos Efectivos en Neurociencia Cognitiva


El presente estudio también contribuye significativamente al desarrollo de modelos más efectivos en neurociencia cognitiva. Al utilizar el Laberinto Acuático de Morris como herramienta principal para evaluar la flexibilidad cognitiva, hemos podido establecer un protocolo robusto para medir los efectos del estrés y la intervención farmacológica en un contexto controlado. Los resultados obtenidos proporcionan una base para futuras investigaciones sobre los mecanismos neurobiológicos subyacentes en el estrés crónico y su impacto sobre la flexibilidad cognitiva.

Además, la implementación de la fluoxetina como tratamiento ha permitido observar cómo los antidepresivos pueden influir en procesos cognitivos específicos. Esto abre nuevas vías para explorar cómo otros fármacos pueden modular la plasticidad sináptica y la función cognitiva en condiciones de estrés. Así, nuestros hallazgos no solo tienen implicaciones para la investigación básica, sino que también pueden informar el desarrollo de tratamientos clínicos más efectivos para trastornos relacionados con el estrés.

### Regresión bayesiana con efectos mixtos y datos censurados

La latencia de escape es una de las métricas más utilizadas para evaluar el aprendizaje en el laberinto acuático de Morris MWM. Esta métrica es crucial para evaluar el aprendizaje en el MWM, dado que a medida que los roedores aprenden la ubicación de la plataforma oculta, el tiempo requerido para alcanzarla se reduce, evidenciando una menor latencia [@garthe2013]. No obstante, esta métrica no considera si el aprendizaje observado depende específicamente del hipocampo, como señalan estudios anteriores [@developments_morris_1984].

Además, los métodos estadísticos comúnmente empleados para analizar esta métrica no siempre son los más adecuados para modelar adecuadamente el comportamiento de los roederes [@young2021]. Como demostramos en este estudio (@tbl-regbayscomps), se puede mejorar el modelado estadístico de esta métrica tomando en cuenta los siguientes supuestos: 

i.   Al utilizar un modelo de efectos mixtos, se toma en cuenta que los datos de un mismo día para un mismo animal, así como los datos de un animal a lo largo de los días, están altamente correlacionados.
i.   Utilizar una distribución no normal (@fig-histogramasdensidad) mejora el ajuste de los datos, permitiendo tener mejores estimados sobre las medidas de tendencia central. Como consecuencia, las comparaciones  entre grupos serán más precisas.
i.   Al utilizar una regresión bayesiana, se considera la censura de datos que se produce cuando se alcanza el valor límite de $60$ segundos [@fig-scatviolinpost]. Esta censura subestima la media y la varianza, lo que conlleva a una disminución artificial en las latencias reportadas.

En los primeros días del entrenamiento, todos los grupos experimentales tienen valores censurados que disminuyen con cada día del entrenamiento (@fig-latenciascencuradospre). Por otro lado, el grupo de `Salina+CUMS` parece tener una mayor proporción de datos censurados en el primer día de entrenamientos reversa (@fig-scatviolinpost). Cuando se comparan los tres modelos analizados (@fig-latenciabayesjuntos), se evidencía que tomar en cuenta los datos censurados resalta una diferencia en el aprendizaje en el primer día de la prueba [@tbl-regbayscomps]. Sin ambargo, para el segundo día todos los ratones aprenden de manera similar. Esto indica que todos los grupos tienen un aprendizaje en la prueba, aunque no podemos concluir si este aprendizaje es dependiente del hipocampo. 

### Estrategias de búsqueda y modelo generalizado

Desde 1982, @place_morris_1982 entendía las limitaciones de utilizar las latencias de escape como una medida del aprendizaje espacial. En este artículo, Morris y colaboradores removieron por aspiración el hipocampo ventral y dorsal de ratas y observaron que estos animales, aunque aprendían la localización de la plataforma con el tiempo (menor latencia de escape), tomaban rutas menos directas hacia la plataforma en comparación de los controles. Para tratar de evaluar si el aprendizaje en los entrenamientos tenía un componente espacial, @developments_morris_1984  desarrollaron un sistema de análisis de la ruta de escape que cuantificaba la direccionalidad de la búsqueda (ángulo hacia la plataforma). Utilizando ratones con lesiones hipocampales y corticales, este artículo identificó que el aprendizaje espacial podía ser evaluado con la direccionalidad de la trayectoria del animal: a medida que el aprendizaje espacial mejoraba, el animal tomaba una direccionalidad más precisa hacia la plataforma (una linea recta). 

Navegar por un nuevo entorno requiere varios procesos neurológicos, como prestar atención a los puntos de referencia, mapear su organización espacial relativa al agente, fijarse en una ubicación objetivo y trazar la mejor trayectoria espacial para alcanzarla. Las subregiones del hipocampo desempeñan roles distintos clave en tales procesos computacionales. El hipocampo desempeña un papel crucial en el aprendizaje espacial **alocéntrico**, que implica comprender las relaciones espaciales entre objetos de manera independiente del punto de vista. Las células de lugar (neuronas que se activan preferencialmente en respuesta a una localización) en el hipocampo crean mapas cognitivos (representaciones mentales estructuradas) que permiten la navegación y orientación espacial [@okeefe1990]. Además, las regiones CA3 y CA1 del hipocampo son esenciales para codificar y recuperar información espacial. En resumen, el hipocampo integra información de la corteza entorrinal y parahipocampal, procesa tanto la navegación basada en la ruta como la actualización del mapa cognitivo mediante la integración del movimiento propio [@sharpening_berdugovega_2023]. Daños en el hipocampo, como en la enfermedad de Alzheimer o en el estrés crónico, afectan negativamente la capacidad de aprender y recordar mapas espaciales [@robins2022].

Este papel del hipocampo en la capacidad de los roedores para resolver el laberinto de agua mediante la construcción de un mapa espacial alocéntrico está bien establecido [@eichenbaum1990]. Además, existe eviedencia que en el MWM, las neurogénesis hipocampal adulta mejora el rendimiento de tareas dependientes del hipocampo [@dupret2008], como el uso de estas estrategias alocéntricas [@garthe2016]. Por ejemplo, en un estudio, @garthe2009 suprimieron la neurogénesis adulta con temozolomida en ratones y evaluaron su rendimiento en una tarea del laberinto acuático de Morris, observando un déficit de aprendizaje altamente específico. Los ratones tratados con este fármaco mostraron limitaciones en adoptar estrategias de búsqueda espacialmente precisas, destacando el papel crucial de las nuevas neuronas en la flexibilidad y precisión del aprendizaje espacial. Estos hallazgos subrayan la importancia de las células granulares adultas en la generación de mapas métricos del entorno y vinculan directamente la plasticidad celular del hipocampo con la funcionalidad cognitiva. 

A pesar de la importancia de evaluar las estrategias de búsqueda para evaluar la función del hipocampo, históricamente ha sido difícil de evaluar esta métrica [@wolfer1992]. A finales de la década pasada, el grupo de Garthe y Kempermann [@garthe2009] definieron patrones de búsqueda que los ratones utilizan para encontrar la plataforma en el MWM durante los entrenamientos [@fig-entEstrategias].  En la revisión de @garthe2013, se presenta evidencia que señalan una fuerte asociación entre el uso de estrategias alocéntricas y la integridad del hipocampo. En cambio, en la navegación egocéntrica, 
los ratones con lesiones al hipocampo pueden aprender la localización de la plataforma utilizando señales internas que dependen de su propia posición [@grech2018]. De este modo, el análisis de las estrategias de búsqueda desarrolladas por los roedores durante el aprendizaje en el laberinto acuático de Morris es un parámetro adecuado para evaluar el aprendizaje espacial dependiente del hipocampo [@hernandez-mercado2022].

El uso de nuestro modelo de regresión de Poisson con efectos mixtos represnta un análisis estadístico novedoso que permite analizar los patrones en el uso de estrategias a través de los días. A diferencia de otros enfoques similares [@garthe2016; @amelchenko2023b], nuestro modelo permite diferenciar entre estrategias egocéntricas, alocéntricas y perseverancia.
 
A pesar de que la prueba Omnibus del modelo (análisis de varianza tipo III con método de Satterthwaite), sólamente detectó una interacción significativa entre el día y el tipo de estrategias (F(1,164)=43.33, p<0.001), sigue siendo valioso analizar los patrones que encontramos en el entrenamiento reversa (@fig-poisonplotsEmmeanspost).

i. En un principio, los grupos con estrés adoptan menos estrategias alocéntricas. Sin embargo, para el segundo día todos los tratamientos son similares. Algo similar ocurre con las estrategias egocéntricas. Esto es relevante ya que el uso de estrategias alocéntricas está relacionado con la integridad del hipocampo y la  neurogénesis hipocampal adulta [@garthe2016], la cual permite integrar un mapa cognitivo de manera más eficiente [@garthe2009]. Por otro lado, la navegación egocéntrica depende principalmente del lóbula parietal [@miniaci2018].
i. Los grupos de Flx tienen menos incidencia de la perseverancia a comparación del grupo de salina. La perseverancia es una forma de evaluar la falta de flexibilidad cognitiva al no poder adaptarse al nuevo ambiente [@garthe2016].

Como señala @amelchenko2023, la evidencia del daño hipocampal en el uso de estrategias es más evidente cuando las pruebas son más complejas, por ejemplo, al introducir un segundo protocolo de aprendizaje reversa. En otro artículo, @amelchenko2023b introduce un protocolo de MWM que añade una prueba de reconocimiento contextual después del protocolo de reversa, evidenciando más el papel de las nuevas neuronas en el uso de estrategias alocéntricas y el reconocimiento de contextos novedosos. Otros autores han llegado a una conclusión similar [@garthe2016] cuando se introduce un segundo protocolo reversa. Como señala @garthe2013, es probable que el papel de la neurogénesis en el MWM solo sea relevante cuando el procesamiento de información sea lo suficientemente demandante. En conclusión, en futuros experimentos se podría incorporar un segundo protocolo de aprendizaje reversa para evaluar si la complejidad agregada tiene un impacto sobre el uso de estrategias alocéntricas en el MWM. 

### Métricas específicas para el aprendizaje espacial en el MWM en las Pruebas

El análisis de las tres pruebas del laberinto (adquisición, retención y aprendizaje reversa) se puede realizar con distintas métricas. De acuerdo a @maei2009a, las medidas más utilizadas, en orden, son: porcentaje de tiempo en cuadrante blanco (4 cuadrantes), porcentaje de tiempo en zona blanco (definida como un círculo alrededor de la localización de la plataforma) y número de cruces (cruces alrededor de la localización de la plataforma). Sin embargo, los parámetros que reflejan con mayor precisión el desempeño en estas pruebas son: distancia promedio al annulus blanco y entropía de Shannon [@maei2009]. 

En este trabajo, derivamos la ecuación de entropía propuesta por @maei2009 y se presenta una explicación del código (@sec-entropiares). Se presenta el código en R y python para facilitar, promover y expandir el uso de esta métrica que puede ser muy útil, pero la falta de su uso, en parte a que el código original no se encuentra disponible, dificulta entender y comparar nuestros resultados. 

La métrica más utilizada, tiempo en cuadrantes, es difícil de modelar estadísticamente debido a que el tiempo pasado en los 4 cuadrantes no es homogéneo, generando heterocedasticidad y problemas en la normalidad de los residuos [@maugard2019]. Esto lo comprobamos en @fig-compscuads. Para tratar de lidiar con estos problemas y obtener mejores estimados de las medias, se utilizó un modelo con efectos mixtos, el cual es más robusto a la violación de estos supuestos [@schielzeth2020].  

En el análisis de la distancia media, el uso de un modelo de efectos mixtos mejoró la normalidad de los residuos y la heterocedasticidad [@fig-compsdistmed]. Esto se debe a que el ANOVA tradicionalmente utilizado en este análisis no ajusta los efectos aleatorios ni la estructura anidada-jerárquica de nuestro diseño. Por esto, la variabilidad inherente de los sujetos a través del tiempo en función de su tratamiento puede influenciar la variable de respuesta, generando residuos no normales y heterocedasticidad. Por otro lado, los modelos de efectos mixtos incorporan explicitamente los efectos aleatorios en el modelo y modelan mejor la variable de respuesta al corregir por las fuentes de variación (variabilidad de los sujetos y su respuesta en el tiempo). Como resultado, vemos una mejora en la normalidad de los residuos y la homogeneidad de varianza, siempre y cuando incorporemos los modelos aleatorios de manera correcta. 

Un fenómeno similar se observa en el análisis del tiempo en cuadrantes (@fig-compscuads), donde los residuos del modelo de efectos mixtos presentan intervalos de confianza (95%) más estrechos (@fig-compsdistmedlemrcuads) en comparación del ANOVA de medidas repetidas (@fig-compsdistmedaovscuads), sugiriendo que los residuos siguen más de cerca una distribución normal. Al incorporar los efectos mixtos, estamos capturando mejor la estructura de nuestros datos. Sin embargo, como señala @maugard2019, el análisis de esta prueba es difícil con cualquier análisis. Esta evidencia recalca la importancia de utilizar mejores métricas para el análisis del MWM, como la distancia media, la cual no solo cumple con los supuestos de los modelos (@fig-compsdistmed), sino que es más sensible para detectar diferencias en el aprendizaje espacial [@maei2009]. 

Otra ventaja de utilizar los modelos de efectos mixtos es que no son sensibles a diseños no balanceados (muestras desiguales entre los grupos) ya que no depende de la igualdad de varianzas y normalidad entre los grupos (como el ANOVA). 

Por último, si un dato de un ratón se pierde en el registro, los modelos de ANOVA suelen eliminar todos los datos asociados a ese sujeto ya que no pueden modelar datos faltantes de manera adecuada. En cambio, los modelos de efectos mixtos no tienen este problema. Ya que en nuestro diseño experimental se llega a perder datos de un animal por diversas razones (problemas con la cámara de registro, problemas con el software, muertes debidas al estrés crónico en las últimas etapas), el uso de estos modelados presenta una gran ventaja ya que no perdemos datos y podemos tener un análisis con más registros.


### Perspectivas y limitaciones

Nuestro diseño teóricamente se vería beneficiado si incorporamos un grupo experimental adicional (Salina sin CUMS). Este grupo permitiría simplificar la interpretación de los modelos estadísticos al separar los efectos de la fluoxetina y salina del estrés. Sin embargo, el modelo actual presenta ventajas. Al tener menos factores, tratamiento y tiempo, en lugar de tiempo, inyección (salina o fluoxetina), y estrés (CUMS y no CUMS), tenemos un modelo más simple y fácil de interpretar. Al tener menos interacciones, el modelo es más facil de ajustar, en especial con una *n* pequeña, aumentando el poder estadístico y los parámetros estimados. La desventaja es que es complicado aislar el efecto del estrés de la inyección (salina o fluoxetina). 

Incorporar un buen control puede mejorar la estimación de los efectos de las variables de respuesta si reduce los errores estándar. Sin embargo, si se selecciona un control inadecuado, los estimados del modelo no serán confiables [@wysocki2022]. Como menciona @wysocki2022, si se desea identificar un efecto causal debemos de remover variables que puedan introducir efectos espurios.

De acuerdo a este último punto, surge la preocupación de utilizar el grupo de Salina sin CUMS y que no repsente un buen control. La cepa que utilizamos (C57BL6/J x BALB/c) proviene de una cepa muy resistente al estrés (C57BL6) y otra muy suceptible al estrés (BALB/c) [@palumbo2009]. A pesar de que en condiciones normales tienen un buen desempeño en una prueba de aprendizaje espacial (laberinto radial) [@roullet1995], esta cruza tiene una suceptibilidad al estrés y ansiedad similar a la cepa BALB/c [@corder2023].

@dupreez2020 reportó que en ratones BALB/c, inyectar salina por 6 semanas producía un fenotipo de ansiedad en estos ratones, aumentaba la reactividad a corticoestona y reducía la diferenciación neuronal en el giro dentado. De manera similar, @drude2011a encontraron que 5 días de inyecciones de un vehículo no tóxico aumentaba la conectración de corticosterone en plasma en ratones BALB/c. Estos resultados indican que aún cuando se inyecta de manera predecible un agente no tóxico, esta cepa no se habitúa ni se sensibiliza al estrés [@zamora-gonzalez2013]. Por otro lado, en otra investicación [@norcross2008a], se encontró que administrar fluoxetina por vía intraperitoneal por 4 semanas no induce conductas de tipo depresivas ni ansiosas en raontes C57BL/6 y BALB/c.

De acuerdo a estos estudios, es probable que introducir el grupo de Salina-No-CUMS produzca más desventajas que ventajas al no ser un buen control. Las hormonas de estrés liberadas por los estados de ansiedad pueden impactar directamente al hipocampo, la NHA en el GD y las funciones cognitivas [@li2024]. Como consecuencia, nuestros modelos estadísticos se podrían ver altamente afectados, dificultando encontrar una relación entre los estados de ansiedad y el efecto de los tratamientos sobre las pruebas del MWM.

Otro problema que menciona @hunermund2023, es utilizar controles "endógenos", los cuales están altamente correlacionados y producen sesgos en los estimados. En el modelo con el grupo de Salina sin CUMS, podríamos esperar una alta correlación entre la inyección y el CUMS (fluoxetina siempre mejora el CUMS, y los grupos de salina siempre empeoran con el CUMS). Además, si la variable de inyección (salina o fluoxetina) y estrés (CUMS y no CUMS) presentan una alta correlación, se va a introducir multicolinealidad en los modelos. A pesar de que un modelo con alta colinealidad puede ser utilizado, estos modelos introducen estimados de los coeficientes inestables. 

Como sugiere @li2021b, una de las metas de los experimentos y modelados estadísticos es que tenga aplicaciones prácticas, por lo que tener estimados precisos puede ser más valioso que controlar para efectos si estos añaden sesgos y estimados menos precisos. El estadístico @rubin2005 sugiere que se prefiere tener un modelo sin variables controles que puedan introducir interpretaciones erróneas que compliquen la identificación de verdaderas relaciones causales. 

Gracias al uso de un modelo con efectos mixtos, podemos modelar la estructura de nuestro diseño con componentes de interacción (o "cruzados"), tratamiento y tiempo, y de factores aleatorios (o anidados), como los sujetos dentro de los tratamientos. Esto significa que podemos estimar la relación entre el tiempo (pruebas y entrenamientos del MWM) y cómo cambian las variables predictoras dependiendo del tratamiento. A pesar de las limitaciones, podemos comparar y concluir que la fluoxetina tiene un efecto sobre el estrés a través de los distintos entrenamientos/pruebas del MWM, aunque no podemos aislar el efecto del estrés de la inyección (salina o fluoxetina). 




# Conclusión


En conclusión, nuestro estudio ha proporcionado evidencia que la fluoxetina puede mitigar las deficiencias en la flexibilidad cognitiva inducidas por el estrés crónico en ratones. Estos resultados tienen importantes implicaciones tanto para la comprensión de los mecanismos neurobiológicos del estrés y la cognición como para el desarrollo de intervenciones terapéuticas. Nuestro protocolo en el Laberinto Acuático de Morris refuerza la validez de este modelo para estudios futuros y subraya la importancia de continuar investigando cómo los tratamientos farmacológicos pueden aliviar las alteraciones cognitivas relacionadas con el estrés.

El estrés crónico dificulta el reaprendizaje en la prueba de reversión del Laberinto Acuático de Morris, indicando que la capacidad para generar una respuesta flexible se ve afectada. El tratamiento con fluoxetina previene esta falta de flexibilidad en los grupos de estrés en comparación con el grupo de salina.

El uso de métricas específicas para evaluar el aprendizaje espacial proporciona una mejor comprensión del papel del hipocampo en la conducta y la flexibilidad cognitiva, aunque un análisis histológico es necesario para confirmar y soportar estos datos. A pesar de que tenemos evidencia conductual de que esto podría estar relacionado con la dinámica e integridad del hipocampo, falta confirmación por parte de la inmunohistoquímica. De la misma manera, falta confirmación inmunohistoquímica para hacer conclusiones más robustas sobre las bases de estos fenómenos y determinar si la neurogénesis hipocampal está implicada en estos efectos.

Utilizar modelos novedosos, como la regresión bayesiana, la regresión de Poisson y los modelos de efectos mixtos, permite entender mejor la conducta y los procesos de aprendizaje al generar mejores estimaciones en la prueba, ya que modelan mejor los diseños con variables que se repiten en el tiempo, con variabilidad entre los sujetos, y la relación entre las variables predictoras y de respuesta, como se mostró en todas las métricas utilizadas.

En resumen, nuestros hallazgos resaltan el potencial de la fluoxetina para contrarrestar los efectos negativos del estrés crónico en la flexibilidad cognitiva y subrayan la necesidad de continuar explorando tanto las bases neurobiológicas de estos efectos como las metodologías analíticas que mejoren la interpretación de los datos conductuales y cognitivos. 


### Literatura Citada

::: {#refs}
:::