---
title: "Caracterización de los efectos de la Fluoxetina sobre el aprendizaje espacial y la flexibilidad cognitiva en un modelo de estrés crónico en ratón"
# subtitle: ""
# description: ""
# abstract: |
#     El estrés crónico tiene efectos profundos sobre distintos aspectos de la cognición, incluyendo la flexibilidad cognitiva dependiente del hipocampo (Tafet y Nemeroff, 2016). Estos impactos cognitivos pueden ser estudiados en modelos de roedores utilizando el Laberinto Acuático de Morris (MWM) (Hernández-Mercado y Zepeda, 2022).  Sin embargo, estos estudios han dependido predominantemente del análisis de métricas y métodos estadísticos que no necesariamente modelan la relación entre el estrés crónico y la flexibilidad cognitiva dependiente del hipocampo. Aunque estos métodos han aportado valiosas perspectivas, sus limitaciones para manejar conjuntos de datos biológicos complejos son cada vez más reconocidos. Esta problemática se observa en la creciente literatura que no ha logrado encontrar una relación clara entre el estrés crónico, mecanismos cognitivos afectados a nivel de hipocampo y el efecto antidepresivo de fármacos como fluoxetina (David et al., 2009). Este estudio explora las ventajas de utilizar técnicas de análisis que modelen mejor la relación para el estudio de la flexibilidad cognitiva. A través de un análisis comparativo que involucra a ratones sometidos a estrés crónico y tratamiento farmacológico con fluoxetina, demostramos cómo estos enfoques pueden proporcionar interpretaciones más matizadas de los datos, acomodando la variabilidad individual y la estructura jerárquica de los diseños experimentales comúnmente utilizados en esta área. Nuestros hallazgos revelan que estos enfoques no solo ofrecen una mayor flexibilidad y precisión predictiva, sino que también mejoran la comprensión de los efectos cognitivos del estrés y la eficacia de posibles intervenciones. Al integrar metodologías estadísticas avanzadas con protocolos experimentales rigurosos, esta investigación contribuye al perfeccionamiento de los modelos de neurociencia cognitiva y apoya el desarrollo de estrategias terapéuticas dirigidas para las alteraciones cognitivas relacionadas con el estrés.
# keywords: |
#     Morris Water Maze, Cognitive Flexibility, Mixed Models.
title-block-banner: true
author:
  - name: Garcia Rios Santiago
    email: santiago_gr@ciencias.unam.mx
    affiliations:
      - name: Facultad de Ciencias
        url: https://www.fciencias.unam.mx/
format: 
  html:
    lang: es  # figure, note, warning, code
    embed-resources: true # self-contained file
    # code-fold: true # retraer código
    # code-summary: "Mostrar código"
    theme: "journal" # cyborg, quartz, slate, solar, superhero, vapor,sandstone,lux,flaty,cosmo, journal, materia, minty,morph,pulse
    page-layout: full
    anchor-sections: true
    # smooth-scroll: true
  docx:
    toc: true
    number-sections: true
    highlight-style: github
    execute:
      echo: false
date: "today"
editor: source
  # markdown: 
  #   wrap: 72
# markdown:
#     wrap: sentence
# editor_options: 
#   chunk_output_type: console
# fig-cap-location: top
tbl-cap-location: bottom
crossref:
  fig-title: '**Figura**'
  fig-labels: arabic
  title-delim: "**.**"
  tbl-title: '**Tabla**'
  tbl-labels: arabic
execute:
  echo: true  
  warning: false
  cache: true
toc: true
# toc-title: Contents
number-sections: true
comments:
  hypothesis: true
lightbox: true
glossary:
  path:  glossary.yml
  popup: hover
  show: true
# bibliography: references.bib
bibliography: zotlib.bib
---

# Introducción

## Depresión, estrés y flexibilidad Cognitiva

### Depresión

Caracterizada por sentimientos persistentes de tristeza, pérdida de interés o placer, y una variedad de síntomas físicos y cognitivos, el trastorno depresivo mayor tiene un impacto profundo en la calidad de vida de un individuo. De acuerdo con la Organización Panamericana de la Salud (OPS), la proporción de la población mundial con depresión en 2015 fue de 4.4% (3.6% en hombres y 5.1% en mujeres). Además, se estima que para 2020, la depresión sea la segunda causa a nivel mundial de discapacidad y que un 20% de la población mundial sufra de algún trastorno afectivo que requiera tratamiento médico en algún momento de su vida [@cerecero-garcia2020]. 

Este panorama resalta la necesidad urgente de comprender mejor los mecanismos subyacentes de la depresión y desarrollar tratamientos más efectivos. En este contexto, la investigación sobre los efectos de fármacos como la fluoxetina, conocidos por su potencial antidepresivo, es particularmente relevante. Estudiar cómo estos fármacos pueden influir en procesos desregulados en la depresión, como la {{< glossary "flexibilidad cognitiva" add_to_table=true >}} y la neurogénesis hipocampal, no solo es crucial para entender mejor la fisiopatología de la depresión, sino también para abrir nuevas vías en el tratamiento de este trastorno debilitante.

#### Depresión y cognición

Los trastornos depresivos van más allá de los síntomas emocionales, afectando profundamente las capacidades cognitivas de los individuos. Estos problemas cognitivos, que incluyen dificultades en la atención, memoria y la flexibilidad cognitiva, son a menudo algunos de los aspectos más debilitantes de la depresión. La {{< glossary "flexibilidad cognitiva" add_to_table=true >}} hace referencia a la capacidad de una persona para adaptarse y cambiar su pensamiento en respuesta a situaciones cambiantes o nuevas. Esta habilidad implica poder cambiar de perspectiva o enfoque mental y adaptarse a nuevas reglas o expectativas. La flexibilidad cognitiva es una parte importante de la función ejecutiva, un conjunto de habilidades cognitivas que nos permiten planificar, organizar, tomar decisiones, mantener la atención, y regular el comportamiento [@anacker2017]. Esta capacidad de adaptar el pensamiento y el comportamiento a situaciones nuevas y cambiantes, es crucial para manejar las complejidades de la vida diaria.

En personas con depresión, la disminución de la flexibilidad cognitiva puede manifestarse en una dificultad para desvincularse de pensamientos negativos y adaptarse a nuevos contextos o perspectivas, lo que a su vez puede perpetuar y agravar los síntomas depresivos. De manera similar, en los desórdenes de ansiedad también se puede observar una falta de flexibilidad cognitiva como pensamientos negativos recurrentes que agravian el padecimiento [@cognitive_uddin_2021].

La mayoría de los pacientes con trastornos depresivos experimentan, en cierta medida, deterioros cognitivos. Parece que los trastornos cognitivos constituyen un síntoma patológico central de la depresión y no deberían ser considerados simplemente como secundarios a ella. Por lo tanto, los síntomas cognitivos deben ser vistos como una dimensión parcialmente independiente del trastorno depresivo mayor y un objetivo importante de cualquier tratamiento que se implemente [@maramis2021].

La flexibilidad conductual es la manifestación física de la flexibilidad cognitiva. Como se explica más adelante, la flexibilidad conductual puede ser evaluada mediante protocolos de aprendizaje reversa. Este aprendizaje reversa (flexibilidad conductual) es afectado por el estrés crónico impredecible [@hurtubise2017].

### Estrés

Richard Lazarus define al estrés en torno a una relación entre el individuo y el ambiente, en el cual un estímulo no placentero, aversivo y/o amenazante para la homeostasis de un individuo es experimentado de manera que exede los recursos para lidiar con él [@folkman2013].

Diversos factores afectan la respuesta al estrés y la susceptibilidad de que desencadene trastornos, como depresivos o de ansiedad. Estos van desde aspectos psicológicos (experiencia subjetiva del estrés, recursos para lidiar con estresores), hasta biológicos (cascadas neuroendócrinas, procesamiento de información) [@tafet2016]. En presencia de estresores crónicos, impredecibles e incontrolables, la capacidad fisiológica de lidiar con estos no será suficiente, contribuyendo al desarrollo de desordenes depresivos y de ansiedad [@hill2012].


#### Respuesta fisiológica al estrés

##### Inflamación

Las concentraciones elevadas de citoquinas proinflamatorias producidas por el estrés agudo (interleucina-1, la interleucina-6 y el factor de necrosis tumoral-alfa), se han vinculado a los efectos de diversos estímulos ambientales y esta activación inmunitaria también se ha observado en la depresión mayor. Además, se ha encontrado que la depresión mayor puede inducir respuestas inflamatorias incrementadas al estrés. Los estresores ambientales activan la rama simpática del sistema nervioso autónomo, resultando en la liberación de catecolaminas que, a su vez, activan sus receptores en las células inmunes y estimulan la liberación de citoquinas proinflamatorias. Las respuestas inflamatorias crónicas en el SNC pueden resultar en la liberación excesiva de citoquinas proinflamatorias, lo que puede llevar a concentraciones reducidas de neurotrofinas (incluido el BDNF), provocando neuroplasticidad deteriorada y disminución de la neurogénesis (especialmente en el hipocampo), asociadas con el origen de trastornos cognitivos y del estado de ánimo. Las citoquinas proinflamatorias también están involucradas en la regulación del eje HPA, estimulando la liberación de CRF y resultando en hipercortisolismo, lo que ha sido asociado con una sensibilidad reducida de los GR y resistencia a los glucocorticoides. Niveles elevados de cortisol, como los observados durante el estrés crónico, pueden llevar a una síntesis disminuida de 5-HT debido a la actividad reducida de la enzima limitante de la velocidad, la triptófano hidroxilasa [@evrensel2020].

###### Regulación del eje hipotálamo-hipofisario-suprarrenal

El estrés regula el eje hipotalámico-pituitario-adrenal (HPA) a través de una serie de mecanismos neuroendocrinos complejos. Ante un estresor, el hipotálamo secreta hormona liberadora de corticotropina (CRH), que estimula la pituitaria anterior para liberar hormona adrenocorticotropa (ACTH). La ACTH viaja a través del torrente sanguíneo hasta las glándulas suprarrenales, donde promueve la liberación de glucocorticoides, principalmente cortisol en humanos. El cortisol también retroalimenta negativamente al hipotálamo y la pituitaria para inhibir la liberación de CRH y ACTH, regulando así la actividad del eje HPA y restaurando la homeostasis. Sin embargo, el estrés crónico puede conducir a una disfunción del eje HPA, resultando en niveles persistentemente elevados de cortisol, lo que puede tener consecuencias negativas para la salud, como inmunosupresión y alteraciones metabólicas.

La activación del eje hipotálamo-hipofisario-suprarrenal ({{< glossary HPA add_to_table=true >}}) tiene consecuencias importantes sobre los receptores de glucocorticoides ({{< glossary GRC add_to_table=true >}}) del {{< glossary hipocampo >}}, reduciendo el nivel de neurogénesis hipocampal en modelos animales [@anacker2017]


##### Papel de Neurotransmisores

**Serotonina**

La mayoría de las neuronas serotoninérgicas en el {{< glossary SNC add_to_table=true >}} se encuentran dentro de los límites de los {{< glossary "núcleos del rafé" >}}. El {{< glossary "núcleo dorsal del rafe" >}} tiene proyecciones a la {{< glossary PFC >}}, {{< glossary amígdala >}}, {{< glossary "núcleo accumbens" >}}, e {{< glossary hipocampo >}} ventral, entre otras estructuras del {{< glossary prosencéfalo >}}. Este {{< glossary "núcleo dorsal del rafe" >}} se ha asociado con la activación de estructuras del {{< glossary "sistema límbico" >}}. Además, el {{< glossary "núcleo de rafé" >}} medial proyecta al {{< glossary hipocampo >}} dorsal. Por lo tanto, alteraciones a estos sistemas se han asociado a desórdenes de ánimo [@tafet2016].

La serotonina ({{< glossary 5-HT add_to_table=true >}}) se une a receptores pre y post sinápticos (se han identificado hasta 14 tipos en 7 familias). Se cree que la administración crónica de antidepresivos ( {{< glossary SSRI add_to_table=true >}} ) (y el subsecuente aumento de {{< glossary 5-HT add_to_table=true >}} en el espacio sináptico) desensibiliza o regula a la baja los {{< glossary autoreceptores >}} somatodentríticos de tipo $5-HT_{1A}$ en el {{< glossary "núcleo de rafé" >}}, a la vez que regula a la alta $5-HT_{1A}$ post-sinápticos y desensibiliza $5-HT_{2A}$ [@latest_lin_2023].

**Dopamina**

La dopamina está relacionada con la regulación del eje {{< glossary HPA add_to_table=true >}}, así como en la fisiopatología de la depresión. Los principales grupos de neuronas dopaminérgicas en el SNC incluyen el campo retro-rubro (A8), la sustancia negra pars compacta (A9) y el área tegmental ventral (A10), de donde emergen las vías mesolímbica y mesocortical. La vía mesolímbica se proyecta principalmente hacia el núcleo accumbens y otras estructuras límbicas, incluyendo la amígdala, el hipocampo, el núcleo de la estría terminal y el septum, y está implicada en el procesamiento y refuerzo de estímulos gratificantes, motivación y la experiencia subjetiva del placer. La vía mesocortical se proyecta principalmente hacia la corteza prefrontal (PFC), el cíngulo anterior (ACC) y la corteza entorrinal, y juega un papel crucial en funciones cognitivas como la concentración y la memoria de trabajo. Además, los estrsores ambientales incrementan la actividad del la amígdala, incrementando la concentración de dopamina en la vía mesocortical (particularmente en PFC), confiriendo un aumento de la saliencia relacinada a estímulos negativos [@tafet2016].

**Norepinefrina**

El principal grupo de neuronas que contienen norepinefrina en el SNC se localiza en el locus coeruleus (LC), desde donde surgen diversas proyecciones que inervan ampliamente áreas corticales y subcorticales, incluyendo la amígdala, el hipocampo y el núcleo paraventricular del hipotálamo. Estas proyecciones al área tegmental ventral han demostrado potenciar la liberación de dopamina, mientras que las proyecciones al núcleo del rafe regulan la liberación de serotonina (5-HT). También se ha observado una regulación recíproca entre la norepinefrina y la 5-HT, no solo a través de conexiones entre ambos sistemas aminérgicos, sino también mediante estructuras límbicas como el hipocampo. Además, las conexiones recíprocas entre la norepinefrina y las neuronas que contienen factor de liberación de corticotropina (CRF) sugieren un papel crucial del LC en la regulación de las respuestas neurales y neuroendocrinas al estrés. En respuesta a estresores agudos, se libera norepinefrina en diferentes estructuras del SNC, resultando en un aumento de la alerta y la hipervigilancia, en el contexto de respuestas adaptativas al estrés. La activación del LC también ha sido asociada con la estimulación del hipotálamo lateral, que participa en la activación de la rama simpática del sistema nervioso autónomo, complementando así la respuesta adaptativa al estrés [@tafet2016].


#### Hipocampo


El estrés crónico se ha asociado a cambios en el volumen de varias regiones cerebrales, incluido el hipocampo. En la literatura, se han reportado variaciones en el volumen del hipocampo en la depresión, que pueden estar relacionadas con diferencias en la duración de la enfermedad, la delimitación anatómica, la lateralización, las condiciones de vida temprana y el genotipo. En general, los cambios en el hipocampo, la amígdala y la corteza prefrontal en el trastorno depresivo mayor (MDD) son hallazgos bien replicados en la psiquiatría. Sin embargo, no está claro si la pérdida de volumen del hipocampo refleja una causa o una consecuencia del MDD, pero se puede prever que volúmenes más bajos del hipocampo en los pacientes están asociados con una mayor duración y recurrencia de episodios depresivos, el tamaño de sus respuestas integradas de cortisol, y una historia de estrés temprano en la vida. Además, un volumen más pequeño del hipocampo podría predisponer al desarrollo de psicopatologías [@lucassen2016]. En el hipocampo adulto de roedores, es muy evidente que el estrés crónico reduce las tasas de neurogénesis hipocampal adulta [@hill2015].

La neurogénesis en el sistema nervioso central (SNC) adulto puede ser estimulada por condiciones específicas, como el ejercicio o diversas clases de fármacos antidepresivos, pero puede ser inhibida por situaciones estresantes y niveles altos de glucocorticoides. Bajo condiciones de estrés crónico y con la activación incrementada del eje hipotalámico-pituitario-adrenal (HPA), la inhibición de la neurogénesis hipocampal puede interferir con la formación de nuevas memorias, contribuyendo así a provocar y mantener condiciones que inducen depresión (falta de flexibilidad cognitiva). Según esta hipótesis, las intervenciones terapéuticas exitosas podrían requerir la recuperación de la tasa normal de neurogénesis hipocampal. Esta recuperación podría estar asociada con un efecto directo de los antidepresivos al incrementar los niveles de 5-HT o indirectamente a través de la modulación del eje HPA y el aumento de los niveles de BDNF, lo cual se ha asociado con una regulación positiva de la neuroplasticidad y el aumento de la neurogénesis [@tafet2016]. 

Muchos factores neurotróficos se han asociado a la respuesta del estrés crónico en el hipocampo. Particularmente, el BDNF ha recibido particular atención debido a su papel en la regulación de la neuroplasticidad y la neurogénesis. Los estudios sugieren que niveles reducidos de BDNF pueden conducir a síntomas depresivos, mientras que su regulación positiva está asociada con la recuperación clínica. Estudios in vitro han mostrado que el BDNF puede disminuir la captación de serotonina (5-HT), indicando su posible papel en la regulación del transportador de serotonina (5-HTT) [@ibarguen-vargas2009].


#### Modelo de Estrés Crónico Impredecible

El modelo de estrés crónico moderado impredecible (CUMS) fue desarrollado como un modelo animal de depresión hace más de 20 años. @katz1981 y colegas demostraron a principios de los ochentas que exponer a ratones a estrsores de manera crónica inducía una reducción en los roedores de un estímulo reforzante (sucrosa). En las décadas posteriores, el investigador Paul Willner publicó y expandió en las conductas que este modelo inducía en los roedores: afectaba el sueño, patrones de acicalamiento, conductas sexuales, conductas de agresión, entre muchas otras [@willner1997]. Gracias a la caracterización de este investigador en este protocolo, se ha establecido como un modelo válido para el estudio de conductas de tipo depresivas en roedores [@willner1997a]. 

Este modelo ha sigo utilizado para examinan variables neurobiológicas asociadas con la depresión, aunque no siempre es fácil validar exactamente cúales cambios neurobiológicos inducidos por el CUMS son paralelos a los documentados en el trastorno depresivo. Sin embargo, es un protocolo que provoca una serie de cambios neurobiológicos que reflejan aquellos vistos en los trastornos depresivos y puede ser una herramienta adecuada para investigar nuevos sistemas que podrían estar alterados en la depresión, y así ayudar en el desarrollo de nuevos objetivos para el tratamiento de la depresión [@hill2012]. Como revisa @willner2017, el CUMS tiene *validez de predicción* (el rendimiento en el protocolo predice el rendimiento que queremos modelar), *validez de apariencia* (similitudes fenomenológicas) y *validez de constructo* (modelo tiene bases teóricas razonables).


##### Efectos sobre cognición

El CUMS tiene efectos sobre varios aspectos de la Cognición (habilidad de procesar información, valorarla y utilizar el conocimiento por medio de conductas dirigidas, aprendizaje, memoria, atención, razonamiento, sentimientos, toma de desiciones) [@bondi2008]. Una consecuencia de estos efectos cognitivos, es la aparición de conductas maladaptativas en las pruebas de conducta, como la dificultad de reaprender una tarea (falta de flexibilidad cognitiva) [@maramis2021].

Debido a que el Hipocampo regula distintos apectos de la cognición, esta estructura está intimamente relacionada con las alteraciones cognitivas producidas por el CUMS. @el-aziz2022 y colaboradores reportan que el CUMS tiene efectos sobre la adquisisición de memoria espacial (evaluada a través del laberinto acuático de Morris), la cuál depende en gran medida de la integridad del hipocampo. Sin embargo, poco se ha estudiado sobre la relación de el CUMS con un proceso específico de la cognición, la flexibilidad cognitiva y cómo se relaciona con el hipocampo y el protocolo de CUMS.

## Hipocampo

Anatómicamente, el término formación hipocampal generalmente se refiere al giro dentado (DG), el cornu ammonis (CA) y la corteza subicular. Además, CA se divide en cuatro subregiones, siendo CA1 y CA3 las más prominentes, CA2 forma una zona intermedia pequeña entre estas dos, y CA4 se considera una subregión polimórfica del DG [@eichenbaum2004].

El hipocampo está implicado en diversas funciones cognitivas, incluyendo el aprendizaje contextual, la navegación, la separación de patrones y los procesos de memoria que surgen como resultado de la integración, separación y completación de la información proyectada y transmitida a través de sus distintas subregiones anatómicas. Como demostraron Penfield y Milner [@penfield1958], es una estructura fundamental para la adquisición de memorias explícitas. En este artículo reeportan el caso del paciente H.M., al cual se le removió la mayoría de su hipocampo, cortices parahipocampales, corteza entorrinal, cortices piriformes y amígdala en un intento de tratar sus ataques epilépticos. Después de la cirugía, su memoria de trabajo y procedural no se vieron afectadas. Sin embargo, el paciente presentó una inhabilidad de formar nuevas memorias episódicas (amnesia anterógrada). Este caso ayudo a entender cómo las memorias se formaban y almacenaban, estableciendo la formación de memorias al hipocampo [@lisman2017].


### neurogénesis hipocampal adulta

La **neurogénesis hipocampal adulta** (NHA) es un fenómeno que desafía la antigua creencia que el cerebro adulto es incapaz de generar nuevas neuronas a lo largo de la vida. La {{< glossary NHA add_to_table=true >}} implica la proliferación de células progenitoras neurales, su diferenciación en neuronas, y su integración eventual en circuitos neuronales. Este fenómeno no solo es crucial para la plasticidad cerebral y la formación de recuerdos, sino que también se ha vinculado con la regulación del estado de ánimo y la respuesta al estrés [@anacker2017].

En roedores la neurogénesis adulta está bien descrita en dos zonas: {{< glossary "zona subventricular" add_to_table=true >}} y {{< glossary "zona subgranular" add_to_table=true >}} en el {{< glossary "giro dentado" add_to_table=true >}}. En la zona subventricular, las células madre neurales se diferencian en distintos tipos de neuronas olfativas. En el giro dentado, las células madre neurales producen neuronas glutamatérgicas que se integran en la capa granular y proyectan sus axones hacia la región de CA3 del hipocampo [@formation_denothlippuner_2021].

Utilizando timidina radioactiva, el estudio pionero de @altman1965 presentó la primera evidencia de la presencia de células no diferenciadas en la capa granular del giro dentado en el hipocampo de ratas adultas. Decadas después, utilizando técnicas de inmunihistoquímica en cerebros post-mortem, @neurogenesis_eriksson_1998 fue el primero en presentar evidencia de la presencia de células progenitoras en el giro dentado de humanos. 

Sin embargo, la existencia de la neurogénesis hipocampal en adultos humanos ha sido un tema controvertido en los últimos años. Por un lado, algunos estudios, como el de @sorrells2018, no han encontrado evidencia de neurogénesis en adultos. Por otro lado, investigaciones como la de @human_boldrini_2018 han llegado a la conclusión opuesta. Estas discrepancias se deben en gran medida a las diferencias en las metodologías utilizadas para detectar la neurogénesis y a las diversas interpretaciones de los resultados. Es probable que este debate continúe en los próximos años hasta que se desarrollen metodologías más precisas y confiables. Además, la creciente evidencia de diferencias en los procesos de neuroplasticidad entre distintos mamíferos sugiere que debemos ser cautelosos al extrapolar las conclusiones de estudios que analicen la NHA en roedores (que abarcan aspectos conductuales, celulares, genéticos, etc.) a implicaciones en humanos, según señalan @larosa2018.

Al menos en roedores, esta neurogénsis hipocampal involucra la presencia de células madres neurales a lo largo de la vida del roedor. Estas células madre neurales (NSCs) generan nuevas neuronas a lo largo de la vida en el cerebro estos animales. Las neuronas nacidas en la adultez moldean la función cerebral y la dinámica del hipocampo, por lo que el estudio de la dinámica de la NHA es un factor importante a considerar en las funciones cognitivas [@formation_denothlippuner_2021]. 

![Neurogénesis Hipocampal Adulta en roedores.](figuras/nha.png){fig-align="center"}



### NHA y flexibilidad cognitiva

El hipocampo juega un papel crucial en la flexibilidad cognitiva, que es la capacidad de adaptarse a nuevas situaciones y cambiar de estrategia cuando las condiciones cambian. Este vínculo se debe a las funciones del hipocampo en la formación y recuperación de recuerdos contextuales y espaciales, así como en la integración de nueva información con experiencias pasadas. La plasticidad sináptica del hipocampo, especialmente a través de procesos como la potenciación a largo plazo (LTP), facilita la reorganización de redes neuronales que subyacen a la adaptación cognitiva. Además, el hipocampo interactúa con la corteza prefrontal, una región clave para la toma de decisiones y la implementación de estrategias flexibles. Las disfunciones en estas interacciones, como las observadas en trastornos neurológicos y psiquiátricos, suelen resultar en una disminución de la flexibilidad cognitiva, evidenciando la importancia del hipocampo en este proceso [@anacker2017a].

La flexibilidad cognitiva es una parte importante de la **función ejecutiva**, un conjunto de habilidades cognitivas que nos permiten planificar, organizar, tomar decisiones, mantener la atención, y regular el comportamiento. De acuerdo a la definición de @formation_denothlippuner_2021, algunos elementos clave de la flexibilidad cognitiva incluyen:

• Adaptabilidad: La capacidad de cambiar de estrategia o enfoque en respuesta a nueva información o cambios en el entorno.

• Tolerancia a la ambigüedad: La capacidad de manejar la incertidumbre o la ambigüedad sin experimentar un estrés excesivo.

• Multitarea: La habilidad de manejar y procesar varias tareas o informaciones a la vez.

• Cambio de perspectiva: La capacidad de ver las cosas desde diferentes ángulos o puntos de vista.

• Pensamiento divergente: La capacidad de generar una variedad de ideas o soluciones aun problema.


En humanos con síntomas depresivos y ansiosos, la falta de flexibilidad cognitiva se manifiesta en la presencia de pensamientos negativos recurrentes y persistentes (engramas viejos), así como en la ansiedad generalizada en diferentes contextos [@cognitive_uddin_2021]. Por otro lado, la flexibilidad cognitiva está asociada con una mejora de estos síntomas, facilitando el enfrentamiento de problemas desde diferentes enfoques o permitiendo el reaprendizaje de experiencias negativas desde una perspectiva de autocompasión (engramas nuevos) [@guler2022]. 

La neurogénesis hipocampal adulta (NHA) desempeña un papel fundamental en la flexibilidad cognitiva, aunque los mecanismos exactos de esta relación aún no se comprenden completamente. Se sugiere que las terminales sinápticas de las nuevas neuronas compiten con las neuronas viejas, que pueden representar engramas antiguos, hasta desplazar estructuralmente estas conexiones. Esto facilita el reaprendizaje al inducir una degradación de engramas previos mediante la interferencia sináptica. En ausencia de nuevas neuronas, no se eliminan los engramas viejos, lo que genera un conflicto entre engramas antiguos y nuevos, impidiendo el reaprendizaje [@akers2014].

Adicionalmente, las neuronas inmaduras pueden reclutar interneuronas que inhiben a las neuronas maduras del giro dentado, mientras que una baja neurogénesis mantiene una alta excitabilidad en esta región. Esta elevada excitabilidad, asociada a una baja NHA, podría resultar en una mayor activación de engramas (tanto viejos como nuevos), manifestándose como una disminución en la flexibilidad cognitiva [@groisman2020]. 

Un estudio por @vila-ballo2017a evidencía el papel del giro dentado en el aprendizaje reversa, un tipo de manifestación de la flexibilidad cognitiva. Este estudio comparó a mujeres con esclerósis hipocampal (pérdida de células y gliosis en el hipocampo) y mujeres con epilepsia del lóbulo temporal contra mujeres controles en una prueba de aprendizaje reversa llamada prueba de aprendizaje probabilístico. En esta tarea, se pide a los participantes que aprendan cuál de dos patrones es más probable que esté asociado con una recompensa. En cada prueba, se presentan simultáneamente dos patrones visuales abstractos y los participantes deben adivinar cuál es más probable que sea recompensado, recibiendo retroalimentación (correcto o incorrecto) después de cada elección. Se les informa que ningún estímulo es recompensado todo el tiempo y que el estímulo "recompensado" cambia ocasionalmente. Los participantes deben mantenerse con su elección hasta que sientan que el estímulo más probable de ser recompensado ha cambiado. La tarea comienza con una fase de adquisición inicial, donde uno de los estímulos es reforzado el 80% del tiempo. Una vez que alcanzan un criterio de 9 elecciones correctas en un bloque de diez ensayos (dentro de un máximo de 50 ensayos), las contingencias de refuerzo se invierten (aprendizaje reversa). Para alcanzar el criterio en la fase de reversión, los participantes deben elegir el nuevo estímulo más probable de ser recompensado 9/10 veces en un bloque de ensayos. Si logran alcanzar el criterio, las contingencias de refuerzo se invierten una vez más, y deben aprender a elegir el estímulo originalmente más probable de ser recompensado. La conclusión del estudio fue que las mujeres con daño al hipocampo tenían dificultades para adoptar estrategias anticipatorias en el aprendizaje reversa. 

#### Laberinto acuático de Morris


Una forma de estudiar la relación entre flexibilidad cognitiva y la NHA en roedores es utilizando el protocolo de laberinto acuático de Morris [@hernandez-mercado2022]. En este laberinto, la flexibilidad cognitiva se estudia a través de un "aprendizaje reversa", donde se evalúa la capacidad de reaprendizaje cuando la plataforma de escape se traslada a una nueva posición. Las pruebas de aprendizaje reversa son útiles para evaluar la flexibilidad cognitiva en roedores, primates no humanos y humanos [@cognitive_uddin_2021]. 

De acuerdo a este paradigma, @garthe2009a utilizó este laberinto para investigar cómo la supresión de la neurogénesis adulta con temozolomida (TMZ) afectaba el rendimiento en esta prueba. Este tratamiento farmacológico condujo a un déficit de aprendizaje un aprendizaje espacial preciso, afectando particularmente la capacidad de adaptarse a nuevas condiciones dentro de tareas aprendidas, sugiriendo que las nuevas neuronas en el giro dentado son cruciales para el aprendizaje y la memoria espacial flexibles y precisos. Los resultados concuerdan con la hipótesis de que el giro dentado contribuye no solo a un mapa configuracional del entorno, sino que desempeña un papel crítico en los procesos de aprendizaje dinámicos, destacando el impacto significativo de la neurogénesis adulta en la plasticidad hipocampal.

A pesar que el laberinto acuático de Morris representa el estándar de facto para probar la función del hipocampo en roedores de laboratorio, el uso de este paradigma para evaluar la relevancia funcional de las nuevas neuronas ha dado resultados sorprendentemente inconsistentes [@garthe2013]. Existe una inconsistencia en los resultados debido a la diversidad en los protocolos, configuraciones experimentales y análisis estadísticos utilizados [@overall2020]. Muchos autores han expresado sus preocupaciones sobre cómo los parámetros clásicos de medición en el laberinto pueden no ser adecuados para identificar los cambios funcionales específicos generados por la modulación de la neurogénesis hipocampal adulta [@maei2009a]. En este sentido, existe una necesidad de evaluar parámetros más específicos y sensibles que reflejen la funcionalidad única del hipocampo.

Por ejemplo, @maei2009 reportan que la mayoría de los artículos que utilizan el {{< glossary MWM add_to_table=true >}} evalúan las pruebas con métricas no óptimas para evaluar el aprendizaje espacial. La principal razón de estudiar métricas menos sensibles (tiempo en cuadrante, conteo de cruces a localización de plataforma) sobre otras más sensibles al aprendizaje espacial (entropía, distancia media) parece ser solo por simplicidad y facilidad, más que por otra cuestión.

Sumado a esto, también existen críticas a los análisis estadísticos clásicamente utilizados. Como recalca [@young2009] y [@young2021], los entrenamientos del MWM suelen ser evaluados con el análisis de varianza de medidas repetidas tradicional. Sin embargo, otros modelados que incluyan regresiones con efectos mixtos (lineales, generalizados o bayesianos) son más efectivos en detectar tendencias reales de aprendizaje y ofrecen mejores ajustes de los datos. Mejorar la interpretación de los datos obtenidos en el MWM es crucial para el entendimiento de los impactos cognitivos que tiene el estrés crónico.


## Fármacos Antidepresivos

Los primeros antidepresivos desarrollados fueron los inhibidores de la monoamino oxidasa, que mejoraban el ánimo a costa de efectos secundarios importantes, como toxicidad hepática y crisis hipertensivas. Posteriormente, se desarrollaron los antidepresivos tricíclicos (ATCs) como la imipramina y la clomipramina, que actúan principalmente bloqueando la recaptación de serotonina y noradrenalina. Debido a su falta de especificidad y efectos secundarios, los ATCs se prescriben actualmente para casos muy particulares de depresión. A finales de los años 80, surgieron los antidepresivos de segunda generación, incluyendo los inhibidores selectivos de la recaptación de serotonina (ISRS), los inhibidores de la recaptación de serotonina y noradrenalina (IRSN), antidepresivos serotonérgicos específicos y otros fármacos relacionados. Los ISRS, como el escitalopram, la fluoxetina y la sertralina, son los medicamentos más recetados para los trastornos de depresión y ansiedad, siendo la primera línea farmacológica debido a su tolerabilidad y eficacia [@hanson2011].

Actualmente, la depresión es tratada farmacológicamente utilizando medicamentos conocidos los ISRS como primera línea terapéutica. Su mecanismo de acción inmediato es a través de la regularización del sistema serotoninérgico mediante el incremento de la concentración de serotonina en el espacio sináptico. Sin embargo, su mecanismo de acción antidepresiva parece involucrar otros mecanismos, como la neurogénesis hipocampal adulta [@haroon2017].

Adicionalmente, los ISRS se utilizan en el tratamiento del trastorno de pánico y el trastorno obsesivo-compulsivo. Sin embargo, tienen el problema de generar efectos terapéuticos semanas o meses posteriores al inicio de su tratamiento, tener una efectividad comprometida, y un 70% de los pacientes responden de manera incompleta a los ISRS, siendo el resto difícil de tratar (pacientes con depresión resistente a los fármacos) [@latest_lin_2023].

Muchos autores han recalcado que hasta la fecha, no tenemos evidencia dura del efecto antidepresivo de los ISRS, recalcando que el efecto antidepresivo podría incluso deberse a un efecto placebo [@latest_moncrieff_2018; @juul2021]. Otros autores señalan que la falta de efectividad proviene más bien del desconocimiento del mecanismo de acción de estos fármacos. El grupo de Igor Branchi propone que hay un poco entendimiento de las vías involucradas en el mecanismo de acción de estos fármacos: conductuales, neurogénesis, BDNF, HPA, LTP. Pero sobre todo, este grupo señala que el menor entendimiento que tenemos es cómo estas vías fisiológicas reguladas por los fármacos interactúan con el ambiente. De acuerdo a la Hipótesis de suceptibilidad unidireccional al cambio que este grupo estudia, los antidepresivos no cambian el estado de ánimo por sí mismos, sino que crean una ventana de oportunidad para el cambio. Esta a su vez puede ser influenciada por el ambiente, positivo o negativo [@branchi2011].

### Mecanismo de acción

Como se mencionó previamente, varias terapias que en modelos murinos incrementan la neurogénesis (ejercicio aeróbico, fármacos antidepresivos, modelos transgénicos) parecen también reducir los síntomas depresivos (Anacker & Hen, 2017). Varios fármacos antidepresivos (clásicos y no clásicos) podrían mitigar síntomas depresivos promoviendo la neurogénesis hipocampal, aunque podrían existir otros mecanismos de acción adicionales que contribuyan a esta acción (como efectos anti inflamatorios) [@hovorka2022].

Se ha demostrado en modelos murinos que el tratamiento crónico con fluoxetina (ISRS y agonista parcial de 5-HT2B) [@latest_lin_2023] promueve la neurogénesis hipocampal y reduce las conductas depresivas en modelos de estrés [@segi-nishida2017]. Sumado a estos efectos, se ha observado que el tratamiento crónico con fluoxetina promueve la flexibilidad cognitiva en ratones en una prueba conductual que involucra discriminación de patrones espaciales, búsqueda de recompensa y evitar castigos [@marwari2018].

Por último, hay que destacar que utilizando técnicas de inmunohistoquímica y electrofisiología en ratones [@kobayashi2011] y primates (*Callithrix jacchus*) [@ohira2019], se han descrito otros procesos de plasticidad hipocampal inducidos por antidepresivos que podrían jugar un papel sobre la flexibilidad cognitiva. Estos grupos han descrito que la fluoxetina puede revertir a neuronas granulares maduras del hipocampo a un fenotipo inmaduro, un fenómeno denominado "demaduración". Al mismo tiempo, este fármaco parece reducir el número de neuronas con redes perineuronales en el giro dentado, un fenómeno que promueve la plasticidad en el cerebro adulto. En conjunto, estos resultados podrían significar que existen otros mecanismos independientes de la NHA que reinstauren un estado de inmadurez al giro dentado que representa un sustrato importante en la cognición y regulación del comportamiento [@umemori2018].

De acuerdo con investigaciones lideradas por Igor Branchini [@branchi2022], los niveles altos de plasticidad inducidos por medicamentos, como los antidepresivos serotoninérgicos y los psicodélicos, no son beneficiosos por sí mismos. Estos fármacos inducen una alta plasticidad (a veces llamados psicoplastógenos) que hacen que el cerebro y el comportamiento sean más susceptibles a cambios según factores contextuales, como las condiciones de vida. Esta suceptibilidad puede ser benéfica si las condiciones de vida mejoran. Sin embargo, si las condiciones de vida no mejoran (o empeoran), esta plasticidad inducida por los fármacos puede ser detrimental.



## Antecedentes

La investigación científica ha demostrado una correlación significativa entre el volumen del hipocampo y la persistencia de trastornos depresivos. Estudios postmortem han revelado que un menor volumen del hipocampo, particularmente en las áreas del giro dentado (GD), CA1 y CA3, está asociado con pacientes que sufren de depresión no medicada [@cobb2013, @huang2013]. Estos hallazgos resaltan la importancia del hipocampo en la modulación de los síntomas depresivos.

En modelos animales, se ha observado que el estrés crónico disminuye la NHA e induce conductas ansiosas y depresivas. Investigaciones con ratones transgénicos han demostrado que el aumento de la NHA puede disminuir estos síntomas, independientemente de la regulación del eje hipotálamo-pituitario-adrenal (HPA), subrayando así el efecto significativo de la neurogénesis en las emociones [@hill2015]. 

La relación entre la NHA y la flexibilidad cognitiva también ha sido demostrada. Por ejemplo, @akers2014 y colaboradores demostraron que el aumento de la neurogénesis después de la formación de una memoria puede inducir el olvido, lo que sugiere un papel crítico de la NHA en la adaptación y el reaprendizaje. En el contexto del laberinto acuático de Morris, se ha encontrado que la NHA es esencial para el aprendizaje y la memoria espacial flexibles, siendo crucial para adaptarse a nuevas condiciones [@garthe2009].

La fluoxetina, un inhibidor selectivo de la recaptación de serotonina (ISRS), ha mostrado efectos promisorios en la mejora de la flexibilidad cognitiva. Estudios recientes han investigado los efectos de los enantiómeros de la fluoxetina en paradigmas de comportamiento cognitivo y proliferación celular en el hipocampo de ratones. Se encontró que la (R)-fluoxetina mejoraba significativamente la adquisición de secuenciación conductual y la flexibilidad cognitiva en tareas de aprendizaje reverso, así como la proliferación celular en el giro dentado @marwari2018.

Por último, desde que Morris diseñó su protocolo del laberinto acuático, ha habido una búsqueda por encontrar métricas que modelen mejor el aprendizaje dependiente del hipocampo [@place_morris_1982]. Sin embargo, hasta la fecha se siguen utilizando principalmente métricas subóptimas para evaluar el aprendizaje espacial [@meenakshi2022] y la revelancia del las nuevas neuronas en este laberinto [@garthe2013]. Utilizar mejores métricas y modelamiento de la prueba ayuda a tener una mejor inferencias estadísticas que permita identificar las interacciones conductuales complejas entre fenómenos como el estrés, depresión y flexibilidad cognitiva.

Dados estos antecedentes, nuestra investigación se propone evaluar el impacto de la fluoxetina sobre la flexibilidad cognitiva en ratones sometidos a estrés crónico y determinar cómo la NHA afecta el aprendizaje en el laberinto acuático de Morris. El estudio pretende vincular directamente los efectos de la fluoxetina y la NHA con la mejora de la flexibilidad cognitiva y la reducción de conductas depresivas, proporcionando una base para potenciales enfoques terapéuticos en el tratamiento de la depresión y otros trastornos relacionados con la flexibilidad cognitiva.

# Objetivos

## General

Evaluar el impacto de la fluoxetina sobre la flexibilidad cognitiva en ratones con estrés crónico y determinar cómo la neurogénesis hipocampal adulta afecta el aprendizaje en el laberinto acuático de Morris.

### Específicos

i. Investigar los efectos del estrés crónico y el tratamiento con fluoxetina sobre la flexibilidad cognitiva dependiente del hipocampo, utilizando el Laberinto Acuático de Morris.
i. Contribuir al desarrollo de modelos más efectivos en neurociencia cognitiva que faciliten la comprensión de los mecanismos por los cuales la fluoxetina puede mitigar las alteraciones cognitivas causadas por el estrés.

# Hipótesis

La administración de fluoxetina mejora significativamente la flexibilidad cognitiva dependiente del hipocampo en ratones sometidos a estrés crónico. Además, el uso de técnicas de análisis estadístico avanzadas proporciona una modelación más precisa y detallada de esta relación, permitiendo una mejor comprensión de los mecanismos subyacentes y la eficacia de la intervención, en comparación con los métodos estadísticos tradicionales.

# Metodología

![Diseño Experimental](figuras/diseno_experimental.png){fig-align="center"}

## Animales

Todos los ratones a utilizar en este experimento se obtendrán a partir de la cruza de ratones macho de la cepa C57BL/6 y hembras de la cepa BALB/c. Estos pies de cría se obtendrán del bioterio de la Facultad de Ciencias, UNAM, donde se tiene el convenio con la Comisión de tica Académica y Responsabilidad Científica (CEARC) con Folio:PI_2020_12_03. Se van a utilizar ratones machos y hembras. 

Los animales se mantienen de manera constante en cajas comunales de acrílico con rejilla de acero inoxidable, son mantenidos a temperatura ambiente controlada de 20°C controlada por termostato y un calentador ambiental eléctrico de aceite. La humedad ambiental se regula mediante un humidificador y se mantiene alrededor de 50%, con un ciclo de luz/oscuridad de 12:12. Los ratones se mantienen en una cama mezcla de viruta comercial para roedores con ocote molido de grano fino para ratones en una mezcla de 1:1, esto con el fin de darles una cama cómoda (viruta) pero con capacidad extra de absorción de agua y amoniaco (ocote). El alimento es ad libitum (LabDiet - 5001). Los animales se cambian de cama y se lavan sus cajas dos veces por semana. Se mantienen en colonias de entre 2 y 5 animales. Adicionalmente se les coloca material de enriquecimiento y nidificación (como tubos de cartón y papel picado) dentro de sus cajas.

## CUMS

Los ratones serán sometidos a un protocolo de estrés crónico moderado impredecible (conocido como CUMS en la literatura) durante 21 días para generar un estado depresivo. Los estresores que se utilizarán en el protocolo de estrés crónico moderado impredecible son los siguientes:

• Privación de agua y comida (8 horas)

• Interrupción ciclo luz/oscuridad.

• Cama mojada (200ml en 100g de aserrín por 19hrs)

• Cajas inclinadas a 45 grados por 24 horas

• Levantamiento por la cola (5 minutos)

• Asilamiento en cajas individuales (2 horas)

Este protocolo está basado en el trabajo de @monteiro2015 y representa una forma confiable de inducir estados de tipo depresivos y ansiosos en ratones C57BL/6. De acuerdo a la revisión de @antoniuk2019, este tipo de estrés crónico reduce la neurogénesis hipocampal en roedores.

## Tratamiento con Fluoxetina

Se administrará un inhibidor de la recaptura de serotonina (Fluoxetina 15mg/kg) para observar sus efectos sobre la flexibilidad cognitiva. El fármaco se administrará diario durante 3 semanas vía subcutánea al mismo tiempo que se administra el protocolo de CUMS.

## MWM {#sec-mwmmetodo}

Posteriormente se llevará a cabo un protocolo del laberinto espacial de Morris para evaluar el desempeño cognitivo. Este protocolo consiste en hacer nadar durante 60 segundos a los ratones en un recipiente con agua a 27℃. En estos 60 segundos, los ratones deben de encontrar una plataforma oculta guiándose únicamente por pistas visuales que se encuentran en el cuarto de prueba. Esta prueba se realiza 4 veces seguidas por cada ratón durante 5 días. Al termino de estas pruebas de entrenamiento, se realizan 2 pruebas de retención de memoria, donde se deja nadar al ratón durante 60 segundos en el mismo recipiente, pero ahora sin la plataforma oculta. Por último, se realiza una última prueba donde la plataforma se cambia de lugar. Esta última prueba, conocida como aprendizaje reversa, se utilizar para dilucidar la flexibilidad cognitiva en los ratones.


## Perfusión e inmunihistoquímica

Para obtener y analizar el tejido neuronal, se sacrificarán los ratones por perfusión. Para esto, se inyectará a los ratones con pentobarbital sódico a una dosis anestésica total irreversible. Este fármaco se adquiere en farmacia veterinaria bajo receta y autorización del M.V.Z encargado del bioterio de la Facultad de Ciencias. Se utiliza la marca Pet's Pharma® N° de Registro: Q-7972-004, la cual se diluye 1:3 en solución salina estéril (0.9%) para obtener 1ml de solución por 100g de peso del animal, que corresponde a 210 mg/kg. La inyección se administra vía intraperitoneal. Tras 3 minutos, se observa si el animal ya no muestra locomoción, reflejo del párpado ante un soplo de aire y reflejo de movimiento corporal ante la presión mecánica sobre la cola. Solo hasta que ya no se observen dichos reflejos, se procede a abrir la caja torácica y perfundir con 50 ml de solución de sacarosa al 30% y 50 ml de paraformaldehído al 3.7%. Los fluidos sobrantes (mezcla de sangre con las soluciones) se almacenan y se rotulan como desechos tóxicos y se desechan de acuerdo con los procedimientos de la comisión de desechos peligrosos de la Facultad de Ciencias. Se colecta el cerebro de los animales y el resto de los tejidos se almacenan en una bolsa etiquetada como desechos biológicos para su apropiada disposición en el congelador del bioterio de la Facultad de Ciencias, anotando número de animales y fecha en la bitácora oficial. Todos los procedimientos de perfusión se llevan a cabo bajo la campana de extracción, utilizando guantes de nitrilo, bata, cofia y mascarilla con filtro para vapores orgánicos y aldehídos. Los cerebros, fijados en paraformaldehído, son rebanados en congelación en un criostato y son almacenados en anticongelante en un congelador hasta su uso para análisis posteriores.

Para obtener y analizar el tejido neuronal, se sacrificarán los ratones por perfusión. Los cerebros, fijados en paraformaldehdo, son rebanados en congelación en un criostato y son almacenados en anticongelante en un congelador hasta su uso para análisis inmunohistoquímico.

Una vez que el cerebro del ratón está incrustado en paraformaldehido se corta en secciones muy finas con un microtomo y se coloca en un portaobjetos las secciones correspondientes al hipocampo. Para remover el paraformaldehido y rehidratar el tejido, se utiliza xileno, seguido de una serie de lavados de alcohol de concentraciones decrecientes para rehidratar el tejido. Para realizar la Inmunotinción, se añade el anticuerpo primario, que está diseñado para unirse a la protenía de interés. En nuestro caso queremos observar la expresión de **doblecortina** (Anticuerpo a doblecortina policlonal - HPA036121-25UL sigmaaldrich), la cual es una proteína asociada a microtúbulos que solo se expresa en células neuronales precursoras o inmaduras. Finalmente, se examina la muestra bajo un microscopio (Zeiss primostar 3) y se analiza la intensidad y localización de la tinción.

## Modelado Estadístico

Debido a la naturaleza de los datos longitudinales y jerárquicos en el laberinto de Morris, se debe considerar en el modelado estadístico la naturaleza dependiente y estructurada de los datos. Los modelos con efectos mixtos, también conocidos como modelos lineales jerárquicos o modelos multinivel, son una herramienta poderosa para abordar estos desafíos. Estos modelos permiten la incorporación de variaciones tanto a nivel individual como grupal, proporcionando una mayor flexibilidad y precisión en el análisis. A pesar de la evidencia de utilizar estos modelos en el laberinto de Morris [@young2009], no muchos estudios los emplean para el análisis de datos de esta prueba [@young2021]. 

El uso de modelos que permitan incorporar efectos aleatorios, permite capturar la variabilidad intrínseca entre individuos o grupos a lo largo del tiempo. Tradicionalmente, para corregir las medidas no independientes en esta prueba se utiliza un análisis de ANOVA de medidas repetidas. Sin embargo, debido a la naturaleza de los resultados en el laberinto de Morris, los supuestos de este modelo son muy difíciles de cumplir. Estos van desde la normalidad y linealidad de la variable de respuesta, simetría de componentes (varianzas y covarianzas similares) y esfericidad de componentes (varianzas de las diferencias entre los niveles deben ser similares). En contraste, los modelos con efectos mixtos manejan naturalmente la dependencia entre mediciones repetidas de los mismos participantes, evitando los problemas de pseudoreplicación. Además, no requieren suposiciones estrictas como la simetría compuesta o la esfericidad. Los modelos con efectos mixtos pueden especificar diferentes estructuras de covarianza, adaptándose mejor a los datos reales. Otro punto es que son más robustos frente a violaciones de suposiciones estadísticas, reduciendo la probabilidad de errores de Tipo I y proporcionando resultados más fiables. Por último, pueden manejar eficientemente datos incompletos o no balanceados, una ventaja significativa en estudios longitudinales y experimentos con mediciones repetidas. [@magezi2015, @aarts2014]. 

Todos los análisis fueron realizados en el lenguaje de programación R. Se utilizó el paquete `lme4` [@bates2015] para las regresiones, excepto para el caso de la regresión bayesiana, el cuál utilizó el paquete `brms`[@burkner2017]. Para obtener las medias marginales de los modelos y realizar los contrastes de las medias se utilizó el paquete `emmeans`.

# Resultados y discusión

```{r librerias}
#| include: false

# Básicas 
library(tidyverse)

# plots
library(gridExtra)
library(grid)
library(plotly)
# library(viridis)
library(viridisLite)
library(patchwork)
library(hexbin)


# Bayes
library(brms)
library(modelbased)
library(see)
library(bayesplot)
library(bayestestR)


# Regresion
library(lme4)
library(emmeans)
library(modelr)
library(sjPlot)
library(gtsummary)
library(performance)
library(ggeffects)

# Tablas
library(flextable)
library(webshot)
library(report)

# Estadistica
library(rstatix)
library(ggpubr)

```

```{r datafrmaes}
#| include: false


df_wm <- read.csv("./datos/df_wm_clean.csv")

# recodificar a factores
df_wm$tratamientos <- as.factor(df_wm$tratamientos)
df_wm$id <- as.factor(df_wm$id)
df_wm$stage <- as.factor(df_wm$stage)
df_wm$prueba <- as.factor(df_wm$prueba)

# table(df_ent_post$tratamientos) ver tratamientos



df_wm_flx <- df_wm |> 
  dplyr::filter(tratamientos %in% c("Flx","Flx-CUMS", "Sal-CUMS-F"))

# table(df_wm_flx$tratamientos)

df_wm_otros <- df_wm |> 
  dplyr::filter(tratamientos %in% c("Ctrl","Ket-CUMS", "Sal-CUMS-K"))

# table(df_wm_otros$tratamientos)

df_wm_flx$tratamientos = factor(df_wm_flx$tratamientos, 
                            levels=c("Flx","Flx-CUMS", "Sal-CUMS-F"))

df_wm_otros$tratamientos = factor(df_wm_otros$tratamientos, 
                            levels=c("Ctrl", "Ket-CUMS", "Sal-CUMS-K"))
```

## Entrenamientos

### Latencias


```{r datafrmaesLatencias}
#| include: false

latencias_pre <- df_wm_flx |> 
  select(latencia, id, tratamientos, stage, dia, tiempo, prueba) |> 
  dplyr::filter(str_detect(prueba, "Entr"))


latencias_post <- df_wm_flx |> 
  select(latencia, id, tratamientos, stage, dia, tiempo, prueba) |> 
  dplyr::filter(str_detect(prueba, "Reversa"))


latencias_pre$censurado = ifelse(latencias_pre$latencia== 60, 1, 0)
latencias_pre$Censurado = ifelse(latencias_pre$latencia==60, "SI", "NO")

latencias_post$censurado = ifelse(latencias_post$latencia== 60, 1, 0)
latencias_post$Censurado = ifelse(latencias_post$latencia==60, "SI", "NO")


```


La latencia de escape es una de las métricas más utilizadas para evaluar el aprendizaje en el laberinto acuático de Morris ({{< glossary MWM >}}). Este parámetro cuantifica el tiempo, en segundos, que tardan los ratones en localizar la plataforma durante los días de entrenamiento, que incluyen cuatro sesiones en la configuración original y dos en la fase reversa. Esta métrica es crucial para evaluar el aprendizaje en el {{< glossary MWM >}}, dado que a medida que los roedores aprenden la ubicación de la plataforma oculta, el tiempo requerido para alcanzarla se reduce, evidenciando una menor latencia. No obstante, esta métrica no considera si el aprendizaje observado depende específicamente del hipocampo, como señalan estudios anteriores [@garthe2013].

Además, los métodos estadísticos comúnmente empleados para analizar esta métrica no siempre son los más adecuados para modelar adecuadamente el comportamiento de los roederes. El análisis estadístico de esta prueba debería tener en cuenta los siguientes aspectos [@young2021]:

i.   Reconocer que los datos de un mismo día para un mismo animal, así como los datos de un animal a lo largo de los días, están altamente correlacionados.
i.   Modelar el {{< glossary "efecto piso" >}} y el {{< glossary "effecto techo" >}} en el rendimiento, lo que introduce una asimetría en la relación entre la latencia y los ensayos (@fig-histogramasdensidad). Estos efectos dificultan obtener medidas de tendencia central y comparar medias entre grupos.
i.   Considerar la {{< glossary "censura de datos" >}} que se produce cuando se alcanza el valor límite de $60$ segundos. Esta censura subestima la media y la varianza, lo que conlleva a una disminución artificial en las latencias reportadas.

Aunque el análisis de varianza de medidas repetidas ({{< glossary "RM-ANOVA" >}}), comúnmente utilizado, intenta abordar el primer problema, no considera adecuadamente los dos últimos. Como mostró @young2009, analizar las latencias de escape con {{< glossary "RM-ANOVA" >}} puede resultar en una alta tasa de errores de {{< glossary "error de tipo I"  >}} y {{< glossary "error de tipo II" >}} , en comparación con otros análisis, como los modelos lineal con efectos mixtos o los modelos lineales generalizados con distribuciones no normales.

Para superar estos desafíos, se puede emplear un modelo de regresión bayesiana con efectos mixtos [@young2021]. Este modelo permite utilizar una distribución no normal que tenga un mínimo de $0$ (ya que las latencias no pueden ser menores o iguales a 0) y una cola superior prolongada (modelar correctamente el {{< glossary "efecto piso" >}} y el {{< glossary "effecto techo" >}}). Las distribuciones de latencia son típicamente sesgadas debido al aprendizaje (@fig-histogramasdensidad). Bajo estos supuestos, se pueden utilizar distribuciones Gamma o Weibull, las cuales se ajustan mejor a este tipo de datos.

```{r distribucioneslatencias}
#| echo: false
#| label: fig-histogramasdensidad
#| fig-cap: "Densidad de los valores de latencia (versión suavizada de un histograma). Se observa cómo los datos claramente no siguen una distribución normal. Líneas puntadas marcan la media."
#| fig-subcap: 
#|   - "Entrenamientos Originales"
#|   - "Entrenamientos Reversa"
#| layout-ncol: 2

# mean
library(plyr)

cdat <- ddply(latencias_pre, "tratamientos", summarise, rating.mean=mean(latencia))


latencias_pre |> 
  ggplot(aes(x = latencia, color = tratamientos, fill = tratamientos)) +
  geom_density(alpha = 0.15) +
  geom_vline(data=cdat, aes(xintercept=rating.mean,  colour=tratamientos),
               linetype="dashed", size=1) +
  ylim(0, 0.06) +
  scale_color_manual(values = c("#222831", "#00ADB5", "#FF2E63", "#FF9800", "#8675A9", "#F2AFEF")) +
  scale_fill_manual(values = c("#222831", "#00ADB5", "#FF2E63", "#FF9800", "#8675A9", "#F2AFEF")) +
  labs(
    # title = "Latencias Entrenamientos Originales",
    # caption = "Líneas puntadas marcan la media",
    color = "Tratamientos",
    fill = "Tratamientos",
    x = "Valor de Latencia (s)",
    y = "Densidad") +
  # ggthemes::theme_base() +
  ggthemes::theme_clean() +
  theme(legend.position='top', axis.text = element_text(size = 12),axis.title = element_text(size = 15))


cdatpost <- ddply(latencias_post, "tratamientos", summarise, rating.mean=mean(latencia))


latencias_post |> 
  ggplot(aes(x = latencia, color = tratamientos, fill = tratamientos)) +
  geom_density(alpha = 0.15) +
  ylim(0, 0.06) +
  geom_vline(data=cdatpost, aes(xintercept=rating.mean,  colour=tratamientos),
               linetype="dashed", size=1) +
  scale_color_manual(values = c("#222831", "#00ADB5", "#FF2E63", "#FF9800", "#8675A9", "#F2AFEF")) +
  scale_fill_manual(values = c("#222831", "#00ADB5", "#FF2E63", "#FF9800", "#8675A9", "#F2AFEF")) +
  labs(
    # title = "Latencias Entrenamientos Reversa",
    # caption = "Líneas puntadas marcan la media",
    color = "Tratamientos",
    fill = "Tratamientos",
    x = "Valor de Latencia (s)",
    y = "Densidad") +
  # ggthemes::theme_base() +
  ggthemes::theme_clean() +
  theme(legend.position='top', axis.text = element_text(size = 12),axis.title = element_text(size = 15))



```


Por último, al utilizar una regresión Bayesiana con la {{< glossary "distribución de probabilidad a priori" >}} propuesta por @young2021, es posible considerar los datos censurados y no reducir artificialmente las latencias ni varianzas. Como menciona Young, considerar esta censura de datos es relevante cuando estamos tratando de entender si existen diferencias en el aprendizaje del MWM en nuestros grupos experimentales.

En los primeros días del entrenamiento, todos los grupos experimentales tienen valores censurados que disminuyen con cada día del entrenamiento (@fig-latenciascencuradospre). Por otro lado, el grupo de `Salina+CUMS` parece tener una mayor proporción de datos censurados en el primer día de entrenamientos reversa (@fig-scatviolinpost). 


```{r violinscatter}
#| eval: false
#| include: false

# scatter plot 
lat_scat_post <- ggplot(latencias_post, aes(x = tiempo, y = latencia, color = Censurado)) +
  geom_jitter(aes(shape = Censurado), size = 5) +
  facet_grid(~ tratamientos) +
  ylim(0, 60) +
  scale_shape_manual(values = c(20, 4)) +
  scale_color_manual(values = c("#A5DEE5", "#850E35")) +
  xlab("Prueba") +
  ylab("Segundos") +
  # labs(
  #   # title = "Latencia de Escape",
  # tag = "A") +
  ggthemes::theme_base()

##  violin 

# Escala de colores
colours <- scales::viridis_pal(option = "viridis")(10)
grad_ungroup <- grid::linearGradient(colours, group = FALSE)

lat_post <- ggplot(latencias_post, aes(x=factor(dia), y= latencia)) +
  # geom_violin(scale="width", aes(fill = latencia)) + 
  geom_violin(scale="width", fill = grad_ungroup) + 
  facet_grid(~ tratamientos) +
  # facet_wrap(~ tratamientos, scales='free') +
  labs(
    #title = "Latencia de Escap",
    x = "Prueba",
    y = "Segundos") +
  # theme_classic()
  # ggthemes::theme_clean()
  ggthemes::theme_base()


lat_post <-  (lat_scat_post / lat_violin_post) +
  plot_annotation(
    tag_levels = 'A'
  )

lat_post
```


::: {#fig-latenciascensurados layout-ncol=2}
![Entrenamientos Originales](figuras/latencias_scatviolin_pre.png){#fig-latenciascencuradospre}


![Entrenamientos Reversa](figuras/latencias_scatviolin_post.png){#fig-scatviolinpost}

Censura de datos en latencias de escape. En la parte superior, el gráfico de dispersión muestra en rojo los datos censurados. En la parte inferior, una alta densidad en la marca de 60 segundos resalta la censura de datos. 
:::


```{r modeladosestadistica}
#| include: false

contrasts(latencias_pre$tratamientos) = contr.sum(3) # contrast encoding - represent categorical variable numerically
contrasts(latencias_post$tratamientos) = contr.sum(3) # contrast encoding - represent categorical variable numerically

latencias_pre$tiempo_centrado = latencias_pre$tiempo - mean(latencias_pre$tiempo) # centrar variable de día (0 = mean of variable) coefficients easier, convergence, reduce multicol
latencias_post$tiempo_centrado = latencias_post$tiempo - mean(latencias_post$tiempo) # centrar variable de día (0 = mean of variable) coefficients easier, convergence, reduce multicol

### PRIORS

priors = c(
  prior("student_t(3, 4.5, .25)", class = "Intercept"),
  prior("student_t(3, 0, .25)", class = "sd"),
  prior(
    "student_t(3, 0, .1)",
    class = "sd",
    coef = "tiempo_centrado",
    group = "id" ## o sera treatment?
  ),
  prior_string(
    "student_t(3, 0, 0.5)",
    class = "b",
    coef = paste("tratamientos", 1:2, sep = "")
  ),
  prior_string("student_t(3,-.2, .1)", class = "b", coef = "tiempo_centrado"),
  prior_string(
    "student_t(3, 0, 0.1)",
    class = "b",
    coef = paste("tiempo_centrado:tratamientos", 1:2, sep = "")
  )
)


### Bayes con distribución Gamma

b1.c <-
  brm(
    latencia |
      cens(censurado) ~ tiempo_centrado * tratamientos + (tiempo_centrado |
                                                      id),
    family = Gamma(link = "log"),
    data = latencias_post,
    init = "0",
    iter = 4000,
    prior = priors,
    save_pars = save_pars(all = TRUE),
    control = list(adapt_delta = 0.95)
  )

b1.c.pre <-
  brm(
    latencia |
      cens(censurado) ~ tiempo_centrado * tratamientos + (tiempo_centrado |
                                                      id),
    family = Gamma(link = "log"),
    data = latencias_pre,
    init = "0",
    iter = 4000,
    prior = priors,
    save_pars = save_pars(all = TRUE),
    control = list(adapt_delta = 0.95)
  )


### GLM

b1.ignore <-
  brm(
    latencia ~ tiempo_centrado * tratamientos + (tiempo_centrado |
                                              id),
    family = Gamma(link = "log"),
    data = latencias_post,
    init = "0",
    iter = 4000,
    prior = priors,
    save_pars = save_pars(all = TRUE),
    control = list(adapt_delta = 0.95)
  )

b1.ignore.pre <-
  brm(
    latencia ~ tiempo_centrado * tratamientos + (tiempo_centrado |
                                              id),
    family = Gamma(link = "log"),
    data = latencias_pre,
    init = "0",
    iter = 4000,
    prior = priors,
    save_pars = save_pars(all = TRUE),
    control = list(adapt_delta = 0.95)
  )


#### EFECTOS MIXTOS 

priors = c(
  prior("student_t(3, 90, 45)", class = "Intercept"),
  prior_string(
    "student_t(3, 0, 35)",
    class = "b",
    coef = paste("tratamientos", 1:2, sep = "")
  ),
  prior_string("student_t(3,-5, 5)", class = "b", coef = "tiempo_centrado"),
  prior_string(
    "student_t(3, 0, 5)",
    class = "b",
    coef = paste("tiempo_centrado:tratamientos", 1:2, sep = "")
  )
)

bn <- brm(
  latencia ~ tiempo_centrado * tratamientos + (tiempo_centrado | id),
  data = latencias_post,
  init = "0",
  iter = 4000,
  prior = c(set_prior("student_t(3,-25,25)", class = "b")),
  save_pars = save_pars(all = TRUE)
)


bn.pre <- brm(
  latencia ~ tiempo_centrado * tratamientos + (tiempo_centrado | id),
  data = latencias_pre,
  init = "0",
  iter = 4000,
  prior = c(set_prior("student_t(3,-25,25)", class = "b")),
  save_pars = save_pars(all = TRUE)
)


##### ANOVA

library(gt)

myData.mean.lat.pre <- aggregate(latencias_pre$latencia,
                                 by = list(latencias_pre$prueba, 
                                           latencias_pre$tratamientos,
                                           latencias_pre$id),
                                 FUN = 'mean')

myData.mean.lat.post <- aggregate(latencias_post$latencia,
                         by = list(latencias_post$prueba, 
                                   latencias_post$tratamientos,
                                   latencias_post$id),
                         FUN = 'mean')

colnames(myData.mean.lat.pre) <- c("prueba","tratamientos","id","latencia")

colnames(myData.mean.lat.post) <- c("prueba","tratamientos","id","latencia")

## Modelo 

aov_latencias_pre <- aov(latencia ~ tratamientos * prueba + Error(id), 
                          data = myData.mean.lat.pre)

aov_latencias_post <- aov(latencia ~ tratamientos * prueba + Error(id), 
                          data = myData.mean.lat.post)



```


Para tomar en cuenta estos datos censurados, ajustamos un modelo Bayesiano lineal generalizado (distribución Gamma) con efectos mixtos para predecir las latencias a través de los entrenamientos en los distintos tratamientos (fórmula `Latencia|censurados ~ tiempo * tratamientos`). El modelo incluye al tiempo y sujetos como efectos aleatorios (fórmula `1 + tiempo | id`). Es decir, la pendiente de la latencia en el tiempo puede variar por sujetos. Esto permite capturar el fenómeno donde la relación entre Latencia y tiempo puede diferir entre diferentes sujetos.

Adicionalmente, se modelaron los datos con un modelo generalizado (distribución Gamma) con efectos mixtos (sin datos censurados) y una regresión lineal con efectos mixtos (con distribución normal) (@fig-latenciabayesjuntos). Al comparar los tres modelos a partir de distintos criterios de información (@tbl-regbayscomps) [@gelman2014 ], se comprobó que el modelo bayesiano ajusta mejor los datos, seguido del modelo generalizado y por último el modelo lineal. Estos criterios son evidencia que los estimados obtenidos a partir del modelo bayesiano serán más confiables que con los otros modelos. Además, el coeficiente de determinación $R^2$ (proporción de la variación en la variable dependiente que puede ser explicado por las variables independientes) también mejora al considerar una distribución Gamma en comparación con una distribución normal. Por último, el índice de correlación de intraclase (*Intraclass correlation*) de 0.89 soporta la alta correlación de nuestros, soportando el uso de efectos mixtos (Ver tabla de regresión completa de los 3 modelos en Anexo @tbl-tablalatenciasregresionespost) [@chen2017a].


| Modelo          | ELPD      | LOOIC  | WAIC   |
| --------------- | --------- | ------ | ------ |
| Bayes Censurado | \-529.248 | 1058.5 | 1049.7 |
| GLM             | \-629.861 | 1259.7 | 1253.0 |
| Modelo lineal   | \-769.128 | 1538.3 | 1536.0 |
: "Criterios de información para los tres modelos. Expected log predictive density (ELPD), donde un mayor número es lo deseado. Leave-one-out cross-validation information criterion (LOOIC),  donde un valor menor es deseado. Widely applicable information criterion (WAIC), donde un menor valor es deseado. En todos los criterios, el modelo Bayesiano tiene los mejores puntajes, seguido del GLM."  {#tbl-regbayscomps .striped .hover}


Para la regresión Bayesiana, se utilizó la distribución previa propuesta por @young2021 (t-student, regresión {{< glossary "location-scale" >}}, **location** = 4.50, **scale** = 0.25). El poder predictivo del modelo es substancial (`R2 = 0.53, 95% CI [0.50, 0.58]`). El modelo fue estimado con métodos de Montecarlo basados en cadenas de Markov (4 cadenas con 4000 iteraciones y 2000 de calentamiento).



```{r bayesInfoCriteria}
#| eval: false
#| include: false


compare_performance(b1.c.pre,b1.ignore.pre, bn.pre)

compare_performance(b1.c,b1.ignore, bn)


waic(b1.c,b1.ignore, bn)


model_performance(b1.c)
model_performance(b1.ignore)
model_performance(bn)
```


Para visualizar las medias estimadas por los 3 modelos, se graficaron las medias marginales estimadas. Estas medias marginales se calculan ajustando por otros factores o covariables en el modelo (en nuestro caso, la interacción de tiempo y tratamientos). Esto significa que representan el efecto medio de un factor específico, controlando o ‘promediando’ los efectos de los otros factores. Esto es útil en experimentos con diseños complejos o con múltiples factores y niveles. 

Las medias marginales consideran toda la estructura del modelo, incluyendo efectos fijos y aleatorios. Esto las hace especialmente relevantes para la interpretación en modelos de efectos mixtos, donde los efectos aleatorios juegan un rol crucial. Además, proveen una base para hacer predicciones ajustadas y generalizables más allá del conjunto de datos actual, especialmente en modelos predictivos que incluyen variables aleatorias y fijas.

La gran diferencia con las medias calculadas, las cuales son simplemente el promedio aritmético de los datos observados dentro de cada grupo o nivel de factor, es que estas últimas no ajustan por la posible confusión de otros factores o la estructura de dependencia dentro de los datos (como en los datos agrupados o jerárquicos). Además, las medias calculadas pueden estar sesgadas porque el número de observaciones en cada grupo puede ser diferente.




```{r bayeslatenciasplotspredict}
#| include: false
#| output: false


b1.c_effects_plot.pre <- plot(conditional_effects(b1.c.pre, effects = "tiempo_centrado:tratamientos", prob=.66))[[1]]

b1.ignore_effects_plot.pre <- plot(conditional_effects(b1.ignore.pre, effects = "tiempo_centrado:tratamientos", prob=.66))[[1]] 

bn_effects_plot.pre <- plot(conditional_effects(bn.pre, effects = "tiempo_centrado:tratamientos", prob=.66))[[1]] 

b1.c_effects_plot <- plot(conditional_effects(b1.c, effects = "tiempo_centrado:tratamientos", prob=.66))[[1]] 

b1.ignore_effects_plot <- plot(conditional_effects(b1.ignore, effects = "tiempo_centrado:tratamientos", prob=.66))[[1]]

bn_effects_plot <- plot(conditional_effects(bn, effects = "tiempo_centrado:tratamientos", prob=.66))[[1]]



```

```{r bayesSlopes}
#| eval: false
#| echo: false


table(latencias_post$tiempo_centrado)

emmeans(b1.c.pre, ~tratamientos, type="response", at=list(tiempo_centrado= -1.86950549450549))

emmeans(b1.c.pre, ~tratamientos, type="response", at=list(tiempo_centrado= 1.88049450549451))

emmeans(b1.c, ~tratamientos, type="response", at=list(tiempo_centrado= -0.875))

emmeans(b1.c, ~tratamientos, type="response", at=list(tiempo_centrado= 0.375))
  # as.tibble() |>
  # flextable()
#   
# slopes
emtrends(b1.c.pre, ~tratamientos, var="tiempo_centrado") 

emtrends(b1.c, ~tratamientos, var="tiempo_centrado") 
  # as.tibble() |>
  # flextable()


```

```{r bayeslatenciasplotspre}
#| echo: false
#| label: fig-bayeslatenciasplotspre
#| fig-cap: "Medias Marginales Estimadas para los 3 modelos en Entrneamientos Originales. De izquierda a derecha: Modelo Bayesiano de efectos mixtos tomando en cuenta los valores censurados (distribución gamma), Modelo lineal generalizado de efectos mixtos sin tomar en cuenta los valores censurados (distribución gamma), Modelo de efectos mixtos sin tomar en cuenta los valores censurados (distribución normal). Graficados con intervalos de densidad más alta al 66% para resaltar los valores más probables del parámetro. El tiempo está centrado y representa los cuatro días de entrenamientos originales."

b1.c_effects_plot.pre <- b1.c_effects_plot.pre  +
  ggplot2::ylim(0,80) +
  theme_classic() +
  scale_color_manual(values = c("#222831", "#00ADB5", "#FF2E63", "#FF9800", "#8675A9", "#862B0D")) +
  scale_fill_manual(values = c("#222831", "#00ADB5", "#FF2E63", "#FF9800", "#8675A9", "#862B0D")) +
  labs(
    # caption = "Plotted with 66% Credible Intervals",
    color = "Tratamientos",
    fill = "Tratamientos",
    shape = "Tratamientos",
    x = "Tiempo",
    y = "Segundos") +
  theme(legend.position='top', axis.text = element_text(size = 12),axis.title = element_text(size = 15))


b1.ignore_effects_plot.pre <- b1.ignore_effects_plot.pre +
  ggplot2::ylim(0,80)+
  theme_classic() +
  scale_color_manual(values = c("#222831", "#00ADB5", "#FF2E63", "#FF9800", "#8675A9", "#862B0D")) +
  scale_fill_manual(values = c("#222831", "#00ADB5", "#FF2E63", "#FF9800", "#8675A9", "#862B0D")) +
  labs(
    # caption = "Plotted with 66% Credible Intervals",
    color = "Tratamientos",
    fill = "Tratamientos",
    shape = "Tratamientos",
    x = "Tiempo",
    y = "Segundos") +
  theme(legend.position='top', axis.text = element_text(size = 12),axis.title = element_text(size = 15)) 


bn_effects_plot.pre <-  bn_effects_plot.pre  +
  ggplot2::ylim(0,80)+
  theme_classic() +
  scale_color_manual(values = c("#222831", "#00ADB5", "#FF2E63", "#FF9800", "#8675A9", "#862B0D")) +
  scale_fill_manual(values = c("#222831", "#00ADB5", "#FF2E63", "#FF9800", "#8675A9", "#862B0D")) +
  labs(
    # caption = "Plotted with 66% Credible Intervals",
    color = "Tratamientos",
    fill = "Tratamientos",
    shape = "Tratamientos",
    x = "Tiempo",
    y = "Segundos") +
  theme(legend.position='top', axis.text = element_text(size = 12),axis.title = element_text(size = 15)) 


bay_effect_plots.pre <- b1.c_effects_plot.pre + b1.ignore_effects_plot.pre + bn_effects_plot.pre + 
  plot_annotation(tag_levels = 'i') + 
  plot_layout(guides = 'collect', axis_titles = 'collect') &
  theme(legend.position = 'top')

bay_effect_plots.pre




```



| Tratamiento | Latencia inicial | Latencia Final | Pendiente |
| ----------- | ---------------- | -------------- | --------- |
| Flx         | 62.1             | 10.96          | \-0.464   |
| Flx-CUMS    | 32.8             | 7.85           | \-0.381   |
| Sal-CUMS-F  | 46.2             | 12.86          | \-0.340   |
: Parámetros estimados para las latencias originales a partir del modelo Bayesiano.  {#tbl-paramsbaypre .striped .hover}

```{r bayeslatenciasplots}
#| echo: false
#| label: fig-latenciabayesjuntos
#| fig-cap: "Medias Marginales Estimadas para los 3 modelos en Entrneamientos Reversa. De izquierda a derecha: Modelo Bayesiano de efectos mixtos tomando en cuenta los valores censurados (distribución gamma), Modelo lineal generalizado de efectos mixtos sin tomar en cuenta los valores censurados (distribución gamma), Modelo de efectos mixtos sin tomar en cuenta los valores censurados (distribución normal). Graficados con intervalos de densidad más alta al 66% para resaltar los valores más probables del parámetro. El tiempo está centrado y representa los dos días de entrenamientos reversa."




b1.c_effects_plot <- b1.c_effects_plot +
  ggplot2::ylim(0,180) +
  theme_classic() +
  scale_color_manual(values = c("#222831", "#00ADB5", "#FF2E63", "#FF9800", "#8675A9", "#862B0D")) +
  scale_fill_manual(values = c("#222831", "#00ADB5", "#FF2E63", "#FF9800", "#8675A9", "#862B0D")) +
  labs(
    # caption = "Plotted with 66% Credible Intervals",
    color = "Tratamientos",
    fill = "Tratamientos",
    shape = "Tratamientos",
    x = "Tiempo",
    y = "Segundos") +
  theme(legend.position='top', axis.text = element_text(size = 12),axis.title = element_text(size = 15))


b1.ignore_effects_plot <- b1.ignore_effects_plot +
  ggplot2::ylim(0,180)+
  theme_classic() +
  scale_color_manual(values = c("#222831", "#00ADB5", "#FF2E63", "#FF9800", "#8675A9", "#862B0D")) +
  scale_fill_manual(values = c("#222831", "#00ADB5", "#FF2E63", "#FF9800", "#8675A9", "#862B0D")) +
  labs(
    # caption = "Plotted with 66% Credible Intervals",
    color = "Tratamientos",
    fill = "Tratamientos",
    shape = "Tratamientos",
    x = "Tiempo",
    y = "Segundos") +
  theme(legend.position='top', axis.text = element_text(size = 12),axis.title = element_text(size = 15)) 


bn_effects_plot <- bn_effects_plot +
  ggplot2::ylim(0,180)+
  theme_classic() +
  scale_color_manual(values = c("#222831", "#00ADB5", "#FF2E63", "#FF9800", "#8675A9", "#862B0D")) +
  scale_fill_manual(values = c("#222831", "#00ADB5", "#FF2E63", "#FF9800", "#8675A9", "#862B0D")) +
  labs(
    # caption = "Plotted with 66% Credible Intervals",
    color = "Tratamientos",
    fill = "Tratamientos",
    shape = "Tratamientos",
    x = "Tiempo",
    y = "Segundos") +
  theme(legend.position='top', axis.text = element_text(size = 12),axis.title = element_text(size = 15)) 


bay_effect_plots <- b1.c_effects_plot + b1.ignore_effects_plot + bn_effects_plot + 
  plot_annotation(tag_levels = 'i') + 
  plot_layout(guides = 'collect', axis_titles = 'collect') &
  theme(legend.position = 'top')

bay_effect_plots

```

| Tratamiento | Latencia inicial | Latencia Final | Pendiente |
| ----------- | ---------------- | -------------- | --------- |
| Flx         | 41.3             | 3.85           | \-1.91    |
| Flx-CUMS    | 65.2             | 6.85           | \-1.82    |
| Sal-CUMS-F  | 109.2            | 8.38           | \-2.05    |
: Parámetros estimados para las latencias Reversa a partir del modelo Bayesiano.  {#tbl-paramsbaypost .striped .hover}



En la @fig-latenciabayesestimados, se utilizan intervalos de credibilidad al 89% para describir la incertidumbre relacionada a los estimados. Conceptualmente son similares a los intervalos de confianza, aunque la interpretación es más sencilla: dados los datos observados, el efecto tiene un 89% de probabilidad de estar dentro de este rango. A partir de esta probabilidad del IC (89%), podemos determinar la proporción de datos que cae dentro de la región *ROPE*, la cual puede ser conceptualizada como la región de no efecto. Si la mayoría de  los valores con mayor probabilidad caen dentro de la región *ROPE*, no tenemos evidencia para rechazar la hipótesis nula. Si la mayoría de los valores caen fuera de la región *ROPE*, rechazamos la hipótesis nula. Se utiliza una región de ROPE de $-0.10$ a $0.10$, basada en la definición de Cohen para un tamaño de efecto pequeño [@kruschke2018]. A comparación de la interacción de  `Tiempo:Flx`, la interacción de `Tiempo:Flx + CUMS`, estamos indecisos sobre su efecto en latencia (intervalos al .89 [-0.17  0.22], 72.08% dentro de ROPE), mientras que la interacción de `Tiempo:Salina + CUMS` también tiene un efecto que no nos permite concluir ni rechazar la hipótesis nula (intervalos al .89 [-0.11  0.44], 58.60% dentro de ROPE).


```{r bayesefectos}
#| echo: false
#| label: fig-latenciabayesestimados
#| fig-cap: "Efectos de los estimados en Latencias Reversa calculados por el modelo Bayesiano con regresión. Graficados con intervalos de credibilidad al 89%. El efecto de tiempo x Flx-CUMS  tiene 56.96%  de probabilidad de ser positivo, 38.22% de ser significativo  y 3.38% de ser un efecto grande. La estimación convergió con éxtio (Rhat = 1.000) y los índices son confiables (ESS = 4939). El efecto de tiempo x Salina-CUMS tiene 73.79%  de probabilidad de ser positivo, 57.20% de ser significativo, y 12.07% de ser un efecto grande . La estimación convergió con éxtio (Rhat = 1.001) y los índices son confiables (ESS =  4024). Los efectos fueron calculados siguiendo el marco de Prueba de significancia y existencia de efectos (SEXIT). De acuerdo a este marco, no se da un p-value que de manera dicotómica acepte o rechaze nuestra hipótesis nula, sino que describe 3 probabilidades: de dirección, de significancia y de tamño del efecto."
#| fig-subcap: 
#|   - "Estimados de los parámetros de entrenamientos bayesianos con Medias. Con una línea roja se resalta la región de no efecto. El color azúl en los estimados representa una probabilidad de dirección positiva, mientras que el color rojo una probabilidad de dirección negativa."
#|   - "Distribución de los parámetros y región ROPE. La inferencia Bayesiana nos permite calcular la distribución posterior de posibles valores y comparar contra la región ROPE para aceptar o rechazar un efecto."
#| layout-ncol: 2



bayes_bpe_post_latencias <- plot_model(b1.c,
           vline.color = "red", # no effect
           bpe = "mean", # mean point estimate
           bpe.style = "dot",
           colors = "Dark2",
           show.values = TRUE,
           show.legend = T,
           axis.labels =  rev(c("Tiempo",
                           "Flx-CUMS", "Sal-CUMS-F",
                           "Tiempo:Flx-CUMS", "Tiempo:Sal-CUMS-F"
                           )
),
            transform = NULL # exponentiates coefficients, if appropriate (e.g. for models with log or logit link
            ) +
  ggthemes::theme_clean() +
  ggplot2::ggtitle("") +
  ggplot2::scale_color_manual(values = c("#FF2E63", "#00ADB5")) +
  ggplot2::scale_fill_manual(values = c("#FF2E63", "#00ADB5")) +
  ggplot2::labs(
    y = "Estimados"
  ) +
  ggplot2::theme(legend.position='top', axis.text = element_text(size = 12),axis.title = element_text(size = 15))

bayes_bpe_post_latencias

plot_rope <- plot(rope(b1.c, ci = .89)) +
  ggthemes::theme_clean()  +
  ggplot2::scale_color_manual(values = c("#00ADB5", "#FF2E63")) +
  ggplot2::scale_fill_manual(values = c("#00ADB5", "#FF2E63")) +
  ggplot2::ggtitle("") +
  ggplot2::labs(
    x = "Estimados",
    y = ""
  ) +
  ggplot2::theme(legend.position='top', axis.text = element_text(size = 12),axis.title = element_text(size = 15))  

plot_rope


```

A partir de este análisis, podemos conluir lo siguiente:

i. Utilizar modelados que incluya una distribución gamma, mejora el modelado de los datos en los entrenamientos de latencia. Esto es evidenciado con los criterios de información (@tbl-regbayscomps) y el coeficiente de determinación (@tbl-tablalatenciasregresionespost). Además, al utilizar esta distribución se captura correctamente el efecto piso que se crea como consecuencia del aprendizaje en el segundo día del entrenamiento (tiempos $0.0$ a $0.5$ en la @fig-latenciabayesjuntos).
i. Incorporar los datos censurados resalta la diferencia de los grupos experimentales, en especial en el primer día del entrenamiento reversa (@tbl-paramsbaypost). 
i. La mayor diferencia en los entrenamientos reversa se observa en el primer día (correspondiente a los valores de $-0.5$ a $0.0$ en la @fig-latenciabayesjuntos). Sin embargo, en el último día la latencia final termina siendo similar para todos los grupos. Esto indica que todos los grupos tienen un aprendizaje en la prueba, aunque no podemos concluir si este aprendizaje es dependiente del hipocampo, como veremos en los siguientes resultados. 



### Estrategias de búsqueda

```{r dataframesEstrategias}
#| echo: false

estrategias_df <- read.csv("./datos/rtrack/exportado_estrategias_final.csv") |> 
  # exportado_estrategias_final_thresholded.csv
  janitor::clean_names() |> 
  dplyr::select(x_target_id, x_day, x_trial, stage, tratamiento, name) |> 
  
  dplyr::mutate(estrategias = case_when(name %in% c("corrected path", "direct path", "directed search") ~ 1, # hipocampo_dependientes 
                                        name %in% c("chaining",  "random path", "scanning", "thigmotaxis") ~ 0, # hipocampo_independientes
                                        name %in% c("perseverance") ~ 3)
  ) |> 
  
  dplyr::mutate(estrategias_hipo = case_when(name %in% c("corrected path", "direct path", "directed search") ~ "hipocampo_dependientes",   
                                             name %in% c("chaining",  "random path", "scanning", "thigmotaxis") ~ "hipocampo_independientes", # 
                                             name %in% c("perseverance") ~ "perseverancia")
  )

## ---- porcentajes-summary
## counts how many times each strategy was used by each group on each day


estrategias_porcentajes_df_pre <- estrategias_df |> 
  dplyr::filter(str_detect(stage, "entrenamiento")) |>
  dplyr::filter(!str_detect(stage, "entrenamiento_rev")) |>
  dplyr::filter(!str_detect(tratamiento, "K")) |>
  dplyr::group_by(stage, tratamiento, estrategias_hipo) |>
  dplyr::summarise(cnt = n()) |> 
  dplyr::mutate(freq = round(cnt / sum(cnt), 3),
         # dia = case_when(stage == "entrenamiento_rev_1" ~ 1,
                         # stage == "entrenamiento_rev_2" ~ 2),
         porcentaje = freq * 100) |> 
  dplyr::ungroup()


estrategias_porcentajes_df <- estrategias_df |> 
  dplyr::filter(str_detect(stage, "entrenamiento_rev")) |>
  dplyr::filter(!str_detect(tratamiento, "K")) |>
  dplyr::group_by(stage, tratamiento, estrategias_hipo) |>
  dplyr::summarise(cnt = n()) |> 
  dplyr::mutate(freq = round(cnt / sum(cnt), 3),
                dia = case_when(stage == "entrenamiento_rev_1" ~ 1,
                                stage == "entrenamiento_rev_2" ~ 2),
                porcentaje = freq * 100) |> 
  dplyr::ungroup()



```

Desde 1982, @place_morris_1982 entendía las limitaciones de utilizar las latencias de escape como una medida del aprendizaje espacial. En este artículo, Morris y colaboradores removieron por aspiración el hipocampo ventral y dorsal de ratas y observaron que estos animales, aunque aprendían la localización de la plataforma con el tiempo (menor latencia de escape), tomaban rutas menos directas hacia la plataforma en comparación de los controles. Para tratar de evaluar si el aprendizaje en los entrenamientos tenía un componente espacial, @developments_morris_1984 y colaboradores desarrollaron un sistema de análisis de la ruta de escape que cuantificaba la direccionalidad de la búsqueda (ángulo hacia la plataforma). Utilizando ratones con lesiones hipocampales y corticales, este artículo identificó que el aprendizaje espacial podía ser evaluado con la direccionalidad de la trayectoria del animal: a medida que el aprendizaje espacial mejoraba, el animal tomaba una direccionalidad más precisa hacia la plataforma (una linea recta). 

Navegar por un nuevo entorno requiere varios procesos neurológicos, como prestar atención a los puntos de referencia, mapear su organización espacial relativa al agente, fijarse en una ubicación objetivo y trazar la mejor trayectoria espacial para alcanzarla. Las subregiones del hipocampo desempeñan roles distintos clave en tales procesos computacionales. El hipocampo desempeña un papel crucial en el aprendizaje espacial **alocéntrico**, que implica comprender las relaciones espaciales entre objetos de manera independiente del punto de vista. Las células de lugar en el hipocampo crean mapas cognitivos que permiten la navegación y orientación espacial. Además, las regiones CA3 y CA1 del hipocampo son esenciales para codificar y recuperar información espacial. El hipocampo integra información de la corteza entorrinal y parahipocampal, procesa tanto la navegación basada en la ruta como la actualización del mapa cognitivo mediante la integración del movimiento propio. Daños en el hipocampo, como en la enfermedad de Alzheimer o en el estrés crónico, afectan negativamente la capacidad de aprender y recordar mapas espaciales [@sharpening_berdugovega_2023].

Este papel del hipocampo en la capacidad de los roedores para resolver el laberinto de agua mediante la construcción de un mapa espacial alocéntrico está bien establecido [@eichenbaum1990]. En el MWM, las nuevas neuronas mejoran el rendimiento solo de aquellas tareas dependientes del hipocampo [@dupret2008], como el uso de estas estrategias alocéntricas [@garthe2016]. Por ejemplo, en un estudio, @garthe2009 suprimieron la neurogénesis adulta con temozolomida ({{< glossary TMZ add_to_table=true >}}) en ratones y evaluaron su rendimiento en una tarea del laberinto acuático de Morris, observando un déficit de aprendizaje altamente específico. Los ratones tratados con este fármaco mostraron limitaciones en adoptar estrategias de búsqueda espacialmente precisas, destacando el papel crucial de las nuevas neuronas en la flexibilidad y precisión del aprendizaje espacial. Estos hallazgos subrayan la importancia de las células granulares adultas en la generación de mapas métricos del entorno y vinculan directamente la plasticidad celular del hipocampo con la funcionalidad cognitiva. 


A pesar de la importancia de evaluar las estrategias de búsqueda para evaluar la función del hipocampo, históricamente ha sido difícil de evaluar esta métrica. Como señala @wolfer1992, las limitaciones en hardware y software han dificultado obtener y analizar esta métrica.  A finales de la década pasada, el grupo de Garthe y Kempermann [@garthe2009] definieron patrones de búsqueda que los ratones utilizan para encontrar la plataforma en el MWM durante los entrenamientos, aunque su análisis sigue siendo más complejo que obtener las latencias de escape. De manera general, las han definido en 2: estrategias alocéntricas y egocéntricas [@fig-entEstrategias]. Cuando los animales utilizan estrategias alocéntricas, se basan en la relación posicional entre las señales distales alrededor de la piscina para encontrar la plataforma, independientemente de su propia posición. En cambio, en la navegación egocéntrica, el animal representa la ubicación de la plataforma utilizando señales internas que dependen de su propia posición. La navegación alocéntrica depende más de la integridad y función del hipocampo que la navegación egocéntrica. De este modo, el análisis de las estrategias de búsqueda desarrolladas por los roedores durante el aprendizaje en el laberinto acuático de Morris es un parámetro adecuado para evaluar el aprendizaje espacial dependiente del hipocampo [@hernandez-mercado2022].



::: {#fig-entEstrategias layout-ncol=1}

![Estrategias Egocéntricas Aleatorias. Estas no están relacionadas con un intento a escapar del laberinto por medio de una búsqueda de la plataforma. En esta categoría se encuentran, de izquierda a derecha: tigmotaxis, aleatorio (caso 1), aleatorio (caso 2).](figuras/estrategias_random.jpg){#fig-estrategiasrandom}

![Estrategias Egocéntricas Procedurales. El contexto de la búsqueda es relativo al sujeto. En la izquierda, exploración (patrones repetitivos en un área), a la derecha, búsqueda en cadena (individuo sabe que la plataforma está a cierta distancia del muro y se mueve en circulos).](figuras/estrategias_chaining.jpg){#fig-estrategiachaining}

![Estrategias Alocéntricas. El individuo se mueve de forma dirigida y orientada a la plataforma. De izquierda a derecha: búsqueda dirigida (se mueve al blanco, aunque con errores que involucran cambios de orientación), búsqueda enfocada (se mueve casi sin errores hacia el blanco), nado directo (nada en línea recta hacia el blanco), perseverancia (búsqueda dirigida hacia blanco anterior). ](figuras/estrategias_directas.jpg){#fig-estrategiasalocentricas}

Estrategias de búsqueda en los entrenamientos del MWM. En A y B, estrategias independientes de hipocampo. En C, estrategias alocéntricas dependientes del hipocampo. En naranja se muestra la localización de la plataforma blanco. En gris se muestra la localización de la plataforma vieja (casos de entrenamiento reversa). El triángulo amarillo representa la zona ideal que debería de seguir el roedor para llegar al blanco. 

:::

Para cálcular las estrategias de búsqueda en el MWM, se utilizó el paquete de R "*Rtrack*" [@overall2020]. Overall, en colaboración con Garthe y Kempermann, toman como base las estrategias definidas por @garthe2009, pero mejoran el algorítmo de clasificación al utiliza un clasificador de *machine learning* (random forest, previamente entrenado con 3111 datos).

Para facilitar el análisis y debido a la falta de una *n* mayor (tanto en animales, como en tiempos), se agruparon las estrategias en 3 tipos (enfoque similar a @amelchenko2023): 

- Estrategias egocéntricas: tigmotáxis, búsqueda aleatoria y exploración (@fig-estrategiasrandom y @fig-estrategiachaining).

- Estrategias alocéntricas: búsqueda dirijida, búsqueda enfocada y nado directo (@fig-estrategiasalocentricas).

- Perseverancia. Se considera aparte debido a la importancia de este fenómeno en la evaluación de la flexibilidad cognitiva (@fig-estrategiasalocentricas). 


De acuerdo a estas clasificaciones, podemos calcular el porcentaje de estrategias utilizadas por día (@fig-porcentajesEstrategiasPlots).

```{r porcentajesEstrategiasPlots}
#| echo: false
#| label: fig-porcentajesEstrategiasPlots
#| fig-cap: "Porcentaje de Estrategias de búsqueda utilizadas en los entrenamientos."
#| fig-subcap: 
#|   - "Entrenamientos Originales"
#|   - "Entrenamientos Reversa"
#| layout-ncol: 1

estrategias_porcentajes_df_pre$estrategias_hipo = factor(estrategias_porcentajes_df_pre$estrategias_hipo, 
                                levels=c("hipocampo_dependientes","hipocampo_independientes"), 
                                labels = c("Alocéntricas","Egocéntricas"))

estrategias_porcentajes_df_pre |> 
  # dplyr::filter(str_detect(experimento, "Flx")) |>
  ggplot(
    aes(
      x = stage,
      y = freq,
      color = estrategias_hipo,
      fill = estrategias_hipo
      # label = porcentaje
    )) +
  geom_col(position = position_stack(reverse = TRUE)) +
  geom_label(aes(label = scales::percent(freq)), size = 4, position = position_stack(reverse = TRUE, vjust = 0.5), color = "black", show.legend = FALSE) +
  # geom_bar(stat = "identity") +
  scale_color_manual(values = c("#046582", "#BBBFCA", "#C86B85")) +
  scale_fill_manual(values = c("#046582", "#BBBFCA", "#C86B85")) +
  facet_wrap(vars(tratamiento)) +
  scale_x_discrete(name = "Dia", labels = c("1", "2", "3", "4")) +
  scale_y_continuous(name = "", labels = scales::percent_format()) +
  labs(fill = "", color = "") +
  ggthemes::theme_clean() +
  # ggthemes::theme_few() +
  theme(legend.position='top', axis.text = element_text(size = 12),axis.title = element_text(size = 15))


estrategias_porcentajes_df$estrategias_hipo = factor(estrategias_porcentajes_df$estrategias_hipo, 
                                levels=c("hipocampo_dependientes","hipocampo_independientes", "perseverancia"), 
                                labels = c("Alocéntricas","Egocéntricas", "Perseverancia"))

estrategias_porcentajes_df |> 
  ggplot(
    aes(
      x = stage,
      y = freq,
      color = estrategias_hipo,
      fill = estrategias_hipo,
      # label = porcentaje
    )) +
  geom_col(position = position_stack(reverse = TRUE)) +
  geom_label(aes(label = scales::percent(freq)), size = 4, position = position_stack(reverse = TRUE, vjust = 0.5), color = "black", show.legend = FALSE) +
  # geom_bar(stat = "identity") +
  scale_color_manual(values = c("#046582", "#BBBFCA", "#C86B85")) +
  scale_fill_manual(values = c("#046582", "#BBBFCA", "#C86B85")) +
  # scale_fill_paletteer_d("futurevisions::atomic_orange") +
  # scale_fill_paletteer_d("nbapalettes::hornets") +
  # scale_fill_paletteer_d("nbapalettes::timberwolves") +
  # scale_fill_paletteer_d("rockthemes::deelite") +
  # scale_color_paletteer_d("rockthemes::muse", direction = -1) +
  # scale_fill_paletteer_d("rockthemes::muse", direction = -1) +
  facet_wrap(vars(tratamiento)) +
  scale_x_discrete(name = "Dia", labels = c("1", "2")) +
  scale_y_continuous(name = "", labels = scales::percent_format()) +
  labs(fill = "", color = "") +
  ggthemes::theme_clean() +
  # ggthemes::theme_few() +
  theme(legend.position='top', axis.text = element_text(size = 12),axis.title = element_text(size = 15)) 
# coord_flip()
# facet_grid(~ estrategias_hipo) +
```



Para analizar si existe una preferencia de estrategias de un día a otro, se realizó una prueba de independencia de **Xi-cuadrada** para determinar si existe una asociación significativa entre día y estrategia utilizada . 



```{r xicuadrada}
#| echo: false

# Create contingency tables for each treatment across the two days
chi <- estrategias_df |> 
  dplyr::filter(str_detect(stage, "entrenamiento_rev")) |> 
  mutate(
    dia = case_when(stage == "entrenamiento_rev_1" ~ 1,
                    stage == "entrenamiento_rev_2" ~ 2),
    experimento = case_when(tratamiento %in% c("Flx", "Flx-CUMS","Sal-CUMS-F") ~ "Flx",
                            tratamiento %in% c("Ket-CUMS","Sal-CUMS-K") ~ "Ket")) |> 
  dplyr::filter(str_detect(experimento, "Flx")) |>
  dplyr::select(stage, tratamiento, estrategias_hipo)

data <- chi

contingency_tables <- list()
unique_treatments <- unique(data$tratamiento)

for(tratamiento in unique_treatments) {
  contingency <- table(data[data$tratamiento == tratamiento, ]$stage,
                       data[data$tratamiento == tratamiento, ]$estrategias_hipo)
  contingency_tables[[tratamiento]] <- contingency
}

# Xi cuadrada a cada tratamiento
chi_square_results <- list()

for(tratamiento in unique_treatments) {
  test_result <- chisq.test(contingency_tables[[tratamiento]])
  chi_square_results[[tratamiento]] <- list(
    Chi2 = test_result$statistic,
    p_value = test_result$p.value,
    Degrees_of_Freedom = test_result$parameter
  )
}

# Output 
# chi_square_results$`Flx-CUMS` 

# contingency_tables[['Flx']]
# contingency_tables[['Flx-CUMS']]
# contingency_tables[['Sal-CUMS-F']]

####### PRE

chi.pre <- estrategias_df |> 
  dplyr::filter(str_detect(stage, "entr")) |> 
  dplyr::filter(!str_detect(stage, "rev")) |> 
  mutate(
    dia = case_when(stage == "entrenamiento_1" ~ 1,
                    stage == "entrenamiento_2" ~ 2,
                    stage == "entrenamiento_3" ~ 3,
                    stage == "entrenamiento_4" ~ 4),
    experimento = case_when(tratamiento %in% c("Flx", "Flx-CUMS","Sal-CUMS-F") ~ "Flx",
                            tratamiento %in% c("Ket-CUMS","Sal-CUMS-K") ~ "Ket")) |> 
  dplyr::filter(str_detect(experimento, "Flx")) |>
  dplyr::select(stage, tratamiento, estrategias_hipo)

data <- chi.pre

contingency_tables <- list()
unique_treatments <- unique(data$tratamiento)

for(tratamiento in unique_treatments) {
  contingency <- table(data[data$tratamiento == tratamiento, ]$stage,
                       data[data$tratamiento == tratamiento, ]$estrategias_hipo)
  contingency_tables[[tratamiento]] <- contingency
}

# Xi cuadrada a cada tratamiento
chi_square_results <- list()

for(tratamiento in unique_treatments) {
  test_result <- chisq.test(contingency_tables[[tratamiento]])
  chi_square_results[[tratamiento]] <- list(
    Chi2 = test_result$statistic,
    p_value = test_result$p.value,
    Degrees_of_Freedom = test_result$parameter
  )
}


# Output 
# chi_square_results
# 
# contingency_tables[['Flx']]
# contingency_tables[['Flx-CUMS']]
# contingency_tables[['Sal-CUMS-F']]

```



**Fluoxetina**


*Entrenamientos Originales:*

|           | Alocéntricas           | Egocéntricas             |
| --------- | ---------------------- | ------------------------ |
| Entr-1    | 10                     | 26                       |
| Entr-2    | 22                     | 14                       |
| Entr-3    | 26                     | 10                       |
| Entr-4    | 29                     | 7                        |

: Tabla de contingencia de estrategias utilizadas en Entrenamientos Originales para grupo Flx. {#tbl-originalesflxcontingencia}

- **X\^2 estadístico** = $24.24682$
- **p.value** = $0.00002218462$ 
- **d.f.** = $3$


*Entrenamientos Reversa*

|           | Alocéntricas           | Egocéntricas             | Perseverancia |
| --------- | ---------------------- | ------------------------ | ------------- |
| Reversa-1 | 25                     | 10                       | 1             |
| Reversa-2 | 20                     | 10                       | 0             |

: Tabla de contingencia de estrategias utilizadas en Entrenamientos reversa para grupo Flx. {#tbl-reversaflxcontingencia}

- **X\^2 estadístico** = $1.018519$
- **p.value** = $0.6009406$ 
- **d.f.** = $2$


**Flx-CUMS**

*Entrenamientos Originales:*

|           | Alocéntricas           | Egocéntricas             |
| --------- | ---------------------- | ------------------------ |
| Entr-1    | 13                     | 15                       |
| Entr-2    | 19                     | 9                        |
| Entr-3    | 9                      | 3                        |
| Entr-4    | 14                     | 2                        |

: Tabla de contingencia de estrategias utilizadas en Entrenamientos Originales para grupo Flx-CUMS. {#tbl-originalesflxcumscontingencia}

- **X\^2 estadístico** = $8.478997$
- **p.value** = $0.03708319$ 
- **d.f.** = $3$


*Entrenamientos Reversa*

|           | Alocéntricas           | Egocéntricas             | Perseverancia |
| --------- | ---------------------- | ------------------------ | ------------- |
| Reversa-1 | 11                     | 12                       | 5             |
| Reversa-2 | 23                     | 4                        | 1             |

: Tabla de contingencia de estrategias utilizadas en Entrenamientos reversa para grupo Flx-CUMS. {#tbl-reversaflxcumscontingencia}

- **X\^2 estadístico** = $10.90196 $
- **p.value** = $0.01153909$ 
- **d.f.** = $2$


**Salina-CUMS** 

*Entrenamientos Originales:*

|           | Alocéntricas           | Egocéntricas             |
| --------- | ---------------------- | ------------------------ |
| Entr-1    | 16                     | 26                       |
| Entr-2    | 29                     | 15                       |
| Entr-3    | 48                     | 11                       |
| Entr-4    | 48                     | 7                        |

: Tabla de contingencia de estrategias utilizadas en Entrenamientos reversa para grupo Salina-CUMS-F. {#tbl-reversasalflxcumscontingencia}

- **X\^2 estadístico** = $32.43482 $
- **p.value** = $0.000000423773$ 
- **d.f.** = $3$


*Entrenamientos Reversa*

|           | Alocéntricas           | Egocéntricas             | perseverancia |
| --------- | ---------------------- | ------------------------ | ------------- |
| Reversa-1 | 11                     | 21                       | 6             |
| Reversa-2 | 25                     | 11                       | 4             |

: Tabla de contingencia de estrategias utilizadas en Entrenamientos reversa para grupo Flx-CUMS. {#tbl-reversaflxcumscontingencia}

- **X\^2 estadístico** = $8.92403$
- **p.value** = $0.004292095$ 
- **d.f.** = $2$


Los *p-values* significativos los entrenamientos originales para todos los grupos sugieren que hay diferencias significativas en la preferencia de estrategias entre los distintos días de los entrenamientos. Como se observa en la @fig-porcentajesEstrategiasPlots, parece que todos los grupos pasan de adoptar estrategias egocéntricas a estrategias alocéntricas. 

Por otro lado, los *p-values* significativos en la prueba Reversa en **Flx-CUMS** y **Sal-CUMS**  sugieren que hay diferencias significativas en la preferencia de estrategias entre el entrenamiento reversa 1 y el entrenamiento reversa 2. Observando la @fig-porcentajesEstrategiasPlots, parece ser que adoptan más estrategias dependientes de hipocampo con el tiempo. 

Para entender mejor la interacción entre variables categóricas (prueba, tipo de estrategia [cuenta] y tratamiento), ajustamos una regresión de Poisson con efectos mixtos (utilizando máxima verosimilitud) (ver @fig-poissonEquaciones). La variable de respuesta es el número de tipo de estrategias, y las variables predictoras son el tiempo y tratamiento. Se incluyeron a los ratones como efectos mixtos para tomar en cuenta la dependencia de los datos en el tiempo (medidas repetidas). 


Para realizar la regresión de Poisson, la varianza observada en los datos no debe ser mayor a la varianza asumida por el modelo (sobre-dispersión). El modelo para latencias originales no presentó sobre-dispersión (*dispersion ratio* = $0.375$, *Pearson Chi2* = $61.074$). El modelo para latencias reversa tampoco presentó sobre-dispersión (*dispersion ratio* = $0.510$, *Pearson Chi2* = $34.145$).



```{r posissoncheckmodel}
#| eval: false
#| include: false
performance::check_model(model, colors = c("#222831", "#00ADB5", "#FF2E63"))

# "all", "vif", "qq", "normality", "linearity", "ncv", "homogeneity", "outliers", "reqq", "pp_check", "binned_residuals" or "overdispersion"

# base_size, title_size, axis_title_size

# theme
# package::theme_name


```


```{r PoissonReport}
#| echo: false
#| eval: false

report::report(glme.poisson.pre)
report::report(glme.poisson.post)

```


```{r poissondataFrames}
#| echo: false

##### FLX Originales
estrategias.poisson.flx.pre <- estrategias_df |> 
  dplyr::filter(str_detect(stage, "entr")) |> 
  dplyr::filter(!str_detect(stage, "entrenamiento_rev")) |> 
  mutate(
    dia = case_when(stage == "entrenamiento_1" ~ 1,
                    stage == "entrenamiento_2" ~ 2,
                    stage == "entrenamiento_3" ~ 3,
                    stage == "entrenamiento_4" ~ 4),
    experimento = case_when(tratamiento %in% c("Flx", "Flx-CUMS","Sal-CUMS-F") ~ "Flx",
                            tratamiento %in% c("Ket-CUMS","Sal-CUMS-K") ~ "Ket")) |> 
  dplyr::filter(str_detect(experimento, "Flx")) |>
  dplyr::select(dia, tratamiento, estrategias_hipo, x_target_id)

estrategias.poisson.flx.pre$tratamiento <- as.factor(estrategias.poisson.flx.pre$tratamiento)

estrategias.poisson.flx.pre$estrategias_hipo <- as.factor(estrategias.poisson.flx.pre$estrategias_hipo)

estrategias.poisson.flx.pre$x_target_id <- as.factor(estrategias.poisson.flx.pre$x_target_id)

estrategias.poisson.flx.pre$count <- 1

estrategias.poisson.flx.pre.agrupado <- estrategias.poisson.flx.pre %>%
  dplyr::group_by(dia, tratamiento, estrategias_hipo, x_target_id) %>%
  dplyr::summarise(count = n(), .groups = 'drop')



#### FLX Reversa

estrategias.poisson.flx.post <- estrategias_df |> 
  dplyr::filter(str_detect(stage, "entrenamiento_rev")) |> 
  mutate(
    dia = case_when(stage == "entrenamiento_rev_1" ~ 1,
                    stage == "entrenamiento_rev_2" ~ 2,
                    stage == "entrenamiento_1" ~ 0,
                    stage == "entrenamiento_2" ~ 1,
                    stage == "entrenamiento_3" ~ 2,
                    stage == "entrenamiento_4" ~ 3
                    ),
    dia_completo = case_when(
      ### E-1 ###
      # stage =="entrenamiento_1" & trial == 1 ~ 0,
      # stage =="entrenamiento_1" & trial == 2 ~ 0.25,
      # stage =="entrenamiento_1" & trial == 3 ~ 0.5,
      # stage =="entrenamiento_1" & trial == 4 ~ 0.75,
      # ### E-2 ###
      # stage =="entrenamiento_2" & trial == 1 ~ 1,
      # stage =="entrenamiento_2" & trial == 2 ~ 1.25,
      # stage =="entrenamiento_2" & trial == 3 ~ 1.5,
      # stage =="entrenamiento_2" & trial == 4 ~ 1.75,
      # ### E-3 ###
      # stage =="entrenamiento_3" & trial == 1 ~ 2,
      # stage =="entrenamiento_3" & trial == 2 ~ 2.25,
      # stage =="entrenamiento_3" & trial == 3 ~ 2.5,
      # stage =="entrenamiento_3" & trial == 4 ~ 2.75,
      # ### E-4 ###
      # stage =="entrenamiento_4" & trial == 1 ~ 3,
      # stage =="entrenamiento_4" & trial == 2 ~ 3.25,
      # stage =="entrenamiento_4" & trial == 3 ~ 3.5,
      # stage =="entrenamiento_4" & trial == 4 ~ 3.75,
      ### E_R-1 ###
      stage =="entrenamiento_rev_1" & x_trial == 1 ~ 0,
      stage =="entrenamiento_rev_1" & x_trial == 2 ~ 0.25,
      stage =="entrenamiento_rev_1" & x_trial == 3 ~ 0.5,
      stage =="entrenamiento_rev_1" & x_trial == 4 ~ 0.75,
      ### E_R-2 ###
      stage =="entrenamiento_rev_2" & x_trial == 1 ~ 1,
      stage =="entrenamiento_rev_2" & x_trial == 2 ~ 1.25,
      stage =="entrenamiento_rev_2" & x_trial == 3 ~ 1.5,
      stage =="entrenamiento_rev_2" & x_trial == 4 ~ 1.75,
    ),
    experimento = case_when(tratamiento %in% c("Flx", "Flx-CUMS","Sal-CUMS-F") ~ "Flx",
                            tratamiento %in% c("Ket-CUMS","Sal-CUMS-K") ~ "Ket")) |>
  dplyr::filter(str_detect(experimento, "Flx")) |>
  dplyr::select(dia_completo, tratamiento, estrategias_hipo, x_target_id, dia)


estrategias.poisson.flx.post$tratamiento <- as.factor(estrategias.poisson.flx.post$tratamiento)

estrategias.poisson.flx.post$estrategias_hipo <- as.factor(estrategias.poisson.flx.post$estrategias_hipo)

estrategias.poisson.flx.post$x_target_id <- as.factor(estrategias.poisson.flx.post$x_target_id)

# Crear cuenta de columna para cada tipo de estrategia

estrategias.poisson.flx.post$count <- 1

# Agrupar datos y resumir cuentas (counts)
estrategias.poisson.flx.post.agrupado <- estrategias.poisson.flx.post %>%
  dplyr::group_by(dia, tratamiento, estrategias_hipo, x_target_id) %>%
  # dplyr::group_by(dia, tratamiento, estrategias_hipo) %>%
  dplyr::summarise(count = n(), .groups = 'drop')

estrategias.poisson.flx.post$count <- 1

estrategias.poisson.flx.post.agrupado.2 <- estrategias.poisson.flx.post %>%
  dplyr::group_by(dia, tratamiento, estrategias_hipo) %>%
  # dplyr::group_by(dia, tratamiento, estrategias_hipo) %>%
  dplyr::summarise(count = n(), .groups = 'drop')

```

```{r poissonModelado}
#| echo: false



glme.poisson.pre <- glmer(count ~ dia * tratamiento * estrategias_hipo +
                            (1 | x_target_id),
                          family = poisson(link = "log"), 
                          data = estrategias.poisson.flx.pre.agrupado)

glme.poisson.post <- glmer(count ~ dia * tratamiento * estrategias_hipo +
                           (1 | x_target_id),
                           family = poisson(link = "log"),
                           data = estrategias.poisson.flx.post.agrupado)

glm.poisson.post <- glm(count ~ dia * tratamiento * estrategias_hipo,
                           family = poisson(link = "log"),
                           data = estrategias.poisson.flx.post.agrupado.2)


```


```{r reglogiEq}
#| echo: false
#| label: fig-poissonEquaciones
#| fig-cap: "Ecuación de regresión de Poisson."
#| layout-ncol: 1

equatiomatic::extract_eq(glme.poisson.pre, wrap = TRUE, terms_per_line = 1, operator_location = "start")

# equatiomatic::extract_eq(glme.poisson.post, wrap = TRUE, terms_per_line = 1, operator_location = "start")

```


Debido a los términos de interacción en el modelo de regresión de Poisson, se recomienda visualizar los efectos por medio de las medias marginales estimadas del modelo. A diferencia de los modelos lineales clásicos, los efectos de interacción en los Modelos Lineales Generalizados (GLM) describen probabilidades y conteos que no son equivalentes a los términos de interacción entre variables predictoras de los modelos lineales. En cambio, las interacciones son el cambio en un efecto marginal de una variable en función del cambio en otra variable, y describe el uso de derivadas parciales y diferencias discretas para cuantificar estos efectos. Debido a esto, los coeficientes obtenidos por estos modelos (log-conteos) no son fáciles de interpretar. Para recuperar la escala natural de la variable e interpretar los términos de interacción, se pueden graficar los efectos marginales @mccabe2022. 



```{r poisonplotsEmmeans}
#| echo: false
#| label: fig-poisonplotsEmmeans
#| fig-cap: "Medias Estimadas a partir de la regresión de Poisson. Las medias graficadas representan el estimado de estrategias utilizadas por tratamiento en cada día de los entrenamientos (4 pruebas por día). No se encontraron diferencias significativas en las medias. Las medias marginales están calculadas a tres niveles, prueba, tratamientos y tipo de estrategia. Graficado con Media + error estándar."
#| fig-subcap: 
#|   - "Entrenamientos Originales"
#|   - "Entrenamientos Reversa"
#| layout-ncol: 1

emm.estrategias.flx.pre <- emmeans(glme.poisson.pre, ~ dia | tratamiento | estrategias_hipo, cov.reduce = F,        
        type = "response") # displayed results to be back-transformed to the response scale
# trans = "log"


emm.estrategias.flx.pre.df <- as.data.frame(emm.estrategias.flx.pre) |> 
  dplyr::mutate(estrategias_hipo = recode(estrategias_hipo,
                                          "hipocampo_dependientes" = "Alocéntricas",
                                          "hipocampo_independientes" = "Egocéntricas"))

ggplot(emm.estrategias.flx.pre.df,
                    aes(
                      x = dia,
                      y = rate, # rate emmeans
                      group = tratamiento,
                      color = tratamiento
                    )) +
  geom_line(linewidth = 0.3, linetype = "dashed", position = position_dodge(0.1)) +
  geom_point(size = 4, position = position_dodge(0.1), aes(shape = tratamiento)) +
  # geom_point(size = 7, shape = 21, position = position_dodge(0.1)) +
  geom_pointrange(aes(ymin = rate-SE, ymax = rate+SE),
                  size = 0.75, position = position_dodge(0.1)) +
  scale_color_manual(values = c("#222831", "#00ADB5", "#FF2E63", "#FF9800", "#8675A9", "#862B0D")) +
  labs(
    # caption = "Graficado con error estándar",
    color = "Tratamientos",
    shape = "Tratamientos",
    x = "Entrenamiento",
    y = "Media Estimada") +
  ylim(0, 4) +
  # scale_x_discrete(labels=c("entrenamiento_rev_1"="1", "entrenamiento_rev_2"="2")) +
  # theme_classic() +
  # ggthemes::theme_base() +
  ggthemes::theme_clean() +
  facet_grid(~ estrategias_hipo) +
  theme(legend.position='top', axis.text = element_text(size = 10),axis.title = element_text(size = 15)) 




# latencias_post_emmeans_aov.df <- as.data.frame(latencias_post_emmeans_aov)


####### POST

emm.estrategias.flx.post <- emmeans(glm.poisson.post, ~ dia | tratamiento | estrategias_hipo, cov.reduce = T)       
        # type = "response") # displayed results to be back-transformed to the response scale
# trans = "log"


emm.estrategias.flx.post.df <- as.data.frame(emm.estrategias.flx.post) |> 
  dplyr::mutate(estrategias_hipo = recode(estrategias_hipo,
                                          "hipocampo_dependientes" = "Alocéntricas",
                                          "hipocampo_independientes" = "Egocéntricas"))

ggplot(emm.estrategias.flx.post.df,
                    aes(
                      x = dia,
                      y = emmean, # rate emmeans
                      group = tratamiento,
                      color = tratamiento
                    )) +
  geom_line(linewidth = 0.3, linetype = "dashed", position = position_dodge(0.1)) +
  geom_point(size = 4, position = position_dodge(0.1), aes(shape = tratamiento)) +
  # geom_point(size = 7, shape = 21, position = position_dodge(0.1)) +
  geom_pointrange(aes(ymin = emmean-SE, ymax = emmean+SE),
                  size = 0.75, position = position_dodge(0.1)) +
  scale_color_manual(values = c("#222831", "#00ADB5", "#FF2E63", "#FF9800", "#8675A9", "#862B0D")) +
  labs(
    # caption = "Graficado con error estándar",
    color = "Tratamientos",
    shape = "Tratamientos",
    x = "Entrenamiento",
    y = "Media Estimada") +
  ylim(0, 4) +
  # scale_y_continuous(name, breaks, labels, limits, trans) +
  scale_x_discrete( 
                    limits=c("1","2")) +
  # scale_x_discrete(labels=c("entrenamiento_rev_1"="1", "entrenamiento_rev_2"="2")) +
  # theme_classic() +
  # ggthemes::theme_base() +
  ggthemes::theme_clean() +
  facet_grid(~ estrategias_hipo) +
  theme(legend.position='top', axis.text = element_text(size = 10),axis.title = element_text(size = 15)) 


######## COMPS EMMEANS

# emmeans(glm.poisson.post, ~ dia | tratamiento | estrategias_hipo, cov.reduce = F)
# 
# 
# aov_em_post <- emmeans(glm.poisson.post, pairwise ~ tratamiento | dia | estrategias_hipo, adjust = "fdr", cov.reduce = F)$contrasts |>
#   dplyr::as_tibble() |>  
#   dplyr::select(-df, -t.ratio) |>
#   dplyr::rename(Estimado = estimate) |> 
#   dplyr::filter(p.value <= 0.05) |>
#   tidyr::separate(contrast, into = c("Tratamiento_1", "Tratamiento_2"), sep = " - ") |> 
#   gt::gt()  |> 
#   tab_footnote("Comparaciones múltiples ajustadas con Tukey HSD") |> 
#   fmt_number(decimals = 3) |>
#   tab_style_body(
#     style = list(
#                  cell_text(color = "#222831")),
#     values = c("Flx")
#   ) |> 
#   tab_style_body(
#     style = list(
#                  cell_text(color = "#00ADB5")),
#     values = c("(Flx-CUMS)")) |>
#   tab_style_body(
#     style = list(
#                  cell_text(color = "#FF2E63")),
#     values = c(("(Sal-CUMS-F)"))
#     ) |> 
#   opt_stylize(style = 1) 
# 
# aov_em_post

```


```{r poisonCheckModel}
#| echo: false
#| eval: false

check_overdispersion(glme.poisson.pre)

check_overdispersion(glme.poisson.post)
```


A pesar de que la prueba Omnibus del modelo (análisis de varianza tipo III con método de Satterthwaite), sólamente detectó una interacción significativa entre el día y el tipo de estrategias (F(1,164)=43.33, p<0.001), sigue siendo valioso analizar los patrones que encontramos en el entrenamiento reversa (@fig-poisonplotsEmmeans):
i. En un principio, los grupos con estrés adoptan menos estrategias alocéntricas. Sin embargo, para el segundo día todos los tratamientos son similares. Algo similar ocurre con las estrategias egocéntricas. Esto es relevante ya que el uso de estrategias alocéntricas está relacionado con la integridad del hipocampo y la integridad de la neurogénesis [@garthe2016].
i. Los grupos de Flx tienen menos incidencia de la perseverancia a comparación del grupo de salina. La perseverancia es una forma de evaluar la falta de flexibilidad cognitiva al no poder adaptarse al nuevo ambiente [@garthe2016].

Como señala @amelchenko2023, la evidencia del daño hipocampal en el uso de estrategias es más evidente cuando las pruebas son más complejas, por ejemplo, al introducir un segundo protocolo de aprendizaje reversa. En otro artículo, @amelchenko2023b introduce un protocolo de MWM que añade una prueba de reconocimiento contextual después del protocolo de reversa, evidenciando más el papel de las nuevas neuronas en el uso de estrategias alocéntricas. Otros autores han llegado a una conclusión similar [@garthe2016] cuando se introduce un segundo protocolo reversa. Como señala @garthe2013, es probable que el papel de la neurogénesis en el MWM solo sea relevante cuando el procesamiento de información sea lo suficientemente demandante. En conclusión, en futuros experimentos se podría incorporar un segundo protocolo de aprendizaje reversa para evaluar si la complejidad agregada tiene un impacto sobre el uso de estrategias alocéntricas en el MWM. 



### Distancia Media al Annulus Blanco

Esta métrica calcula la distancia promedio del roedor al centro de la plataforma. Como demostró @maei2009a, esta es una métrica muy sensible al aprendizaje espacial en el MWM. 


```{r dataframesDistanciaMediaENTS}
#| echo: false


##### PRE

entr.dist.media.pre.df <- 
  df_wm_flx |> 
  # df_wm_otros |> 
  dplyr::select(distancia_annulus_ne, tratamientos, tiempo, id, prueba, dia) |> 
  # dplyr::filter(str_detect(prueba, "Ent")) |> 
  dplyr::filter(!str_detect(prueba, "Rev")) |> 
  dplyr::filter(str_detect(prueba, "Ent")) |>
  dplyr::filter(distancia_annulus_ne > .1) 

entr.dist.media.pre.df$tiempo_centrado = entr.dist.media.pre.df$tiempo - mean(entr.dist.media.pre.df$tiempo)





df.mean.dist.media.ent.pre <- aggregate(entr.dist.media.pre.df$distancia_annulus_ne,
                                    by = list(entr.dist.media.pre.df$prueba, 
                                              entr.dist.media.pre.df$tratamientos,
                                              entr.dist.media.pre.df$id),
                                    FUN = 'mean')

colnames(df.mean.dist.media.ent.pre) <- c("prueba","tratamientos","id","distancia_annulus_ne")







##### POST

entr.dist.media.df <- 
  df_wm_flx |> 
  # df_wm_otros |> 
  dplyr::select(distancia_annulus_so, distancia_annulus_ne, tratamientos, tiempo, id, prueba, dia) |> 
  # dplyr::filter(str_detect(prueba, "Ent")) |> 
  dplyr::filter(str_detect(prueba, "Rev")) |> 
  dplyr::filter(!str_detect(prueba, "P-Rev")) |>   
  dplyr::filter(distancia_annulus_so > .1) 
  # dplyr::filter(distancia_annulus_ne > .1)
# dplyr::filter(!str_detect(Id, "gris-2")) |>
#   dplyr::filter(!str_detect(Id, "2-1")) |>
#   dplyr::filter(!str_detect(Id, "2b")) |>
#   dplyr::filter(!str_detect(Id, "1b")) |>
#   dplyr::filter(!str_detect(Id, "negro-2")) |>
#   janitor::clean_names()  |> 
#   mutate(dia = case_when (stage == "prueba_1" ~ 1,
#                           stage == "prueba_2" ~ 2,
#                           stage == "prueba_rev" ~ 3
#   ), 
#   entropia_blanco = case_when(
#     stage == "prueba_1" ~ entropia_ne,
#     stage == "prueba_2" ~ entropia_ne,
#     stage == "prueba_rev" ~ entropia_so
#   ))

entr.dist.media.df$tiempo_centrado = entr.dist.media.df$tiempo - mean(entr.dist.media.df$tiempo)


df.mean.dist.media.ent <- aggregate(entr.dist.media.df$distancia_annulus_so,
                                    by = list(entr.dist.media.df$prueba, 
                                              entr.dist.media.df$tratamientos,
                                              entr.dist.media.df$id),
                                    FUN = 'mean')

colnames(df.mean.dist.media.ent) <- c("prueba","tratamientos","id","distancia_annulus_so")
```


```{r lmerEntsDistMediaFlx}
#| echo: false


###### PRE

lmer.dist.media.entr.flx.pre <- lmer(
  distancia_annulus_ne ~ tiempo_centrado * tratamientos + (1 | id),
  data = entr.dist.media.pre.df
)

aov.dist.media.entr.flx.pre <- aov(distancia_annulus_ne ~ tratamientos * prueba + Error(id), 
                               data = df.mean.dist.media.ent.pre)

####### POST

lmer.dist.media.entr.flx <- lmer(
  distancia_annulus_so ~ tiempo_centrado * tratamientos + (1 | id),
  data = entr.dist.media.df
)


aov.dist.media.entr.flx <- aov(distancia_annulus_so ~ tratamientos * prueba + Error(id), 
                               data = df.mean.dist.media.ent)


# rstatix::anova_test(data = df.mean.dist.media.ent, dv = distancia_annulus_so, 
#                     wid = id,
#   between = tratamientos, within = prueba
#   ) |> 
# rstatix::get_anova_table()
```

```{r dmedpruebReport}
#| include: false
#| eval: false
report::report(lmer.dist.media.entr.flx)
```

Ajustamos un modelo lineal con efectos mixtos (estimado utilizando REML) para predecir la distancia media al annulus blanco a partir del tiempo y los tratamientos (fórmula: `distancia ~ tiempo * tratamientos`). El modelo incluyó a los ratones como efecto aleatorio (fórmula: `~1 | id`). El poder explicativo total del modelo es sustancial (R2 condicional = 0.34). Ver @fig-equacionregeqDMediaEntrenamientos.


```{r eqDMediaEntrenamientos}
#| echo: false
#| label: fig-equacionregeqDMediaEntrenamientos
#| fig-cap: Ecuación del modelo de regresión.

equatiomatic::extract_eq(lmer.dist.media.entr.flx, wrap = TRUE, terms_per_line = 4, operator_location = "start")

```

Para el caso de los entrenamientos originales, se obtienen los siguientes resultados: 


```{r DMediaEntrPlotsPredictedLMER}
#| output: false
#| include: false

# plot_model(lmer.dist.media.entr.flx, type = "pred", terms = c("tiempo_centrado", "tratamientos"))

pre <- ggpredict(lmer.dist.media.entr.flx.pre, c("tiempo_centrado", "tratamientos"))


```

```{r DMediaEntrPlotsPOSTdictedLMER}
#| output: false
#| include: false

# plot_model(lmer.dist.media.entr.flx, type = "pred", terms = c("tiempo_centrado", "tratamientos"))

p <- ggpredict(lmer.dist.media.entr.flx, c("tiempo_centrado", "tratamientos"))


```

```{r TablaRegDistMediaEntspre}
#| echo: false
#| eval: false
#| label: tbl-TablaRegDistMediaEntspre
#| tbl-cap: "Tabla de regresión en Distancias Medias para entrenamientos originales."

sjPlot::tab_model(lmer.dist.media.entr.flx.pre,
                  show.std = T,
                  # std.response = T,
                  # show.stat = T,
                  collapse.ci = T,
                  # auto.label = TRUE,
                  # show.se = T,
                  # show.obs = T,
                  # show.fstat = T,
                  # show.reflvl = F, # nivel de referencia para factores
                  show.intercept = F,
                  show.r2 = F,
                  show.re.var = F,
                  rm.terms = "Residuals",
                  show.icc = F,
                  show.df = F,
                  p.style = "numeric_stars",
                  # title = "Latencias Reversa Efectos Mixtos",
                  string.pred = "Predictores",
                  string.est = "Estimados",
                  pred.labels = c("Tiempo",
                                  "Flx-CUMS", "Sal-CUMS-F",
                                  "Tiempo:Flx-CUMS", "Tiempo:Sal-CUMS-F"
                                  # "Tratamientos",
                                  # "Tiempo", "Tratamientos:Prueba"
                  ),
                  dv.labels = c("Modelo con Efectos Mixtos")
                  # file = "./tablas/lmer_aov_dist_media_so_ent_post.html"
                  # string.se = "SEM"
)

```

```{r TablaRegDistMediaEntspredos}
#| echo: false
#| label: tbl-TablaRegDistMediaEntspredos
#| tbl-cap: "Tabla de regresión en Distancias Medias para entrenamientos originales."

tbl_regression(lmer.dist.media.entr.flx.pre, pvalue_fun = ~ style_pvalue(.x, digits = 3)) %>%
  add_global_p() |> 
  bold_p(t = 0.05) %>%
  bold_labels() %>%
  modify_header(label = "**Variable**") %>%
  as_gt()




```


```{r DMEDIAPlotEstimadospre}
#| echo: false
#| label: fig-DMEDIAPlotEstimadospre
#| fig-cap: "Medias Marginales Estimadas para entrenamientos originales. Graficados con Media + IC al 95%"

ggplot(pre, aes(x, predicted, colour = group, fill = group )) +
  geom_line() +
  geom_ribbon(aes(ymin = conf.low, ymax = conf.high), alpha = 0.1) +
  scale_fill_manual(values = c("#222831", "#00ADB5", "#FF2E63", "#FF9800", "#8675A9", "#862B0D")) +
  scale_color_manual(values = c("#222831", "#00ADB5", "#FF2E63", "#FF9800", "#8675A9", "#862B0D")) +
  labs(
    # caption = "Graficados con Media + IC al 95%",
    color = "Tratamientos",
    shape = "Tratamientos",
    fill = "Tratamientos",
    group = "Tratamientos",
    x = "Tiempo",
    y = "metros") +
  ylim(0, 0.6) +
  # scale_x_continuous(labels=c('1', '2', '3', '4')) +
  facet_grid( ~ group) +
  # facet_wrap( ~ group) +
  # ggthemes::theme_base() +
  # scale_x_discrete(labels=c("Entr_1"="1", "Entr_2"="2", "Entr_3"="3","Entr_4"="4")) +
  # theme_classic() +
  ggthemes::theme_clean() +
  # ggthemes::theme_clean() + 
  theme(legend.position='top', axis.text = element_text(size = 12),axis.title = element_text(size = 15))



```

```{r DMEDIACompsEntspre}
#| echo: false
#| label: tbl-DMEDIACompsEntspre
#| tbl-cap: Comparación múltiples obtenidas a partir de los efectos marginales del modelo Entrenamientos Originales. Ajustadas con tukey HSD.


# test_predictions(pre, test = NULL, p_adjust = "tukey")|>
#   dplyr::as_tibble() |> 
#   dplyr::select(-tiempo_centrado) |>
#   dplyr::rename(Pendiente = Slope, ICi = conf.low, ICs = conf.high) |>
#   # dplyr::filter(p.value <= 0.05) |>
#   # tidyr::separate(tratamientos, into = c("Tratamiento_1", "Tratamiento_2"), sep = "-") |>
#   gt::gt()  |> 
#   # tab_footnote("Comparaciones múltiples ajustadas con Tukey HSD") |> 
#   fmt_number(decimals = 3) |>
#   opt_stylize(style = 1) |> 
#   tab_style_body(
#     style = list(
#                  cell_text(color = "#222831")),
#     values = c("Flx")
#   ) |>
#   tab_style_body(
#     style = list(
#                  cell_text(color = "#00ADB5")),
#     values = c("Flx-CUMS")) |>
#   tab_style_body(
#     style = list(
#                  cell_text(color = "#FF2E63")),
#     values = c(("Sal-CUMS-F"))
#     ) |>
#   opt_stylize(style = 1)


# test_predictions(p, test = NULL) |> # p_adjust = "tukey" 
test_predictions(pre, p_adjust = "tukey") |> # p_adjust = "tukey"
  dplyr::as_tibble() |> 
  dplyr::select(-tiempo_centrado) |>
  dplyr::rename(Contraste = Contrast, ICi = conf.low, ICs = conf.high) |>
  # dplyr::filter(p.value <= 0.05) |>
  # tidyr::separate(tratamientos, into = c("Tratamiento_1", "Tratamiento_2"), sep = "-") |>
  gt::gt()  |> 
  # tab_footnote("Comparaciones múltiples ajustadas con Tukey HSD") |>
  fmt_number(decimals = 3) |>
  opt_stylize(style = 1) |> 
  # tab_style_body(
  #   style = list(
  #                cell_text(color = "#222831")),
  #   values = c("(Flx)")
  # ) |> 
  # tab_style_body(
  #   style = list(
  #                cell_text(color = "#00ADB5")),
  #   values = c("(Flx-CUMS)")) |>
  # tab_style_body(
  #   style = list(
  #                cell_text(color = "#FF2E63")),
  #   values = c(("(Sal-CUMS-F)"))
  #   ) |> 
  opt_stylize(style = 1)



# emmeans(lmer.dist.media.entr.flx.pre, pairwise ~ tratamientos | tiempo_centrado, adjust = "tukey",  cov.reduce = FALSE)$contrasts |> 
#   as_tibble() |> 
#   dplyr::select(-df, -t.ratio, -SE) |>
#   dplyr::rename(Estimado = estimate) |> 
#   dplyr::filter(p.value <= 0.05) |>
#   separate(contrast, into = c("Tratamiento_1", "Tratamiento_2"), sep = " - ") |> 
#   gt::gt()  |> 
#   tab_footnote("Comparaciones múltiples ajustadas con Tukey HSD") |>
#   fmt_number(decimals = 3) |>
#   opt_stylize(style = 1) |> 
#   tab_style_body(
#     style = list(
#                  cell_text(color = "#222831")),
#     values = c("(Flx)")
#   ) |>
#   tab_style_body(
#     style = list(
#                  cell_text(color = "#00ADB5")),
#     values = c("(Flx-CUMS)")) |>
#   tab_style_body(
#     style = list(
#                  cell_text(color = "#FF2E63")),
#     values = c(("(Sal-CUMS-F)"))
#     ) |>
#   opt_stylize(style = 1)

  
```


```{r TablaRegDistMediaEnts}
#| echo: false
#| eval: false
#| label: tbl-TablaRegDistMediaEnts
#| tbl-cap: "Tabla de regresión en Distancias Medias."

sjPlot::tab_model(lmer.dist.media.entr.flx, 
                  show.std = T,
                  # std.response = T,
                  # show.stat = T,
                  collapse.ci = T,
                  # auto.label = TRUE,
                  # show.se = T,
                  # show.obs = T,
                  # show.fstat = T,
                  # show.reflvl = F, # nivel de referencia para factores
                  show.intercept = F,
                  show.r2 = F,
                  show.re.var = F,
                  rm.terms = "Residuals",
                  show.icc = F,
                  show.df = F,
                  p.style = "numeric_stars",
                  # title = "Latencias Reversa Efectos Mixtos",
                  string.pred = "Predictores",
                  string.est = "Estimados",
                  pred.labels = c("Tiempo",
                                  "Flx-CUMS", "Sal-CUMS-F",
                                  "Tiempo:Flx-CUMS", "Tiempo:Sal-CUMS-F"
                                  # "Tratamientos",
                                  # "Tiempo", "Tratamientos:Prueba"
                  ),
                  dv.labels = c("Modelo con Efectos Mixtos")
                  # file = "./tablas/lmer_aov_dist_media_so_ent_post.html"
                  # string.se = "SEM"
)


```

Para el caso de los entrenamientos reversa, tenemos los siguientes resultados:

```{r TablaRegDistMediaEntspostsdos}
#| echo: false
#| label: tbl-TablaRegDistMediaEntspostsdos
#| tbl-cap: "Tabla de regresión en Distancias Medias Reversa."

tbl_regression(lmer.dist.media.entr.flx, 
               pvalue_fun = ~ style_pvalue(.x, digits = 3)) %>%
  add_global_p() |> 
  bold_p(t = 0.05) %>%
  bold_labels() %>%
  modify_header(label = "**Variable**") %>%
  as_gt()

```

```{r DMEDIAPlotEstimadospost}
#| echo: false
#| label: fig-DMEDIAPlotEstimadospost
#| fig-cap: "Medias Estimadas Entrenamientos reversa. Graficados con Media + IC al 95%"




ggplot(p, aes(x, predicted, colour = group, fill = group )) +
  geom_line() +
  geom_ribbon(aes(ymin = conf.low, ymax = conf.high), alpha = 0.1) +
  scale_fill_manual(values = c("#222831", "#00ADB5", "#FF2E63", "#FF9800", "#8675A9", "#862B0D")) +
  scale_color_manual(values = c("#222831", "#00ADB5", "#FF2E63", "#FF9800", "#8675A9", "#862B0D")) +
  labs(
    # caption = "Graficados con Media + IC al 95%",
    color = "Tratamientos",
    shape = "Tratamientos",
    fill = "Tratamientos",
    group = "Tratamientos",
    x = "Tiempo",
    y = "metros") +
  ylim(0, 0.6) +
  # scale_x_continuous(labels=c('1', '2', '3', '4')) +
  facet_grid( ~ group) +
  # facet_wrap( ~ group) +
  # ggthemes::theme_base() +
  # scale_x_discrete(labels=c("Entr_1"="1", "Entr_2"="2", "Entr_3"="3","Entr_4"="4")) +
  # theme_classic() +
  ggthemes::theme_clean() +
  # ggthemes::theme_clean() + 
  theme(legend.position='top', axis.text = element_text(size = 12),axis.title = element_text(size = 15))

```


```{r DMEDIACompsEnts}
#| echo: false
#| label: tbl-DMEDIACompsEnts
#| tbl-cap: Comparación múltiples obtenidas a partir de los efectos marginales del modelo Entrenamientos Originales. Ajustadas con tukey HSD. 
#| tbl-subcap: 
#|   - "Pendientes de los grupos."
#|   - "Contrastes en las pendientes."
#|   - "Contrastes significativos de las medias en los distintos tiempos."
#| layout-ncol: 1

test_predictions(p, test = NULL) |>
  dplyr::as_tibble() |> 
  dplyr::select(-tiempo_centrado) |>
  dplyr::rename(Pendiente = Slope, ICi = conf.low, ICs = conf.high) |>
  # dplyr::filter(p.value <= 0.05) |>
  # tidyr::separate(tratamientos, into = c("Tratamiento_1", "Tratamiento_2"), sep = "-") |>
  gt::gt()  |> 
  # tab_footnote("Comparaciones múltiples ajustadas con Tukey HSD") |> 
  fmt_number(decimals = 3) |>
  opt_stylize(style = 1) |> 
  tab_style_body(
    style = list(
                 cell_text(color = "#222831")),
    values = c("Flx")
  ) |>
  tab_style_body(
    style = list(
                 cell_text(color = "#00ADB5")),
    values = c("Flx-CUMS")) |>
  tab_style_body(
    style = list(
                 cell_text(color = "#FF2E63")),
    values = c(("Sal-CUMS-F"))
    ) |>
  opt_stylize(style = 1)


# test_predictions(p, test = NULL) |> # p_adjust = "tukey" 
test_predictions(p) |> # p_adjust = "tukey"
  dplyr::as_tibble() |> 
  dplyr::select(-tiempo_centrado) |>
  dplyr::rename(Contraste = Contrast, ICi = conf.low, ICs = conf.high) |>
  # dplyr::filter(p.value <= 0.05) |>
  # tidyr::separate(tratamientos, into = c("Tratamiento_1", "Tratamiento_2"), sep = "-") |>
  gt::gt()  |> 
  # tab_footnote("Comparaciones múltiples ajustadas con Tukey HSD") |> 
  fmt_number(decimals = 3) |>
  opt_stylize(style = 1) |> 
  # tab_style_body(
  #   style = list(
  #                cell_text(color = "#222831")),
  #   values = c("(Flx)")
  # ) |> 
  # tab_style_body(
  #   style = list(
  #                cell_text(color = "#00ADB5")),
  #   values = c("(Flx-CUMS)")) |>
  # tab_style_body(
  #   style = list(
  #                cell_text(color = "#FF2E63")),
  #   values = c(("(Sal-CUMS-F)"))
  #   ) |> 
  opt_stylize(style = 1)



emmeans(lmer.dist.media.entr.flx, pairwise ~ tratamientos | tiempo_centrado, adjust = "tukey",  cov.reduce = FALSE)$contrasts |> 
  as_tibble() |> 
  dplyr::select(-t.ratio, -SE) |>
  dplyr::rename(Estimado = estimate, Tiempo = tiempo_centrado) |> 
  dplyr::filter(p.value <= 0.05) |>
  separate(contrast, into = c("1", "2"), sep = " - ") |> 
  gt::gt()  |> 
  tab_footnote("Comparaciones múltiples ajustadas con Tukey HSD") |>
  fmt_number(decimals = 3) |>
  opt_stylize(style = 1) |> 
  tab_style_body(
    style = list(
                 cell_text(color = "#222831")),
    values = c("(Flx)")
  ) |>
  tab_style_body(
    style = list(
                 cell_text(color = "#00ADB5")),
    values = c("(Flx-CUMS)")) |>
  tab_style_body(
    style = list(
                 cell_text(color = "#FF2E63")),
    values = c(("(Sal-CUMS-F)"))
    ) |>
  opt_stylize(style = 1)

  
```


En conclusión, se resalta el mayor ritmo de aprendizaje en los entrenamientos reversa (@tbl-DMEDIACompsEnts) en el grupo de Flx, evidenciado por la pendiente más negativa, así como las diferencias en las medias estimadas en distintos puntos. 


## Pruebas

El análisis de las 3 pruebas del laberinto (adquisición, retención y aprendizaje reversa) se puede realizar con distintas métricas. De acuerdo a @maei2009, las medidas más utilizadas, en orden, son: porcentaje de tiempo en cuadrante blanco (4 cuadrantes), porcentaje de tiempo en zona blanco (definida como un círculo alrededor de la localización de la plataforma) y número de cruces (cruces alrededor de la localización de la plataforma). Sin embargo, los parámetros que reflejan con mayor precisión el desempeño en estas pruebas son: distancia promedio al blanco y entropía de Shannon. 

### Mapas de calor

El seguimiento de movimiento aporta información valiosa sobre el desarrollo del proceso de formación de preferencias, la cual puede emplearse de al menos tres maneras. La trayectoria del movimiento puede iluminar la fuerza relativa de la preferencia por las opciones (cuadrantes), o, en otras palabras, el grado de competencia entre las elecciones (cuadrante original vs cuadrante reversa) [@wulff2021]. 

```{r rtrack}
#| echo: false

load("./datos/rtrack/final_experiment.RData")

estrategias_rtrack <-  Rtrack::call_strategy(rtrack_experimento)


# ---- P1 
flx_p1_metrics =
  rtrack_experimento$metrics[rtrack_experimento$factors$Tratamiento == "Flx" &
                               (rtrack_experimento$factors$`_Day` == 5)]
# Flx-CUMS
flx_CUMS_p1_metrics =
  rtrack_experimento$metrics[rtrack_experimento$factors$Tratamiento == "Flx-CUMS" &
                               (rtrack_experimento$factors$`_Day` == 5)]
# Sal-CUMS-F
sal_cums_f_p1_metrics =
  rtrack_experimento$metrics[rtrack_experimento$factors$Tratamiento == "Sal-CUMS-F" &
                               (rtrack_experimento$factors$`_Day` == 5)]
# Ket-CUMS
ket_cums_p1_metrics =
  rtrack_experimento$metrics[rtrack_experimento$factors$Tratamiento == "Ket-CUMS" &
                               (rtrack_experimento$factors$`_Day` == 5)]
# Sal-CUMS-K
sal_cums_k_p1_metrics =
  rtrack_experimento$metrics[rtrack_experimento$factors$Tratamiento == "Sal-CUMS-K" &
                               (rtrack_experimento$factors$`_Day` == 5)]




# ---- P2 
flx_p2_metrics =
  rtrack_experimento$metrics[rtrack_experimento$factors$Tratamiento == "Flx" &
                               (rtrack_experimento$factors$`_Day` == 6)]
# Flx-CUMS
flx_CUMS_p2_metrics =
  rtrack_experimento$metrics[rtrack_experimento$factors$Tratamiento == "Flx-CUMS" &
                               (rtrack_experimento$factors$`_Day` == 6)]
# Sal-CUMS-F
sal_cums_f_p2_metrics =
  rtrack_experimento$metrics[rtrack_experimento$factors$Tratamiento == "Sal-CUMS-F" &
                               (rtrack_experimento$factors$`_Day` == 6)]
# Ket-CUMS
ket_cums_p2_metrics =
  rtrack_experimento$metrics[rtrack_experimento$factors$Tratamiento == "Ket-CUMS" &
                               (rtrack_experimento$factors$`_Day` == 6)]
# Sal-CUMS-K
sal_cums_k_p2_metrics =
  rtrack_experimento$metrics[rtrack_experimento$factors$Tratamiento == "Sal-CUMS-K" &
                               (rtrack_experimento$factors$`_Day` == 6)]


# ---- P-Rev 

flx_rev_metrics =
  rtrack_experimento$metrics[rtrack_experimento$factors$Tratamiento == "Flx" &
                               (rtrack_experimento$factors$`_Day` == 9)]
# Flx-CUMS
flx_CUMS_rev_metrics =
  rtrack_experimento$metrics[rtrack_experimento$factors$Tratamiento == "Flx-CUMS" &
                               (rtrack_experimento$factors$`_Day` == 9)]
# Sal-CUMS-F
sal_cums_f_rev_metrics =
  rtrack_experimento$metrics[rtrack_experimento$factors$Tratamiento == "Sal-CUMS-F" &
                               (rtrack_experimento$factors$`_Day` == 9)]
# Ket-CUMS
ket_cums_rev_metrics =
  rtrack_experimento$metrics[rtrack_experimento$factors$Tratamiento == "Ket-CUMS" &
                               (rtrack_experimento$factors$`_Day` == 9)]
# Sal-CUMS-K
sal_cums_k_rev_metrics =
  rtrack_experimento$metrics[rtrack_experimento$factors$Tratamiento == "Sal-CUMS-K" &
                               (rtrack_experimento$factors$`_Day` == 9)]


```


```{r mapascalorfluoxetina}
#| echo: false
#| label: fig-mapascalorfluox
#| fig-cap: "Mapas de Calor Fluoxetina."
#| fig-subcap: 
#|   - "Prueba-1"
#|   - "Prueba-2"
#|   - "Prueba-Reversa"
#| layout-ncol: 3

Rtrack::plot_density(
  flx_p1_metrics,
  title = "FLX P-1",
  col = viridis(300), # 738
  resolution = 900,
  feature.col = "#E87FB0",
  feature.lwd = 4,
  legend = F
)


Rtrack::plot_density(
  flx_p2_metrics,
  title = "FLX P-2",
  col = viridis(300), # 738
  resolution = 900,
  feature.col = "#E87FB0",
  feature.lwd = 4,
  legend = F
)

Rtrack::plot_density(
  flx_rev_metrics,
  title = "FLX Reversa",
  col = viridis(300), # 738
  resolution = 900,
  feature.col = "#E87FB0",
  feature.lwd = 4,
  legend = F
)

```


```{r fluoxetinaCumsMapa}
#| echo: false
#| label: fig-fluoxetinaCumsMapa
#| fig-cap: "Mapas de Calor Fluoxetina-CUMS."
#| fig-subcap: 
#|   - "Prueba-1"
#|   - "Prueba-2"
#|   - "Prueba-Reversa"
#| layout-ncol: 3

Rtrack::plot_density(
  flx_CUMS_p1_metrics,
  title = "FLX-CUMS P-1",
  col = viridis(300), # 738
  resolution = 900,
  feature.col = "#E87FB0",
  feature.lwd = 4,
  legend = F
)


Rtrack::plot_density(
  flx_CUMS_p2_metrics,
  title = "FLX-CUMS P-2",
  col = viridis(300), # 738
  resolution = 900,
  feature.col = "#E87FB0",
  feature.lwd = 4,
  legend = F
)

Rtrack::plot_density(
  flx_CUMS_rev_metrics,
  title = "Flx-CUMS Reversa",
  col = viridis(300), # 738
  resolution = 900,
  feature.col = "#E87FB0",
  feature.lwd = 4,
  legend = F
)

```

```{r salinaCUMSfMapa}
#| echo: false
#| label: fig-salinaCUMSfMapa
#| fig-cap: "Mapas de Calor Salina-CUMS-Fluoxetina."
#| fig-subcap: 
#|   - "Prueba-1"
#|   - "Prueba-2"
#|   - "Prueba-Reversa"
#| layout-ncol: 3

Rtrack::plot_density(
  sal_cums_f_p1_metrics,
  title = "Sal-CUMS-FLX P1",
  col = viridis(300), # 738
  resolution = 900,
  feature.col = "#E87FB0",
  feature.lwd = 4,
  legend = F
)

Rtrack::plot_density(
  sal_cums_f_p2_metrics,
  title = "Sal-CUMS-FLX P-2",
  col = viridis(300), # 738
  resolution = 900,
  feature.col = "#E87FB0",
  feature.lwd = 4,
  legend = F
)

Rtrack::plot_density(
  sal_cums_f_rev_metrics,
  title = "Sal-CUMS-F Reversa",
  col = viridis(300), # 738
  resolution = 900,
  feature.col = "#E87FB0",
  feature.lwd = 4,
  legend = F
)



```




### Distancia Media

```{r dfDistMedPrueb}
#| echo: false

df.distancia.media.pruebas.flx <- 
  df_wm_flx |> 
  # df_wm_otros |> 
  dplyr::select(distancia_media_blanco, distancia_annulus_so, distancia_annulus_ne, tratamientos, id, prueba, dia) |> 
  # dplyr::filter(str_detect(prueba, "Ent")) |> 
  dplyr::filter(str_detect(prueba, "P")) 


df.meandist.media.pruebas <- aggregate(df.distancia.media.pruebas.flx$distancia_media_blanco,
                                       by = list(df.distancia.media.pruebas.flx$prueba, 
                                                 df.distancia.media.pruebas.flx$tratamientos,
                                                 df.distancia.media.pruebas.flx$id),
                                       FUN = 'mean')

colnames(df.meandist.media.pruebas) <- c("prueba","tratamientos","id","distancia_media_blanco")

```

```{r ModeladoDistanciaMedia}
#| echo: false


lmer.dist.media.pruebas <- lmer(
  distancia_media_blanco ~ prueba * tratamientos + (1 | id),
  data = df.distancia.media.pruebas.flx
)




# aov_latencias_post <- aov(latencia ~ tratamientos * stage + Error(id/stage), 
#                           data = aov_latencias_post.df)

aov.dist.media.pruebas <- aov(distancia_media_blanco ~ tratamientos * prueba + Error(id), 
             data = df.meandist.media.pruebas)


```

Como se mencionó antes, esta es una métrica mucho más sensible que las anteriores. Aquí, una menor distancia implica un mejor aprendizaje espacial. 

Ajustamos un modelo lineal mixto (estimado usando REML) para predecir la distancia media al blanco a partir de la prueba y tratamientos (fórmula: `distancia_media_blanco ~ prueba * tratamientos`). El modelo incluyó a los sujetos como efecto aleatorio (fórmula:` ~1 | id`). El poder explicativo total del modelo es sustancial (R2 condicional = 0.72). Dentro de este modelo:


```{r EqDistanciaMedia}
#| echo: false
#| label: fig-EqDistanciaMedia
#| fig-cap: Ecuación de regresión Distancia Media.

equatiomatic::extract_eq(lmer.dist.media.pruebas, wrap = TRUE, terms_per_line = 4, operator_location = "start")

```

| Variable              | NumDF | DenDF  | F      | p      |
| --------------------- | ----- | ------ | ------ | ------ |
| Prueba                | 2     | 27.732 | 32.539 | <0.001 |
| Tratamientos          | 2     | 34.469 | 7.227  | 0.002  |
| Prueba x Tratamientos | 4     | 32.751 | 7.879  | <0.001 |
: Tabla de análisis de varianza del modelo de efectos Mixtos con aproximado de Satterthwaite. {#tbl-pruebasdmedaovtab}


```{r dmediaevalmodeloaovs}
#| echo: false
#| eval: false

anova(lmerTest::lmer(distancia_media_blanco ~ prueba * tratamientos + (1 | id),
  data = df.distancia.media.pruebas.flx))


plot_model(lmer.dist.media.pruebas, type = "int")

tbl_regression(lmer.dist.media.pruebas, 
               pvalue_fun = ~ style_pvalue(.x, digits = 3)) %>%
  add_global_p() |> 
  bold_p(t = 0.05) %>%
  bold_labels() %>%
  modify_header(label = "**Variable**") %>%
  as_gt()

tab_model(lmer.dist.media.pruebas)
```


```{r DMedPlotEmmeanPruebas}
#| echo: false
#| label: fig-DMedPlotEmmeanPruebas
#| fig-cap: "Distancia Media al annulus blanco en las tres Pruebas. Graficado con Media + error estándar."


lmer.dist.media.pruebas.emm <- emmeans(lmer.dist.media.pruebas,  
                        ~ tratamientos | prueba, cov.reduce = FALSE)


lmer.dist.media.pruebas.emm.df <- as.data.frame(lmer.dist.media.pruebas.emm)

lmer.dist.media.plot <- ggplot(lmer.dist.media.pruebas.emm.df,
                    aes(
                      x = prueba,
                      y = emmean,
                      group = tratamientos,
                      color = tratamientos
                    )) +
  geom_line(linewidth = 0.3, linetype = "dashed", position = position_dodge(0.1)) +
  geom_point(size = 4, position = position_dodge(0.1), aes(shape = tratamientos)) +
  # geom_point(size = 7, shape = 21, position = position_dodge(0.1)) +
  geom_pointrange(aes(ymin = emmean-SE, ymax = emmean+SE),
                  size = 0.75, position = position_dodge(0.1)) +
  scale_color_manual(values = c("#222831", "#00ADB5", "#FF2E63", "#FF9800", "#8675A9", "#862B0D")) +
  labs(
    # caption = "Plotted with SEM",
    color = "Tratamientos",
    shape = "Tratamientos",
    x = "Prueba",
    y = "Distancia (m)") +
  # ylim(0, 60) +
  # scale_x_discrete(labels=c("entrenamiento_rev_1"="1", "entrenamiento_rev_2"="2")) +
  # theme_classic()
  # ggthemes::theme_clean() +
  ggthemes::theme_clean() + 
  theme(legend.position='top', axis.text = element_text(size = 12),axis.title = element_text(size = 15)) 

lmer.dist.media.plot  + annotate(
  "text",
  label = "*",
  x = "P-2",
  y = .50,
  size = 8.5,
  colour =  "#00ADB5"
) +
  annotate(
    "text",
    label = "**",
    x = "P-Rev",
    y = .50,
    size = 8.5,
    colour =  "#FF2E63"
  )




```

```{r DMedPCompsEmmeans}
#| echo: false
#| label: tbl-DMedPCompsEmmeans
#| tbl-cap: "Contrastes significativos en Distancia Media."



emmeans(lmer.dist.media.pruebas, pairwise ~ tratamientos | prueba, adjust = "tukey",  cov.reduce = FALSE)$contrasts |>
  as_tibble() |>
  dplyr::select(-df, -t.ratio) |>
  dplyr::rename(Estimado = estimate) |>
  dplyr::filter(p.value <= 0.05) |>
  tidyr::separate(contrast, into = c("1", "2"), sep = " - ")  |> 
  gt::gt()  |> 
  tab_footnote("Comparaciones múltiples ajustadas con Tukey HSD") |> 
  fmt_number(decimals = 3) |>
  tab_style_body(
    style = list(
                 cell_text(color = "#222831")),
    values = c("Flx")
  ) |> 
  tab_style_body(
    style = list(
                 cell_text(color = "#00ADB5")),
    values = c("(Flx-CUMS)")) |>
  tab_style_body(
    style = list(
                 cell_text(color = "#FF2E63")),
    values = c(("(Sal-CUMS-F)"))
    ) |> 
  opt_stylize(style = 1)


# emmeans(aov.dist.media.pruebas, pairwise ~ tratamientos | prueba, adjust = "tukey",  cov.reduce = FALSE)$contrasts |>
#   as_tibble() |>
#   dplyr::select(-df, -t.ratio) |>
#   dplyr::rename(Estimado = estimate) |>
#   dplyr::filter(p.value <= 0.05) |>
#   tidyr::separate(contrast, into = c("1", "2"), sep = " - ")  |> 
#   gt::gt()  |> 
#   tab_footnote("Comparaciones múltiples ajustadas con Tukey HSD") |> 
#   fmt_number(decimals = 3) |>
#   tab_style_body(
#     style = list(
#                  cell_text(color = "#222831")),
#     values = c("Flx")
#   ) |> 
#   tab_style_body(
#     style = list(
#                  cell_text(color = "#00ADB5")),
#     values = c("(Flx-CUMS)")) |>
#   tab_style_body(
#     style = list(
#                  cell_text(color = "#FF2E63")),
#     values = c(("(Sal-CUMS-F)"))
#     ) |> 
#   opt_stylize(style = 1)
  

```

```{r dmediaTABreg}
#| echo: false
#| eval: false
#| label: tbl-dmediaTABreg

sjPlot::tab_model(lmer.dist.media.pruebas, aov.dist.media.pruebas$Within,
                  show.re.var = F,
                  # auto.label = TRUE,
                  # show.se = T,
                  # show.obs = T,
                  # show.fstat = T)
                  # show.reflvl = F, # nivel de referencia para factores
                  show.intercept = F,
                  show.r2 = F,
                  rm.terms = "Residuals",
                  # show.df = T
                  p.style = "numeric_stars",
                  # title = "Latencias Reversa Efectos Mixtos",
                  string.pred = "Predictores",
                  string.est = "Estimados",
                  pred.labels = c("Prueba-2", "Prueba-Reversa",
                                  "Flx-CUMS", "Sal-CUMS-F",
                                  "Prueba-2 x Flx-CUMS", "Prueba-Rev x Flx-CUMS",
                                  "Prueba-2 x Sal-CUMS-F", "Prueba-Rev x Sal-CUMS-F",
                                  "Tratamientos", "Prueba", "Tratamientos:Prueba"
                  ),
                  dv.labels = c("Efectos Mixtos lineal", "RM-ANOVA")
                  # file = "./tablas/dist_media_pruebas_fluox.html"
                  # string.se = "SEM"
)
```

La menor distancia media al annulus en la prueba reversa (@fig-DMedPlotEmmeanPruebas) para los grupos de Flx, en comparación con el grupo Salina, es evidencia que estos grupos reaprenden mejor la localización de la plataforma reversa. Esto se evidencía cuando comparamos el mapa de calor (@fig-salinaCUMSfMapa) del grupo de salina contra los grupos de fluoxetina. Enconclusión, el tratamiento con fluoxetina parece prevenir la falta de flexibilidad cognitiva que observamos en el grupo de Saluina cuando hay un protocolo de estrés crónico. De acuerdo a @garthe2016, esta flexibilidad cognitiva en el MWM está asociada a la integridad del hipocampo y potencialmente a la neurogénesis hipocampal adulta. 



### Entropía

```{r dfEntropi}
#| echo: false

entropia_df_filtrado <- read.csv("./datos/entropia/entropia_clean.csv") |> 
  # dplyr::filter(!str_detect(Id, "gris-2")) |>
  # dplyr::filter(!str_detect(Id, "2-1")) |>
  dplyr::filter(!str_detect(Id, "2b")) |>
  # dplyr::filter(!str_detect(Id, "1b")) |>
  # dplyr::filter(!str_detect(Id, "negro-2")) |>
  janitor::clean_names()  |> 
  mutate(dia = case_when (stage == "prueba_1" ~ 1,
                           stage == "prueba_2" ~ 2,
                           stage == "prueba_rev" ~ 3
                ), 
         entropia_blanco = case_when(
           stage == "prueba_1" ~ entropia_ne,
           stage == "prueba_2" ~ entropia_ne,
           stage == "prueba_rev" ~ entropia_so
         ))



entropia_df_filtrado_fluox <- entropia_df_filtrado |>
  janitor::clean_names() |> 
  dplyr::filter(!str_detect(experimento, "Keta"))

# table(entropia_df_filtrado_fluox$tratamiento)

entropia_df_filtrado_fluox$tratamiento <- as.factor(entropia_df_filtrado_fluox$tratamiento)

entropia_df_filtrado_fluox$tratamiento = factor(entropia_df_filtrado_fluox$tratamiento, 
                                levels=c("Flx","Fluoxetina-CUMS", "Salina-CUMS-F"))

# entropia_df_filtrado_fluox$tratamiento = factor(entropia_df_filtrado_fluox$tratamiento, 
#                                 levels=c("Flx","Fluoxetina-CUMS", "Salina-CUMS-F",
#                                          "Ketamina-CUMS", "Salina-CUMS-K"))


# df_wm_otros$tratamientos = factor(df_wm_otros$tratamientos, 
#                                   levels=c("Ctrl", "Ket-CUMS", "Sal-CUMS-K"))


df.mean.entropia <- aggregate(entropia_df_filtrado_fluox$entropia_blanco,
                     by = list(entropia_df_filtrado_fluox$stage, 
                               entropia_df_filtrado_fluox$tratamiento,
                               entropia_df_filtrado_fluox$id),
                     FUN = 'mean')

colnames(df.mean.entropia) <- c("prueba","tratamientos","id","entropia_blanco")


```


Está definida como la incertidumbre con la que se conoce una variable. Esta incertidumbre reduce con información (aprendizaje). En este sentido, una certidumbre de "0" significaría que el ratón pasó todo el tiempo en la localización de la plataforma blanco. Por otro lado, si el ratón exploró todo el laberinto acuático durante la prueba, la entropía sería máxima. Esta métrica describe el grado en que la búsqueda se centra en la localización de la plataforma, así cómo el enfoque de esta búsqueda. Los roedores tienden a mejorar el enfoque de la búsqueda (más organizada) para localizar la plataforma cuando aprenden mejor.  

El cálculo de esta métrica está basado en la descripción del artículo de @maei2009. Se obtiene al calcular la entropía de la trayectoria de nado y la entropía de error en varianza. 

Para calcular esta métrica, se realizaron los siguientes cálculos: 

i. Obtener las coordenadas del animal y la plataforma (en pixeles) para cada animal en las tres pruebas.

i. Calculamos la distancia del animal a la plataforma en cada tiempo. Para esto usamos la distancia Euclidiana tomando en cuenta las coordenadas del animal ($x_a, y_a$) y de la plataforma planco ($x_b, y_b$)

$$d = \sqrt{(x_a - x_b) + (y_a - y_b)^2} $$

i. Calculamos la varianza de los vectores de las distancias del animal respecto a la plataforma.

i. Calculamos $H_{error}$ basados en la fórmula $H_{error} = log(varianza_{distancia})$

i. Calculamos la varianza de la trayectoria $var(X_a) + var(Y_a)$

i. Para calcular la entropía de la trayectoria, realizamos la operación $H_{trayectoria} = log(var_{trayectoria})$

i. Por último, calculamos la entropía total $H_{total} = H_{error} + H_{trayectoria}$


```{r entropiaModelado}
#| echo: false

entropia.lmer.flx <- lmer(
  entropia_blanco ~ stage * tratamiento + (1 | id),
  data = entropia_df_filtrado_fluox
)



aov.entropia <- aov(entropia_blanco ~ tratamientos * prueba + Error(id/prueba), 
             data = df.mean.entropia)
```


```{r entromodelsum}
#| echo: false
#| eval: false

anova(lmerTest::lmer(entropia_blanco ~ stage * tratamiento + (1 | id) + (1 | stage),
  data = entropia_df_filtrado_fluox))

plot_model(entropia.lmer.flx, type = "int")

tbl_regression(entropia.lmer.flx, 
               pvalue_fun = ~ style_pvalue(.x, digits = 3)) %>%
  add_global_p() |> 
  bold_p(t = 0.05) %>%
  bold_labels() %>%
  modify_header(label = "**Variable**") %>%
  as_gt()

tab_model(entropia.lmer.flx)

report(entropia.lmer.flx)
```

De acuerdo a esta métrica, ajustamos un modelo lineal mixto (estimado usando REML) para predecir la entropia a partir de la prueba y tratamientos (fórmula: `entropia_blanco ~ etapa * tratamiento`). El modelo incluyó a los sujetos como efecto aleatorio (fórmula:` ~1 | id`). El poder explicativo total del modelo es sustancial (R2 condicional = 0.49). Dentro de este modelo, el efecto de la prueba 2 × tratamiento [**Fluoxetina-CUMS**] es estadísticamente significativo y positivo (beta = 0.75, IC del 95% [0.06, 1.43], t(73) = 2.16, p = 0.034; beta estandarizado = 1.06, IC del 95% [0.08, 2.04]). 


```{r EqEntropia}
#| echo: false
#| label: fig-EqEntropia
#| tbl-cap: "Ecuación de regresión para modelar la Entropia al annulus blanco."
equatiomatic::extract_eq(entropia.lmer.flx, wrap = TRUE, terms_per_line = 4, operator_location = "start")
```

| Variable              | NumDF | DenDF  | F      | p      |
| --------------------- | ----- | ------ | ------ | ------ |
| Prueba                | 2     | 50.000 | 29.1453| <0.001 |
| Tratamientos          | 2     | 25.000 | 0.4872 | 0.620  |
| Prueba x Tratamientos | 4     | 50.000 | 1.9190 | 0.1218 |
: Tabla de análisis de varianza del modelo de efectos Mixtos con aproximado de Satterthwaite. {#tbl-pruebasdmedaovtabentrop}

```{r RegrTabEntropia}
#| echo: false
#| eval: false
#| label: tbl-RegrTabEntropia


sjPlot::tab_model(entropia.lmer.flx, aov.entropia)


# sjPlot::tab_model(lmer.1, aov.1, 
#                   # auto.label = TRUE,
#                   # show.se = T,
#                   show.obs = F,
#                   # show.fstat = T)
#                   # show.reflvl = F, # nivel de referencia para factores
#                   show.intercept = F,
#                   show.r2 = F,
#                   rm.terms = "Residuals",
#                   # show.df = T
#                   p.style = "numeric_stars",
#                   # title = "Latencias Reversa Efectos Mixtos",
#                   string.pred = "Predictores",
#                   string.est = "Estimados",
#                   pred.labels = c("Prueba-2", "Prueba-Rev",
#                                   "Flx-CUMS", "Sal-CUMS-F",
#                                   "Prueba-2 x Flx-CUMS", "Prueba-Rev x Flx-CUMS",
#                                   "Prueba-2 x Sal-CUMS-F", "Prueba-Rev x Sal-CUMS-F",
#                                   "Tratamientos", "Prueba", "Tratamientos x Prueba"
#                   ),
#                   dv.labels = c("Efectos Mixtos lineal", "RM-ANOVA"),
#                   file = "./tablas/entropia_blanco.html"
#                   # string.se = "SEM"
# )

```

```{r PlotEntropialmer}
#| echo: false
#| label: fig-PlotEntropialmer
#| fig-cap: "Medias marginales estimadas para la variable de Entropia al annulus blanco. Graficado con media +- error estándar."

entropia.lmer.flx.emmeans <- emmeans(entropia.lmer.flx,  
                        ~ tratamiento | stage, cov.reduce = FALSE)


entropia.lmer.flx.emmeans.df <- as.data.frame(entropia.lmer.flx.emmeans)

entropia.flx.emmeans.plot <- ggplot(entropia.lmer.flx.emmeans.df,
                    aes(
                      x = stage,
                      y = emmean,
                      group = tratamiento,
                      color = tratamiento
                    )) +
  geom_line(linewidth = 0.3, linetype = "dashed", position = position_dodge(0.1)) +
  geom_point(size = 5.5, position = position_dodge(0.1), shape = 21) +
  # geom_point(size = 7, shape = 21, position = position_dodge(0.1)) +
  geom_pointrange(aes(ymin = emmean-SE, ymax = emmean+SE),
                  size = 0.75, position = position_dodge(0.1)) +
  scale_color_manual(values = c("#222831", "#00ADB5", "#FF2E63", "#FF9800", "#8675A9", "#862B0D")) +
  labs(
    # caption = "Plotted with SEM",
    color = "Tratamientos",
    shape = "Tratamientos",
    x = "Prueba",
    y = "H") +
  # ylim(0, 60) +
  scale_x_discrete(labels=c("prueba_1"="P-1", "prueba_2"="P-2", "prueba_rev"="P-Rev")) +
  # theme_classic()
  # ggthemes::theme_clean() +
  ggthemes::theme_clean() + 
  theme(legend.position='top', axis.text = element_text(size = 12),axis.title = element_text(size = 15)) 

entropia.flx.emmeans.plot


###
###
###

# entropia.emmeans.aov <- emmeans(aov.entropia,  
                        # ~ tratamientos | prueba)


# entropia.emmeans.aov.df <- as.data.frame(entropia.emmeans.aov)
# 
# entropia.aov.flx.emmeans.plot <- ggplot(entropia.emmeans.aov.df,
#                     aes(
#                       x = prueba,
#                       y = emmean,
#                       group = tratamientos,
#                       color = tratamientos
#                     )) +
#   geom_line(linewidth = 0.3, linetype = "dashed", position = position_dodge(0.1)) +
#   geom_point(size = 5.5, position = position_dodge(0.1), shape = 21) +
#   # geom_point(size = 7, shape = 21, position = position_dodge(0.1)) +
#   geom_pointrange(aes(ymin = emmean-SE, ymax = emmean+SE),
#                   size = 0.75, position = position_dodge(0.1)) +
#   scale_color_manual(values = c("#222831", "#00ADB5", "#FF2E63", "#FF9800", "#8675A9", "#862B0D")) +
#   labs(
#     caption = "Plotted with SEM",
#     color = "Tratamientos",
#     shape = "Tratamientos",
#     x = "Prueba",
#     y = "H") +
#   # ylim(0, 60) +
#   scale_x_discrete(labels=c("prueba_1"="P-1", "prueba_2"="P-2", "prueba_rev"="P-Rev")) +
#   # theme_classic()
#   # ggthemes::theme_clean() +
#   ggthemes::theme_clean() + 
#   theme(legend.position='top', axis.text = element_text(size = 12),axis.title = element_text(size = 15)) 

# entropia.aov.flx.emmeans.plot
```

```{r ContrastestEntropialmer}
#| echo: false
#| label: tbl-ContrastestEntropialmer
#| tbl-cap: "Contrastes múltiples para las pruebas de entropía."


emmeans(entropia.lmer.flx, pairwise ~ tratamiento | stage, adjust = "none",  cov.reduce = FALSE)$contrasts |>
  as_tibble() |>
  # dplyr::filter(!str_detect(contrast, "K")) |>
  select(-df, -t.ratio, -SE) |>
  dplyr::rename(
    # prueba = dia,
         Estimado = estimate) |>
  dplyr::filter(p.value <= 0.05) |>
  separate(contrast, into = c("1", "2"), sep = " - ") |>
  gt::gt()  |> 
  # tab_footnote("Comparaciones múltiples ajustadas con Tukey HSD") |> 
  fmt_number(decimals = 3) |>
  tab_style_body(
    style = list(
      cell_text(color = "#222831")),
    values = c("Flx")
  ) |> 
  tab_style_body(
    style = list(
      cell_text(color = "#00ADB5")),
    values = c("(Flx-CUMS)")) |>
  tab_style_body(
    style = list(
      cell_text(color = "#FF2E63")),
    values = c(("(Sal-CUMS-F)"))
  ) |> 
  opt_stylize(style = 1)


# emmeans(aov.entropia, pairwise ~ tratamientos | prueba, adjust = "none",  cov.reduce = FALSE)$contrasts |>
#   as_tibble() |>
#   # dplyr::filter(!str_detect(contrast, "K")) |>
#   select(-df, -t.ratio, -SE) |>
#   dplyr::rename(
#     # prueba = dia,
#          Estimado = estimate) |>
#   dplyr::filter(p.value <= 0.05) |>
#   separate(contrast, into = c("1", "2"), sep = " - ") |>
#   gt::gt()  |> 
#   # tab_footnote("Comparaciones múltiples ajustadas con Tukey HSD") |> 
#   fmt_number(decimals = 3) |>
#   tab_style_body(
#     style = list(
#       cell_text(color = "#222831")),
#     values = c("Flx")
#   ) |> 
#   tab_style_body(
#     style = list(
#       cell_text(color = "#00ADB5")),
#     values = c("(Flx-CUMS)")) |>
#   tab_style_body(
#     style = list(
#       cell_text(color = "#FF2E63")),
#     values = c(("(Sal-CUMS-F)"))
#   ) |> 
#   opt_stylize(style = 1)

```

Al analizar las pruebas con esta métrica, fallamos en detectar una diferencia en las medias marginales en la prueba reversa. Sin embargo, como señala @meenakshi2022, esta métrica evalúa más el grado de dispersión en la prueba, más que el grado de localización (como la distancia media) en la prueba. Es decir,  este parámetro estima el grado de desorganización en el rendimiento del MWM y no específicamente una propiedad espacial o de navegación. @smaldino2015 señala que la interpretación de la entropía en pruebas de aprendizaje se complica cuando se introduce más de una opción (más de un blanco). En estos casos, un aumento de entropía podría significar cambios en los patrones de conducta que lleven al animal a tomar nuevas estrategias una vez que se identificó que la pltaforma no está presente, más que una falta de aprendizaje. Debido a que muy pocos artículos exploran esta métrica (y hasta nuestro conocimiento ninguno en el contexto de aprendizaje reversa posterior a un protocolo de CUMS), es dificil comparar e interpretar nuestros resultados. 


### Tiempo en cuadrantes

Evaluar el tiempo que el roedor pasa en el cuadrante blanco (cuatro cuadrantes imaginarios del mismo tamaño) ha sido la métrica clásica para el análisis de la memoria y aprendizaje espacial en el MWM por su facilidad. Sin embargo, no es la métrica más confiable para representar el aprendizaje [@maei2009a]. Además, a nivel de los modelos estadísticos es muy difícil evaluar esta prueba debido a que el tiempo pasado en los 4 cuadrantes no es homogéneo, generando una distribución no normal de los parámetros y  heterocedasticidad [@maugard2019]. Para tratar de lidiar con estos problemas se va a utilizar un modelo con efectos mixtos, el cual es más robusto a la violación de estos supuestos [@schielzeth2020].   

Ajustamos un modelo lineal mixto (estimado usando REML) para predecir el tiempo en cuadrantes a partir de la prueba, tratamientos y el tipo de cuadrante (noreste, noroeste, sureste, suroeste) (fórmula: `tiempo_cuadrante ~ prueba * tratamientos * cuadrante`). El modelo incluyó a los sujetos como efecto aleatorio (fórmula: `~1 | id`). El poder explicativo total del modelo es sustancial (R2 condicional = 0.59). 

```{r dfTiempoCuad}
#| echo: false

df.cuadrantes <- df_wm_flx |> 
  select(cuadrante_so, cuadrante_ne, cuadrante_no, cuadrante_se, 
         id, tratamientos, stage, dia, prueba) |> 
  dplyr::filter(str_detect(prueba, "P")) 



df.cuadrantes.long <- df.cuadrantes |> 
  pivot_longer(
    cols = starts_with("cuadrante"), 
    names_to = "cuadrante",
    values_to = "tiempo_cuadrante",
    values_drop_na = TRUE
  )

df.cuadrantes.long$cuadrante <- as.factor(df.cuadrantes.long$cuadrante)


###

df.mean.cuadrantes <- aggregate(df.cuadrantes.long$tiempo_cuadrante,
                     by = list(df.cuadrantes.long$prueba, 
                               df.cuadrantes.long$tratamientos,
                               df.cuadrantes.long$id,
                               df.cuadrantes.long$cuadrante),
                     FUN = 'mean')

colnames(df.mean.cuadrantes) <- c("prueba","tratamientos","id","cuadrante", "tiempo_cuadrante")

```

```{r CuadrantesModelado}
#| echo: false

lmer.cuadrantes <- lmer(
  tiempo_cuadrante ~ prueba * tratamientos * cuadrante + (1 | id),
  data = df.cuadrantes.long
)



aov.cuadrantes <- aov(tiempo_cuadrante ~ tratamientos * prueba * cuadrante + Error(id), 
                      data = df.mean.cuadrantes)


# library(rstatix)
# res.aov <- anova_test(
#   data = df.mean, dv = distancia_media_blanco, wid = id,
#   within = c(tratamientos, prueba)
# )
# get_anova_table(aov.1)
```

```{r cuadrmodelsum}
#| echo: false
#| eval: false

anova(lmerTest::lmer(tiempo_cuadrante ~ prueba * tratamientos * cuadrante + (1 | id),
  data = df.cuadrantes.long))

plot_model(lmer.cuadrantes, type = "int")

tbl_regression(lmer.cuadrantes, 
               pvalue_fun = ~ style_pvalue(.x, digits = 3)) %>%
  add_global_p() |> 
  bold_p(t = 0.05) %>%
  bold_labels() %>%
  modify_header(label = "**Variable**") %>%
  as_gt()

tab_model(lmer.cuadrantes)

report(lmer.cuadrantes)
```

```{r EqCuadrantes}
#| echo: false

equatiomatic::extract_eq(lmer.cuadrantes)

```

| Variable              | NumDF | DenDF  | F      | p      |
| --------------------- | ----- | ------ | ------ | ------ |
| Prueba                | 2     | 240    | 0.0001 | 0.999  |
| Tratamiento           | 2     | 240    | 0.0000 | 0.999  |
| Cuadrante             | 3     | 240    | 34.9483| <0.001 |
| Prueba x Tratamiento  | 4     | 240    | 0.0000 | 0.999  |
| Prueba x Cuadrante    | 6     | 240    | 36.2731| <0.001 |
| Cuadra x Tratamientos | 6     | 240    | 3.8514 | 0.001  |
| Prueba x Cuad x Trat  | 12    | 240    | 4.4075 | <0.001 |
: Tabla de análisis de varianza del modelo de efectos Mixtos con aproximado de Satterthwaite. {#tbl-pruebasdmedaovtabentrop}

```{r CuadTab}
#| echo: false
#| eval: false

sjPlot::tab_model(lmer.cuadrantes)

# sjPlot::tab_model(lmer.2, aov.1$Within,
#                   # auto.label = TRUE,
#                   # show.se = T,
#                   show.obs = F,
#                   # show.fstat = T,
#                   # show.reflvl = T, # nivel de referencia para factores
#                   show.intercept = F,
#                   show.r2 = F,
#                   show.ci = F,
#                   rm.terms = "Residuals",
#                   # show.df = T,
#                   p.style = "numeric_stars",
#                   # title = "Latencias Reversa Efectos Mixtos",
#                   string.pred = "Predictores",
#                   string.est = "Estimados",
#                   # pred.labels = c("Prueba-2", 
#                   #                 "Prueba-Reversa",
#                   #                 "Flx-CUMS", "Sal-CUMS-F",
#                   #                 "Cuadrante-Adyacente-1", "Cuadrante-Adyacente-2", "Cuadrante-Reversa", 
#                   #                 "Prueba-2 x Flx-CUMS", "Prueba-Rev x Flx-CUMS",
#                   #                 "Prueba-2 x Sal-CUMS-F", "Prueba-Rev x Sal-CUMS-F",
#                   #                 "Tratamientos", "Prueba", "Cuadrante",
#                   #                 "Tratamientos:Prueba", "Tratamientos:Cuadrante", "Prueba:Cuadrante",
#                   #                 "Tratamientos:Prueba:Cuadrante"
#                   # ),
#                   dv.labels = c("Efectos Mixtos lineal", "RM-ANOVA"),
#                   file = "./tablas/cuadrantes_fluox.html"
#                   # string.se = "SEM"
# )
```



```{r CuadPlot}
#| echo: false
#| label: fig-CuadPlot
#| fig-cap: "Medias estimadas para los cuatro cuadrantes a lo largo de las tres pruebas. Con linea punteada se marca el tiempo de 15 segundos, el cual representa un 25% del tiempo total en dicho cuadrante (es decir, preferencia por dicho cuadrante). El total de la prueba es de 60 segundos."

cuadrantes.emmeans.lmer <- emmeans(lmer.cuadrantes,  
                        ~ tratamientos | prueba | cuadrante, cov.reduce = FALSE)


cuadrantes.emmeans.lmer.df <- as.data.frame(cuadrantes.emmeans.lmer)

cuadrantes.emmeans.lmer.df$cuadrante = factor(cuadrantes.emmeans.lmer.df$cuadrante, 
                                levels=c("cuadrante_no","cuadrante_ne", 
                                         "cuadrante_so", "cuadrante_se"), 
                                labels = c("Opuesto 1","BLANCO Original", 
                                           "BLANCO Reversa", "Opuesto 2"))


 
library(gghighlight)

cuadrantes.lmer.plot <- ggplot(cuadrantes.emmeans.lmer.df,
                    aes(
                      x = prueba,
                      y = emmean,
                      group = tratamientos,
                      color = tratamientos
                    )) +
  geom_line(linewidth = 0.3, linetype = "dashed", position = position_dodge(0.1)) +
  geom_point(size = 3, position = position_dodge(0.1), aes(shape = tratamientos)) +
  # geom_point(size = 7, shape = 21, position = position_dodge(0.1)) +
  geom_pointrange(aes(ymin = emmean-SE, ymax = emmean+SE),
                  size = 0.75, position = position_dodge(0.1)) +
  scale_color_manual(values = c("#222831", "#00ADB5", "#FF2E63", "#FF9800", "#8675A9", "#862B0D")) +
  facet_wrap( ~ cuadrante, axis.labels = "all_x") +
  gghighlight(emmean > 15, calculate_per_facet = T, use_direct_label = FALSE,
              unhighlighted_params = list(colour = NULL, alpha = 0.3)) +
  geom_hline(yintercept=15, linetype="dashed", color = "#006769", linewidth = 0.6) +
  labs(
    # caption = "Plotted with SEM",
    color = "Tratamientos",
    shape = "Tratamientos",
    x = "Prueba",
    y = "Segundos (s)") +
  ylim(0, 40) +
  # scale_x_discrete(labels=c("entrenamiento_rev_1"="1", "entrenamiento_rev_2"="2")) +
  # theme_classic() +
  # ggthemes::theme_base() +
  ggthemes::theme_clean() +
  # ggthemes::theme_clean() + 
  theme(legend.position='top', axis.text = element_text(size = 12),axis.title = element_text(size = 15)) 




cuadrantes.lmer.plot
```


```{r CuadrantesComps}
#| echo: false
#| label: tbl-CuadrantesComps
#| tbl-cap: "Contrastes significativos en Latencias de escape."


emmeans(lmer.cuadrantes, pairwise ~ tratamientos | prueba | cuadrante, adjust = "tukey",  cov.reduce = FALSE)$contrasts |>
  as_tibble() |>
  # dplyr::filter(!str_detect(contrast, "K")) |>
  select(-t.ratio, -SE) |>
  dplyr::rename(
    # prueba = dia,
    Estimado = estimate) |>
  dplyr::filter(p.value <= 0.05) |>
  separate(contrast, into = c("1", "2"), sep = " - ") |>
  gt::gt()  |> 
  tab_footnote("Comparaciones múltiples ajustadas con Tukey HSD") |> 
  fmt_number(decimals = 3) |>
  tab_style_body(
    style = list(
                 cell_text(color = "#222831")),
    values = c("Flx")
  ) |> 
  tab_style_body(
    style = list(
                 cell_text(color = "#00ADB5")),
    values = c("(Flx-CUMS)")) |>
  tab_style_body(
    style = list(
                 cell_text(color = "#FF2E63")),
    values = c(("(Sal-CUMS-F)"))
    ) |> 
  opt_stylize(style = 1)


# emmeans(aov.cuadrantes, pairwise ~ tratamientos | prueba | cuadrante, adjust = "tukey",  cov.reduce = FALSE)$contrasts |> 
#   as_tibble() |>
#   # dplyr::filter(!str_detect(contrast, "K")) |>
#   select(-t.ratio, -SE) |>
#   dplyr::rename(
#     # prueba = dia,
#     Estimado = estimate) |>
#   dplyr::filter(p.value <= 0.05) |>
#   separate(contrast, into = c("1", "2"), sep = " - ") |>
#   gt::gt()  |> 
#   tab_footnote("Comparaciones múltiples ajustadas con Tukey HSD") |> 
#   fmt_number(decimals = 3) |>
#   tab_style_body(
#     style = list(
#                  cell_text(color = "#222831")),
#     values = c("Flx")
#   ) |> 
#   tab_style_body(
#     style = list(
#                  cell_text(color = "#00ADB5")),
#     values = c("(Flx-CUMS)")) |>
#   tab_style_body(
#     style = list(
#                  cell_text(color = "#FF2E63")),
#     values = c(("(Sal-CUMS-F)"))
#     ) |> 
#   opt_stylize(style = 1)
```


Lo más destacable de esta métrica es que se observa un olvido paulatino en la preferencia del Blanco original, en especial en los grupos de Flx (@fig-CuadPlot). Para la prueba reversa, el grupo de Salina es el único que sigue presentando una preferencia por este cuadrante original. Por otro lado, solo los grupos de Flx presentan una preferencia por el blanco reversa en la prueba reversa, resaltando de nuevo que estos grupos presentan una mayor flexibilidad cognitiva. 



### Porcentaje en Zonas

Esta métrica evalúa el tiempo que los ratones pasan en una zona de 11 cm alrededor de la localización del annulus blanco. Es una métrica más sensible que evaluar el tiempo en cuadrantes, aunque no tanto como distancia media [@maei2009a].

Ajustamos un modelo lineal mixto (estimado usando REML) para predecir el tiempo en zona a partir de la prueba, tratamientos y el tipo de cuadrante (noreste, noroeste, sureste, suroeste) (fórmula: `tiempo_zona ~ prueba * tratamientos * cuadrante`). El modelo incluyó a los sujetos como efecto aleatorio (fórmula: `~1 | id`). El poder explicativo total del modelo es sustancial (R2 condicional = 0.70). 

```{r dfZonas}
#| echo: false

df.zonas <- df_wm_flx |> 
  select(
    # zona_blanco, 
    zona_ne, zona_so, 
         id, tratamientos, stage, dia, prueba) |> 
  dplyr::filter(str_detect(prueba, "P")) 



df.zonas.long <- df.zonas  |> 
  pivot_longer(
    cols = starts_with("zona"),
    names_to = "zona",
    values_to = "tiempo_zona",
    values_drop_na = TRUE
  )
df.zonas.long$zona <- as.factor(df.zonas.long$zona)
# str(df.zonas.long)
# 
# 

df.mean.zonas <- aggregate(df.zonas.long$tiempo_zona,
                     by = list(df.zonas.long$prueba, 
                               df.zonas.long$tratamientos,
                               df.zonas.long$id,
                               df.zonas.long$zona),
                     FUN = 'mean')

colnames(df.mean.zonas) <- c("prueba","tratamientos","id","zona", "tiempo_zona")

# str(df.mean)

```



```{r ModeladoZonas}
#| echo: false

lmer.zonas <- lmer(
  tiempo_zona ~ prueba * tratamientos * zona  + (1 | id),
  data = df.zonas.long
)


aov.zonas <- aov(tiempo_zona ~ tratamientos * prueba * zona + Error(id), 
             data = df.mean.zonas)
```


```{r zonamodelsum}
#| echo: false
#| eval: false

anova(lmerTest::lmer(tiempo_zona ~ prueba * tratamientos * zona  + (1 | id),
  data = df.zonas.long))

plot_model(lmer.zonas, type = "int")

tbl_regression(lmer.zonas, 
               pvalue_fun = ~ style_pvalue(.x, digits = 3)) %>%
  add_global_p() |> 
  bold_p(t = 0.05) %>%
  bold_labels() %>%
  modify_header(label = "**Variable**") %>%
  as_gt()

tab_model(lmer.zonas)

report(lmer.zonas)
```

```{r eqZonas}
#| echo: false

equatiomatic::extract_eq(lmer.zonas)
```



| Variable              | NumDF | DenDF  | F      | p      |
| --------------------- | ----- | ------ | ------ | ------ |
| Prueba                | 2     | 120    | 14.2851| <0.001 |
| Tratamiento           | 2     | 120    | 2.0632 | 0.1315 |
| Zona                  | 1     | 120    | 24.6864| <0.001 |
| Prueba x Tratamiento  | 4     | 120    | 2.0922 | 0.0860 |
| Prueba x Zona         | 2     | 120    | 100.193| <0.001 |
| Zona   x Tratamientos | 2     | 120    | 5.0092 | <0.001 |
| Prueba x zona x Trat  | 4     | 120    | 11.4956| <0.001 |
: Tabla de análisis de varianza del modelo de efectos Mixtos con aproximado de Satterthwaite. {#tbl-pruebasdmedaovtabentropzonas

```{r PlotsZonas}
#| echo: false
#| label: fig-PlotsZonas
#| fig-cap: "PlotsZonas."


emmeans.zonas <- emmeans(lmer.zonas,  
                        ~ tratamientos | prueba | zona , cov.reduce = FALSE)


emmeans.zonas.df <- as.data.frame(emmeans.zonas)


emmeans.zonas.df$zona = factor(emmeans.zonas.df$zona, 
                                   levels=c("zona_ne","zona_so"), 
                                   labels = c("Zona Original", 
                                              "Zona Reversa"))

library(gghighlight)

lmer.zonas.plot <- ggplot(emmeans.zonas.df,
                    aes(
                      x = prueba,
                      y = emmean,
                      group = tratamientos,
                      color = tratamientos
                    )) +
  geom_line(linewidth = 0.3, linetype = "dashed", position = position_dodge(0.1)) +
  geom_point(size = 4, position = position_dodge(0.1), aes(shape = tratamientos)) +
  # geom_point(size = 7, shape = 21, position = position_dodge(0.1)) +
  geom_pointrange(aes(ymin = emmean-SE, ymax = emmean+SE),
                  size = 0.75, position = position_dodge(0.1)) +
  scale_color_manual(values = c("#222831", "#00ADB5", "#FF2E63", "#FF9800", "#8675A9", "#862B0D")) +
  facet_wrap(~ zona) +
  gghighlight(emmean > 6.6, calculate_per_facet = T, use_direct_label = FALSE,
              unhighlighted_params = list(colour = NULL, alpha = 0.3)) +
  geom_hline(yintercept=6.6, linetype="dashed", color = "#006769", linewidth = 0.6) +
  labs(
    caption = "Plotted with SEM",
    color = "Tratamientos",
    shape = "Tratamientos",
    x = "Prueba",
    y = "Segundos") +
  # ylim(0, 30) +
  # scale_x_discrete(labels=c("entrenamiento_rev_1"="1", "entrenamiento_rev_2"="2")) +
  # theme_classic()
  ggthemes::theme_clean() +
  # ggthemes::theme_base() +
  # ggthemes::theme_clean() +
  theme(legend.position='top', axis.text = element_text(size = 12),axis.title = element_text(size = 15))

lmer.zonas.plot

# 
# zonas.aov.emmeans <- emmeans(aov.zonas,  
#                        ~ tratamientos | prueba | zona, cov.reduce = FALSE)
# 
# 
# zonas.aov.emmeans.df <- as.data.frame(zonas.aov.emmeans)
# 
# aov_plot <- ggplot(zonas.aov.emmeans.df,
#                    aes(
#                      x = prueba,
#                      y = emmean,
#                      group = tratamientos,
#                      color = tratamientos
#                    )) +
#   geom_line(linewidth = 0.3, linetype = "dashed", position = position_dodge(0.1)) +
#   geom_point(size = 5.4, position = position_dodge(0.1), shape = 21) +
#   # geom_point(size = 7, shape = 21, position = position_dodge(0.1)) +
#   geom_pointrange(aes(ymin = emmean-SE, ymax = emmean+SE),
#                   size = 0.75, position = position_dodge(0.1)) +
#   scale_color_manual(values = c("#222831", "#00ADB5", "#FF2E63", "#FF9800", "#8675A9", "#862B0D")) +
#   facet_wrap( ~ zona, axis.labels = "all_x") +
#   gghighlight(emmean > 6.6, calculate_per_facet = T, use_direct_label = FALSE,
#               unhighlighted_params = list(colour = NULL, alpha = 0.3)) +
#   geom_hline(yintercept=6.6, linetype="dashed", color = "#006769", linewidth = 0.6) +
#   labs(
#     caption = "Plotted with SEM",
#     color = "Tratamientos",
#     shape = "Tratamientos",
#     x = "Prueba",
#     y = "Segundos (s)") +
#   # ylim(0, 40) +
#   # scale_x_discrete(labels=c("entrenamiento_rev_1"="1", "entrenamiento_rev_2"="2")) +
#   # theme_classic()
#   # ggthemes::theme_clean() +
#   ggthemes::theme_clean() + 
#   theme(legend.position='top', axis.text = element_text(size = 12),axis.title = element_text(size = 15)) 
# 
# aov_plot


```


```{r ContrastZonas}
#| echo: false
#| label: tbl-ContrastZonas
#| tbl-cap: "Contrastes significativos Zonas."


emmeans(lmer.zonas, pairwise ~ tratamientos | prueba | zona, adjust = "tukey",  cov.reduce = FALSE)$contrasts |> 
  dplyr::as_tibble() |>  
  dplyr::select(-t.ratio) |>
  dplyr::rename(Estimado = estimate) |> 
  dplyr::filter(p.value <= 0.05) |>
  tidyr::separate(contrast, into = c("1", "2"), sep = " - ") |> 
  gt::gt()  |> 
  tab_footnote("Comparaciones múltiples ajustadas con Tukey HSD") |> 
  fmt_number(decimals = 3) |>
  tab_style_body(
    style = list(
                 cell_text(color = "#222831")),
    values = c("Flx")
  ) |> 
  tab_style_body(
    style = list(
                 cell_text(color = "#00ADB5")),
    values = c("(Flx-CUMS)")) |>
  tab_style_body(
    style = list(
                 cell_text(color = "#FF2E63")),
    values = c(("(Sal-CUMS-F)"))
    ) |> 
  opt_stylize(style = 1)


# emmeans(aov.zonas, pairwise ~ tratamientos | prueba | zona, adjust = "tukey",  cov.reduce = FALSE)$contrasts |> 
#   dplyr::as_tibble() |>  
#   dplyr::select(-t.ratio) |>
#   dplyr::rename(Estimado = estimate) |> 
#   dplyr::filter(p.value <= 0.05) |>
#   tidyr::separate(contrast, into = c("1", "2"), sep = " - ") |> 
#   gt::gt()  |> 
#   tab_footnote("Comparaciones múltiples ajustadas con Tukey HSD") |> 
#   fmt_number(decimals = 3) |>
#   tab_style_body(
#     style = list(
#                  cell_text(color = "#222831")),
#     values = c("Flx")
#   ) |> 
#   tab_style_body(
#     style = list(
#                  cell_text(color = "#00ADB5")),
#     values = c("(Flx-CUMS)")) |>
#   tab_style_body(
#     style = list(
#                  cell_text(color = "#FF2E63")),
#     values = c(("(Sal-CUMS-F)"))
#     ) |> 
#   opt_stylize(style = 1)


```

De nuevo, se destaca que el grupo de Salina tiene una mayor persistencia en la zona original en la prueba reversa, mientras que los grupos de Flx reaprenden mejor la localización de la zona reversa. Esto es otra evidencia de la falta de flexibilidad cognitiva asociada al protocolo de estrés y cómo la fluoxetina parece prevenir este efecto.  




### Otros resultados y discusión

#### Cepa de ratones utilizada

En el protocolo experimental original se tenían contempladas otras pruebas conductuales para evaluar los estados de tipo ansioso y de tipo depresivo. Sin embargo, tenemos resultados problemáticos. Por ejemplo, parece ser que la fluoxetina tiene efectos ansiogénicos (@fig-perfieria, @fig-medio, @fig-centro), que la ketamina promueve conductas de tipo depresivas (@fig-inmovSegment) o que la solución salina tiene efectos antidepresivos (@fig-inmovtot). 


En investigaciones biomédicas, la selección de la cepa de ratones es crucial dado que las características genéticas y fisiológicas pueden influir significativamente en los resultados experimentales. En mi estudio, utilicé una cepa híbrida de ratones C57BL6/J cruzados con BALB/c, lo que parece haber impactado los resultados obtenidos, posiblemente debido a la heterogeneidad genética y la variabilidad en la respuesta al estrés y a los fármacos.

Un estudio relevante [@gosselin2017] que examina las respuestas comportamentales y farmacológicas en las cepas C57BL6/J y BALB/c nos proporciona una visión clara de cómo las diferencias entre estas cepas pueden afectar los resultados experimentales. Según este estudio, mientras que los ratones BALB/c mostraron efectos antidepresivos esperados al ser tratados con fluoxetina bajo un protocolo de estrés crónico leve impredecible, los ratones C57BL6/J exhibieron respuestas paradójicas, como un aumento en la latencia de olfateo en pruebas de supresión de la novedad alimentaria, un efecto contrario al esperado.

Este hallazgo es significativo porque destaca la complejidad inherente al trabajar con cepas híbridas como la utilizada en mi experimento. La combinación de características de dos cepas con respuestas farmacológicas y comportamentales distintas podría llevar a una variabilidad fenotípica en la descendencia que complica la interpretación de los efectos del tratamiento. Esto es especialmente relevante en estudios de comportamiento y farmacología, donde la consistencia genética es esencial para la reproducibilidad y la interpretación clara de los resultados.

En otro estudio se utilizaró el laberinto elevado más cruz (EPM) y campo abierto (OF) y se analizaron las variables de comportamiento de estas cepas y sus híbridos F1 (B6CBF1), así como ratones quiméricos C57BL/6 × BALB/c (CHIM) creados mediante agregación de embriones. Este análisis reveló diferencias significativas dependiendo del grado de quimerismo, especialmente en los ratones CHIM [@carola2004].

Los ratones CHIM con un componente de pelaje predominante de C57BL/6 o BALB/c mostraron comportamientos similares a la cepa dominante, mientras que aquellos con un grado intermedio de quimerismo exhibieron comportamientos que diferían de ambas cepas consanguíneas. Además, se observó que los ratones CHIM y B6CBF1 con quimerismo intermedio compartían estrategias de afrontamiento al estrés que no describen las cepas consanguíneas, como una actividad motora mayormente limitada a áreas protegidas y intentos de acercarse a áreas ansiogénicas mientras procesan y almacenan información externa.

Estos hallazgos son cruciales, ya que indican que la presencia equilibrada de los antecedentes genéticos de C57BL/6 y BALB/c, ya sea en la misma célula o en células diferentes, genera estrategias de afrontamiento al estrés distintas a las de las cepas consanguíneas. Este fenómeno subraya la complejidad de trabajar con cepas híbridas, como en el caso de mi estudio, donde la combinación genética podría haber conducido a respuestas conductuales y farmacológicas no previstas, complicando la interpretación de los resultados experimentales. La variabilidad en las respuestas observadas podría, por lo tanto, ser atribuida a la diversidad genética y fenotípica de la cepa cruzada utilizada, lo que resalta la importancia de seleccionar cuidadosamente la cepa en investigaciones que evalúan comportamientos complejos y respuestas a tratamientos.

Además, investigaciones adicionales sobre la anatomía hipocampal en quimeras artificiales generadas por la agregación de embriones de las cepas C57BL/6J y BALB/cJ refuerzan la idea de la complejidad inherente al uso de modelos híbridos en estudios científicos. Contrario a lo esperado, las quimeras no siempre mostraron características intermedias entre las cepas parentales. En muchos casos, estas quimeras mostraron rangos fenotípicos que superaban cualitativa y cuantitativamente los de las cepas parentales consanguíneas [@crusio1990].

Este hallazgo sugiere que los efectos observados en las quimeras pueden no representar simplemente una mezcla de los fenotipos de sus cepas parentales, sino que pueden manifestar características completamente nuevas y únicas. Esta variabilidad fenotípica intensifica los desafíos al intentar aislar los efectos de un genotipo particular en estudios que involucran modelos quiméricos o genéticamente heterogéneos. 

Por lo tanto, en el contexto de mi experimento, la utilización de una cepa cruzada de C57BL/6J y BALB/cJ podría haber contribuido significativamente a los resultados inesperados, debido a la presencia de características fenotípicas no anticipadas que no son típicas de ninguna de las cepas parentales. Esto ilustra la importancia de una selección cuidadosa de la cepa y del entendimiento profundo del fondo genético en estudios de comportamiento y neurología, especialmente cuando se emplean modelos híbridos o quiméricos cuyas respuestas pueden ser impredecibles y altamente variables.

Por otro lado, para los experimentos de Fluoxetina, todos los animales utilizados provenían de linajes cercanos, por lo que esperamos que las conductas observadas no diferan mucho y sean comparables. Sin embargo, este no fue el caso para los casos de Ketamina+CUMS y Salina+CUMS(grupo ketamina), donde las conductas no fueron consistentes en ratones de linajes no cercanos.

### Inferencia Causal

La discusión anterior va ligada al problema de encontrar una inferencia causal en nuestros datos como consecuencia de asociaciones espurias. 

Aumentar el número de grupos experimentales en un intento de controlar o explorar estas variaciones puede no ser la estrategia más eficaz. Primero, incrementar el número de grupos diluye la potencia estadística de los análisis, pues divide la muestra total en múltiples subgrupos, reduciendo la capacidad de detectar diferencias significativas donde realmente existen. Segundo, la introducción de múltiples grupos control o experimentales adicionales puede llevar a la generación de resultados que, aunque estadísticamente significativos, son difíciles de interpretar debido a la amplificación de efectos menores o irrelevantes biológicamente, resultado de la propia heterogeneidad del modelo.

Además, el uso de numerosos grupos controla con la intención de establecer comparaciones adicionales puede, paradójicamente, introducir más variables confusas. Esto es particularmente relevante en estudios que involucran genotipos con respuestas potencialmente impredecibles, como es el caso con modelos quiméricos o híbridos. En tales situaciones, cada grupo adicional no solo consume más recursos y tiempo, sino que también complica la interpretación global de los datos, pudiendo llevar a conclusiones erróneas o a la identificación de diferencias que son artefactos del diseño experimental más que de influencias experimentales genuinas.

En el diseño de estudios experimentales que intentan esclarecer relaciones causales entre la exposición y los resultados, es fundamental manejar adecuadamente la confusión, que surge cuando tanto la exposición como el resultado están fuertemente asociados con una tercera variable, un término conocido como 'ensalada causal' [@rubin2005]. En este enfoque, se agregan indiscriminadamente variables de control a un modelo estadístico, observando cambios en las estimaciones y luego narrando una historia sobre la causalidad. Este método, aunque frecuentemente empleado en biología y ciencias sociales, no solo es propenso a interpretaciones erróneas, sino que también puede complicar la identificación de verdaderas relaciones causales.

En mi experimento, el uso de una cepa híbrida de ratones introduce una variabilidad genética significativa, lo cual podría relacionarse con múltiples variables confusoras potenciales. Añadir más grupos experimentales en un intento de controlar estas variables confusoras podría, paradójicamente, llevar a un mayor riesgo de caer en la trampa de la 'ensalada causal'. Esto sucede porque cada grupo adicional podría introducir su propia dinámica y asociaciones con variables terceras no identificadas, lo que podría confundir aún más cualquier análisis causal.

Por tanto, mantener un número limitado de grupos experimentales permite un control más riguroso de las variables y una interpretación más clara y directa de los datos. Este enfoque restringido ayuda a evitar la complejidad añadida y las interpretaciones erróneas que pueden surgir al tratar de ajustar y controlar múltiples grupos con variabilidad genética heterogénea. Además, un diseño más simplificado facilita la comparación directa entre grupos seleccionados específicamente para explorar las relaciones de interés, minimizando así la influencia de confusores potenciales y aumentando la validez de las conclusiones causales del estudio.


### Campo abierto

```{r dfCampoabierto}
#| echo: false

campo_abierto_kg1 <- read.csv("./datos_otras_pruebas/campo_abierto/campo_abierto_ketamina_g1.csv") |> 
  janitor::clean_names() |> 
  dplyr::select(animal, treatment, stage, distance, periferia_time, medio_time, centro_time, centro_number_line_crossings) |> 
  dplyr::rename(id = animal, time = stage) 


campo_abierto_fg1 <- read.csv("./datos_otras_pruebas/campo_abierto/resultados_fluoxetina_abierto.csv") |> 
  janitor::clean_names() |> 
  dplyr::select(animal, tratamiento, tiempo, distance, periferia_time, medio_time, centro_time, centro_number_line_crossings) |> 
  dplyr::mutate(time = case_when(tiempo == "pre-cums" ~ "1_pre_CUMS", 
                                 tiempo == "postcums" ~ "2_post_CUMS" )) |>
  dplyr::select(-tiempo) |> 
  dplyr::rename(id = animal, treatment = tratamiento)


campo_abierto_df <- rbind(campo_abierto_fg1, campo_abierto_kg1)


campo_abierto_df$treatment = factor(campo_abierto_df$treatment, 
                                levels=c("Flx-CUMS", "Sal-CUMS-Flx", "Ket-CUMS", "Sal-CUMS-K"))

```


```{r perfieria}
#| echo: false
#| label: fig-perfieria
#| fig-cap: "Periferia."

campo_abierto_df |>  
  ggpubr::ggdotplot(
    x = "time",
    y = "periferia_time", 
    color = "treatment",
    # fill = "treatment",
    size = 0.6,
    palette = c("#222831", "#00ADB5", "#FF2E63", "#FF9800", "#8675A9", "#862B0D"),
    xlab = "Tiempo",
    ylab = "Segundos",
    add = c("mean_se"),
    facet.by = "treatment"
  ) +  stat_compare_means(method = "t.test", paired = TRUE) + ggthemes::theme_clean()
```


```{r medio}
#| echo: false
#| label: fig-medio
#| fig-cap: "Medio"

campo_abierto_df |>  
  ggpubr::ggdotplot(
    x = "time",
    y = "medio_time", 
    color = "treatment",
    # fill = "treatment",
    size = 0.6,
    palette = c("#222831", "#00ADB5", "#FF2E63", "#FF9800", "#8675A9", "#862B0D"),
    xlab = "Tiempo",
    ylab = "Segundos",
    add = c("mean_se"),
    facet.by = "treatment"
  ) +  stat_compare_means(method = "t.test", paired = TRUE) + ggthemes::theme_clean() 
```


```{r centro}
#| echo: false
#| label: fig-centro
#| fig-cap: "Centro"

campo_abierto_df |>  
  ggpubr::ggdotplot(
    x = "time",
    y = "centro_time", 
    color = "treatment",
    # fill = "treatment",
    size = 0.6,
    palette = c("#222831", "#00ADB5", "#FF2E63", "#FF9800", "#8675A9", "#862B0D"),
    xlab = "Tiempo",
    ylab = "Segundos",
    add = c("mean_se"),
    facet.by = "treatment"
  ) +  stat_compare_means(method = "t.test", paired = TRUE) + ggthemes::theme_clean()  
```


```{r cruces}
#| echo: false
#| label: fig-cruces
#| fig-cap: "cruces"

campo_abierto_df |>  
  ggpubr::ggdotplot(
    x = "time",
    y = "centro_number_line_crossings", 
    color = "treatment",
    # fill = "treatment",
    size = 0.6,
    palette = c("#222831", "#00ADB5", "#FF2E63", "#FF9800", "#8675A9", "#862B0D"),
    xlab = "Tiempo",
    ylab = "Cruces",
    add = c("mean_se"),
    facet.by = "treatment"
  ) +  stat_compare_means(method = "t.test", paired = TRUE) + ggthemes::theme_clean()  

```





### Nado Forzado

```{r dfNadoFor}
#| echo: false

nado_forzado_kg1 <- read.csv("./datos_otras_pruebas/nado_forzado/nado_forzado_ketamina_g1.csv") |> 
  janitor::clean_names() |> 
  dplyr::select(animal, treatment, stage, time_immobile_s) |> 
  dplyr::rename(id = animal)

nado_forzado_segmentos_kg1 <- read.csv("./datos_otras_pruebas/nado_forzado/nado_forzado_ketamina_g1_segmentos.csv") |> 
  janitor::clean_names() |> 
  dplyr::select(-test, -code,-trial, -apparatus) |> 
  dplyr::rename(id = animal, 
                inmovil_0_60 = x0_60_time_immobile_s, 
                inmovil_60_120 = x60_120_time_immobile_s, 
                inmovil_120_180 = x120_180_time_immobile_s, 
                inmovil_180_240 = x180_240_time_immobile_s, 
                inmovil_240_300 = x240_300_time_immobile_s,
                inmovil_300_360 = x300_360_time_immobile_s)

nado_forzado_fg1 <- read.csv("./datos_otras_pruebas/nado_forzado/nado_forzado_fluoxetina_g1.csv") |> 
  janitor::clean_names() |> 
  dplyr::select(animal, treatment, stage, time_immobile_s) |> 
  dplyr::rename(id = animal)

nado_forzado_segmentos_fg1 <- read.csv("./datos_otras_pruebas/nado_forzado/nado_forzado_fluoxetina_g1_segmentos.csv") |> 
  janitor::clean_names() |> 
  dplyr::select(-test, -code,-trial, -apparatus) |> 
  dplyr::rename(id = animal, 
                inmovil_0_60 = x0_60_time_immobile_s, 
                inmovil_60_120 = x60_120_time_immobile_s, 
                inmovil_120_180 = x120_180_time_immobile_s, 
                inmovil_180_240 = x180_240_time_immobile_s, 
                inmovil_240_300 = x240_300_time_immobile_s,
                inmovil_300_360 = x300_360_time_immobile_s)


###
###

nado_forzado_df <- 
  rbind(nado_forzado_kg1, nado_forzado_fg1)

nado_forzado_df <- nado_forzado_df |> 
  dplyr::mutate(prueba = case_when(
    stage == "1_pre_CUMS" ~ "1_Pre_CUMS",
    stage == "1_pre_CUMS " ~ "1_Pre_CUMS",
    stage == "2_post_CUMS" ~ "2_post_CUMS",
  ))

# table(nado_forzado_df$prueba)

nado_forzado_df$treatment = factor(nado_forzado_df$treatment, 
                                levels=c("Flx-CUMS", "Sal-CUMS-F", "Ket-CUMS", "Sal-CUMS-K"))



nado_frozado_segmentos_df <- 
  rbind(nado_forzado_segmentos_kg1, nado_forzado_segmentos_fg1)


nado_frozado_segmentos_df <- nado_frozado_segmentos_df |> 
  dplyr::mutate(prueba = case_when(
    stage == "1_pre_CUMS" ~ "1_Pre_CUMS",
    stage == "1_pre_CUMS " ~ "1_Pre_CUMS",
    stage == "2_post_CUMS" ~ "2_post_CUMS",
  ))

# table(nado_forzado_df$prueba)

nado_frozado_segmentos_df$treatment = factor(nado_frozado_segmentos_df$treatment, 
                                   levels=c("Flx-CUMS", "Sal-CUMS-F", "Ket-CUMS", "Sal-CUMS-K"))
```

```{r inmovtot}
#| echo: false
#| label: fig-inmovtot
#| fig-cap: "Inmovilidad Total"

nado_forzado_df |>  
  ggpubr::ggbarplot(
    x = "prueba",
    y = "time_immobile_s", 
    color = "treatment",
    fill = "treatment",
    size = 0.6,
    palette = c("#222831", "#00ADB5", "#FF2E63", "#FF9800", "#8675A9", "#862B0D"),
    xlab = "Tiempo",
    ylab = "Segundos",
    add = c("mean_se"),
    facet.by = "treatment"
  ) +  
  stat_compare_means(method = "t.test", paired = TRUE, label.y = 180) + 
  # ggplot2::theme_classic() +
  ggthemes::theme_clean() +
  theme(legend.position = "none", axis.text = element_text(size = 12),axis.title = element_text(size = 15))
```


```{r inmovSegment}
#| echo: false
#| label: fig-inmovSegment
#| fig-cap: "Inmovilidad Segmentada"

nado_frozado_segmentos_df |>
  pivot_longer(
    cols = starts_with("inmovil"),
    names_to = "inmovilidad",
    names_prefix = "inmovil_",
    values_to = "tiempo_inmovilidad",
    values_drop_na = TRUE
  ) |> 
  ggpubr::ggline(
    x = "inmovilidad",
    y = "tiempo_inmovilidad", 
    color = "treatment",
    fill = "treatment",
    palette = c("#222831", "#00ADB5", "#FF2E63", "#FF9800", "#8675A9", "#862B0D"),
    linetype = "treatment",
    shape = "treatment",
    facet.by = "prueba",
    add = "mean_se",
    numeric.x.axis = TRUE,
    xlab = "Segmento de la prueba por minuto",
    ylab = "Segundos de Inmovilidiad"
    # ggtheme = theme_pubr()
    # error.plot = "errorbar"
  ) +  
  stat_compare_means(method = "anova", 
                     aes(group = treatment),
                     label.y = 50,
                     hide.ns = T,
                     label = "p.signif") + 
  ggplot2::theme_classic() +
  theme(legend.position = "top", axis.text = element_text(size = 12),axis.title = element_text(size = 15), axis.text.x=element_blank())
```


# Conclusión

En conclusión, el estrés crónico produce una déficit de flexibilidad cognitiva en las pruebas del MWM, evidenciado por la mayor distancia al annulus reversa y el menor tiempo en los cuadrantes y zona del annulus reversa. El tratamiento con fluoxetina previene esta falta de flexibilidad en comparación con el grupo de salina. A pesar de que tenemos evidencia conductual que esto podría estar relacionado con la neurogénesis hipocampal, falta confirmación por parte de la inmunohistoquímica. Por último, se utilizaron métricas en el MWM que destacan la importancia del aprendizaje espacial en el MWM, las cuales no son comunmente utilizadas. De la misma manera, falta confirmación inmunohistoquímica para hacer conclusiones más robustas sobre las bases de estos fenómenos.

# ANEXO 


```{r tablaregresionlatenciaspre}
#| echo: false
#| eval: false
#| label: tbl-tablalatenciasregresiones
#| tbl-cap: "Modelos de regresión para Latencias Originales. R2 "

sjPlot::tab_model(b1.c.pre, b1.ignore.pre, bn.pre,
                  collapse.ci = TRUE,
                  show.obs = T,
                  show.re.var = F,
                  show.icc = F,
                  p.style = "numeric_stars",
                  string.pred = "Predictores",
                  # title = "Entrenamientos Originales",
                  string.est = "Estimados",
                  pred.labels = c("Intercepto",
                                  "Tiempo",
                                  "Flx-CUM", "Sal-CUM-F", 
                                  "Tiempo:Flx-CUM", "Tiempo:Sal-CUM-F"),
                  dv.labels = c("Bayes-Censurado", "GLM", "Efectos Mixtos lineal")
                  # file = "./tablas/bayes_latencias_post.html"
                  # string.se = "SEM"
)

```

```{r tablaregresionlatenciaspost}
#| echo: false
#| label: tbl-tablalatenciasregresionespost
#| tbl-cap: "Modelos de regresión para Latencias Entrenamientos Reversa."


sjPlot::tab_model(b1.c,b1.ignore, bn,
                  collapse.ci = TRUE,
                  show.obs = T,
                  show.re.var = F,
                  bpe = "mean",
                  show.reflvl = T,
                  # show.aic = T,
                  # show.dev = T,
                  # show.loglik = T,
                  # show.icc = F,
                  p.style = "numeric_stars",
                  string.pred = "Predictores",
                  # title = "Entrenamientos Reversa",
                  string.est = "Estimados",
                  # pred.labels = c("Intercepto",
                  #                 "Tiempo",
                  #                 "Flx-CUM", "Sal-CUM-F", 
                  #                 "Tiempo:Flx-CUM", "Tiempo:Sal-CUM-F"),
                  dv.labels = c("Bayes-Censurado", "GLM", "Efectos Mixtos lineal")
                  # file = "./tablas/bayes_latencias_post.html"
                  # string.se = "SEM"
)

```



```{r plotslatencias}
#| echo: false
#| eval: false
#| label: fig-latenciasplots
#| fig-cap: "Medias marginales estimadas para latencias. Graficado con Media + error estándar."
#| fig-subcap: 
#|   - "Latencias Entrenamientos Originales"
#|   - "Latencias Entrenamientos Reversa"
#| layout-ncol: 2


latencias_pre_emmeans_aov <- emmeans(aov_latencias_pre, ~ prueba | tratamientos, cov.reduce = F)
latencias_pre_emmeans_aov.df <- as.data.frame(latencias_pre_emmeans_aov)

latencias_post_emmeans_aov <- emmeans(aov_latencias_post, ~ prueba | tratamientos, cov.reduce = F)
latencias_post_emmeans_aov.df <- as.data.frame(latencias_post_emmeans_aov)


aov_plot.pre <- ggplot(latencias_pre_emmeans_aov.df,
                   aes(
                     x = prueba,
                     y = emmean,
                     group = tratamientos,
                     color = tratamientos
                   )) +
  geom_line(linewidth = 0.3, linetype = "dashed", position = position_dodge(0.1)) +
  geom_point(size = 4, position = position_dodge(0.1), aes(shape = tratamientos)) +
  # geom_point(size = 7, shape = 21, position = position_dodge(0.1)) +
  geom_pointrange(aes(ymin = emmean-SE, ymax = emmean+SE),
                  size = 0.75, position = position_dodge(0.1)) +
  scale_color_manual(values = c("#222831", "#00ADB5", "#FF2E63", "#FF9800", "#8675A9", "#F2AFEF")) +
  labs(
    # caption = "Plotted with SEM",
    color = "Tratamientos",
    shape = "Tratamientos",
    x = "Entrenamiento",
    y = "Segundos") +
  ylim(0, 60) +
  scale_x_discrete(labels=c("Entr_1"="1", "Entr_2"="2", "Entr_3"="3","Entr_4"="4")) +
  # theme_classic()
  # ggthemes::theme_clean() +
  ggthemes::theme_clean() + 
  theme(legend.position='top', axis.text = element_text(size = 12),axis.title = element_text(size = 15)) 


aov_plot.pret_comps <-  aov_plot.pre + annotate(
  "text", label = "***", x = "Entr_1", y = 60, size = 6.7, colour =  "#00ADB5"
) +
  annotate(
    "text", label = "**", x = "Entr_1", y = 58, size = 6.7, colour =  "#FF2E63"
  )

aov_plot.pret_comps
# ggsave("./figuras/aov_plot.pre.png", plot = aov_plot.pre)

aov_plot.post <- ggplot(latencias_post_emmeans_aov.df,
                   aes(
                     x = prueba,
                     y = emmean,
                     group = tratamientos,
                     color = tratamientos
                   )) +
  geom_line(linewidth = 0.3, linetype = "dashed", position = position_dodge(0.1)) +
  geom_point(size = 4, position = position_dodge(0.1), aes(shape = tratamientos)) +
  # geom_point(size = 7, shape = 21, position = position_dodge(0.1)) +
  geom_pointrange(aes(ymin = emmean-SE, ymax = emmean+SE),
                  size = 0.75, position = position_dodge(0.1)) +
  scale_color_manual(values = c("#222831", "#00ADB5", "#FF2E63", "#FF9800", "#8675A9", "#F2AFEF")) +
  labs(
    # caption = "Plotted with SEM",
    color = "Tratamientos",
    shape = "Tratamientos",
    x = "Entrenamiento",
    y = "Segundos") +
  ylim(0, 60) +
  # scale_x_discrete(labels=c("entrenamiento_rev_1"="1", "entrenamiento_rev_2"="2")) +
  # theme_classic()
  # ggthemes::theme_clean() +
  ggthemes::theme_clean() + 
  theme(legend.position='top', axis.text = element_text(size = 12),axis.title = element_text(size = 15)) 

aov_plot.post_comps <-  aov_plot.post + annotate(
  "text", label = "**", x = "Reversa_1", y = 50, size = 6.7, colour =  "#222831"
) +
  annotate(
    "text", label = "**", x = "Reversa_1", y = 53, size = 6.7, colour =  "#00ADB5"
  )

aov_plot.post_comps

# ggsave("./figuras/aov_plot_post.png", plot = aov_plot.post)

```

```{r tablasanovaslatencias}
#| echo: false
#| eval: false
#| label: tbl-tablasanovalatenciasflx
#| tbl-cap: "Tabla de ANOVA para Latencias."
#| tbl-subcap: 
#|   - "Latencias Entrenamientos Originales"
#|   - "Latencias Entrenamientos Reversa"
#| layout-ncol: 2

anovalatpre <- anova_summary(aov_latencias_pre$Within) |> 
  tibble::as.tibble() |> 
  dplyr::rename(Efecto = Effect) |> 
  gt::gt()  |> 
  fmt_number(decimals = 3) |>
  fmt_integer(columns = c(DFn, DFd)) |>
  opt_stylize()


anovalatpre

# knitr::kable(anovalatpre, digits = 3, format.args = list(scientific = FALSE)) |> 
  # kable_classic_2("hover", full_width = F)
  # as_tibble() |> 
  # dplyr::()
  # kbl() |> 
  # kable_minimal("hover", full_width = F, font_size = 8)
  # rename(Efecto = Effect) |> 
  # flextable() |> 
  # theme_apa()

# kableExtra::kbl(anova_summary(aov_latencias_pre$Within)) |> 
#   kable_minimal("hover", full_width = F, font_size = 8)

anovalatpost <- anova_summary(aov_latencias_post) |> 
  tibble::as.tibble() |> 
  dplyr::rename(Efecto = Effect) |> 
  gt::gt()  |> 
  fmt_number(decimals = 3) |>
  fmt_integer(columns = c(DFn, DFd)) |>
  opt_stylize()

anovalatpost


```

```{r contrastesanovaslatencias}
#| echo: false
#| eval: false
#| label: tbl-tablasanovalatenciasflx2
#| tbl-cap: "Contrastes significativos en Latencias de escape."
#| tbl-subcap: 
#|   - "Latencias Entrenamientos Originales"
#|   - "Latencias Entrenamientos Reversa"
#| layout-ncol: 2

aov_em_pre <- emmeans(latencias_pre_emmeans_aov, pairwise ~ tratamientos | prueba, adjust = "tukey")$contrasts |> 
  dplyr::as_tibble() |>  
  dplyr::select(-df, -t.ratio) |>
  dplyr::rename(Estimado = estimate) |> 
  dplyr::filter(p.value <= 0.05) |>
  tidyr::separate(contrast, into = c("1", "2"), sep = " - ") 

aov_em_pre |>   gt::gt()  |> 
  tab_footnote("Comparaciones múltiples ajustadas con Tukey HSD") |> 
  fmt_number(decimals = 3) |>
  tab_style_body(
    style = list(
                 cell_text(color = "#222831")),
    values = c("Flx")
  ) |> 
  tab_style_body(
    style = list(
                 cell_text(color = "#00ADB5")),
    values = c("(Flx-CUMS)")) |>
  tab_style_body(
    style = list(
                 cell_text(color = "#FF2E63")),
    values = c(("(Sal-CUMS-F)"))
    ) |> 
  opt_stylize(style = 1) 
  
aov_em_post <- emmeans(latencias_post_emmeans_aov, pairwise ~ tratamientos | prueba, adjust = "tukey")$contrasts |>
  dplyr::as_tibble() |>  
  dplyr::select(-df, -t.ratio) |>
  dplyr::rename(Estimado = estimate) |> 
  dplyr::filter(p.value <= 0.05) |>
  tidyr::separate(contrast, into = c("1", "2"), sep = " - ") |> 
  gt::gt()  |> 
  tab_footnote("Comparaciones múltiples ajustadas con Tukey HSD") |> 
  fmt_number(decimals = 3) |>
  tab_style_body(
    style = list(
                 cell_text(color = "#222831")),
    values = c("Flx")
  ) |> 
  tab_style_body(
    style = list(
                 cell_text(color = "#00ADB5")),
    values = c("(Flx-CUMS)")) |>
  tab_style_body(
    style = list(
                 cell_text(color = "#FF2E63")),
    values = c(("(Sal-CUMS-F)"))
    ) |> 
  opt_stylize(style = 1) 

aov_em_post

```


```{r DistMediaEntsSupuestoslmer}
#| echo: false
#| label: fig-DistMediaEntsSupuestoslmer
#| fig-cap: Supuestos modelos Lineal Con Efectos Mixtos para modelar distancia media. Todos los ssupuestos se cumplen. 

check_model(lmer.dist.media.entr.flx,
            check = c("vif", "qq", "normality", "linearity", "homogeneity"),
            show_dots = T
            # ggplot2::theme_classic()c
            # ggthemes::theme_clean() +
            # ggthemes::theme_clean
            )


```

```{r DistMediaEntsSupuestosaov}
#| echo: false
#| eval: false
#| code-summary: Ver código
#| label: fig-DistMediaEntsSupuestosaov
#| fig-cap: Supuestos modelos RM-ANOVA Distancia Media Entrenamientos. 
#| out-width: "50%"



plot(check_heteroscedasticity(aov.dist.media.entr.flx$id))

# ggqqplot(df.mean.dist.media.ent, "distancia_annulus_so ", facet.by = "tratamientos")
# 
# ggqqplot(df.mean.dist.media.ent, "distancia_annulus_so", ggtheme = theme_bw()) +
#   facet_grid(prueba ~ tratamientos)



```


```{r DistMediaEntsSupuestoslmerPruebas}
#| echo: false
#| eval: false
#| label: fig-DistMediaEntsSupuestoslmerPruebas
#| fig-cap: Supuestos modelos Lineal Con Efectos Mixtos Distancia Media Pruebas.

performance::check_model(lmer.dist.media.pruebas,
                         check = c("normality", "qq", "linearity", "homogeneity"))


# performance::check_model(aov.dist.media.entr.flx$Within)

# plot(check_heteroscedasticity(aov.dist.media.entr.flx$Within))

```

```{r entropiLMERSupuestos}
#| echo: false
#| eval: false
#| label: fig-entropiLMERSupuestos
#| fig-cap: Supuestos modelos Lineal Con Efectos Mixtos Entropia.

performance::check_model(entropia.lmer.flx,
                         check = c("normality", "qq", "linearity", "homogeneity"))


```

```{r entropiAOVSupuestos}
#| echo: false
#| eval: false
#| label: fig-entropiAOVSupuestos
#| fig-cap: Supuestos modelos Lineal Con Efectos Mixtos Entropia.
#| out-width: "50%" 


plot(check_heteroscedasticity(aov.entropia$`id:prueba`))
```

```{r cuadrantesLMERSupuestos}
#| echo: false
#| label: fig-cuadrantesLMERSupuestos
#| fig-cap: Supuestos modelos Lineal Con Efectos Mixtos Cuadrantes."

performance::check_model(lmer.cuadrantes,
                         check = c("normality", "qq", "linearity", "homogeneity"))


```

```{r zonasLMERSupuestos}
#| echo: false
#| label: fig-zonasLMERSupuestos
#| fig-cap: Supuestos modelos Lineal Con Efectos Mixtos Zonas."

performance::check_model(lmer.zonas,
                         check = c("normality", "qq", "linearity", "homogeneity"))
```


```{r aovDistMedENTSaovPlots}
#| echo: false
#| eval: false
#| label: fig-aovDistMedENTSaovPlots
#| fig-cap: "Medias Estimadas AOV PRE. Graficado con Media + error estándar."
#| fig-subcap: 
#|   - "Pre"
#|   - "Post"
#| layout-ncol: 2

aov.dist.media.entr.flx.emmeans.pre <- emmeans(aov.dist.media.entr.flx.pre, ~ prueba | tratamientos)

aov.dist.media.entr.flx.emmeans.pre.df <- as.data.frame(aov.dist.media.entr.flx.emmeans.pre)

ggplot(aov.dist.media.entr.flx.emmeans.pre.df,
                    aes(
                      x = prueba,
                      y = emmean,
                      group = tratamientos,
                      color = tratamientos
                    )) +
  geom_line(linewidth = 0.3, linetype = "dashed", position = position_dodge(0.1)) +
  geom_point(size = 4, position = position_dodge(0.1), aes(shape = tratamientos)) +
  # geom_point(size = 7, shape = 21, position = position_dodge(0.1)) +
  geom_pointrange(aes(ymin = emmean-SE, ymax = emmean+SE),
                  size = 0.75, position = position_dodge(0.1)) +
  scale_color_manual(values = c("#222831", "#00ADB5", "#FF2E63", "#FF9800", "#8675A9", "#862B0D")) +
  labs(
    # caption = "Plotted with SEM",
    color = "Tratamientos",
    shape = "Tratamientos",
    x = "Prueba",
    y = "Segundos") +
  ylim(0, 0.5) +
  # scale_x_discrete(labels=c("entrenamiento_rev_1"="1", "entrenamiento_rev_2"="2")) +
  # theme_classic()
  # ggthemes::theme_clean() +
  ggthemes::theme_clean() + 
  theme(legend.position='top', axis.text = element_text(size = 12),axis.title = element_text(size = 15)) 


aov.dist.media.entr.flx.emmeans <- emmeans(aov.dist.media.entr.flx, ~ prueba | tratamientos)

aov.dist.media.entr.flx.emmeans.df <- as.data.frame(aov.dist.media.entr.flx.emmeans)

ggplot(aov.dist.media.entr.flx.emmeans.df,
                    aes(
                      x = prueba,
                      y = emmean,
                      group = tratamientos,
                      color = tratamientos
                    )) +
  geom_line(linewidth = 0.3, linetype = "dashed", position = position_dodge(0.1)) +
  geom_point(size = 4, position = position_dodge(0.1), aes(shape = tratamientos)) +
  # geom_point(size = 7, shape = 21, position = position_dodge(0.1)) +
  geom_pointrange(aes(ymin = emmean-SE, ymax = emmean+SE),
                  size = 0.75, position = position_dodge(0.1)) +
  scale_color_manual(values = c("#222831", "#00ADB5", "#FF2E63", "#FF9800", "#8675A9", "#862B0D")) +
  labs(
    caption = "Plotted with SEM",
    color = "Tratamientos",
    shape = "Tratamientos",
    x = "Prueba",
    y = "Segundos") +
  ylim(0, 0.5) +
  # scale_x_discrete(labels=c("entrenamiento_rev_1"="1", "entrenamiento_rev_2"="2")) +
  # theme_classic()
  # ggthemes::theme_clean() +
  ggthemes::theme_clean() + 
  theme(legend.position='top', axis.text = element_text(size = 12),axis.title = element_text(size = 15)) 

```

```{r contrastesanovasdistmediaENTS}
#| echo: false
#| eval: false
#| label: tbl-contrastesanovasdistmediaENTS
#| tbl-cap: "Contrastes en Distancias Medias."
 
aov_em_post_ent_dmedia <- emmeans(aov.dist.media.entr.flx, pairwise ~  tratamientos| prueba, adjust = "tukey")$contrasts |> 
  dplyr::as_tibble() |>  
  dplyr::select(-df, -t.ratio) |>
  dplyr::rename(Estimado = estimate) |> 
  dplyr::filter(p.value <= 0.06) |>
  tidyr::separate(contrast, into = c("1", "2"), sep = " - ") 

aov_em_post_ent_dmedia |>   gt::gt()  |> 
  # tab_footnote("Comparaciones múltiples ajustadas con Tukey HSD") |> 
  fmt_number(decimals = 3) |>
  tab_style_body(
    style = list(
                 cell_text(color = "#222831")),
    values = c("Flx")
  ) |> 
  tab_style_body(
    style = list(
                 cell_text(color = "#00ADB5")),
    values = c("(Flx-CUMS)")) |>
  tab_style_body(
    style = list(
                 cell_text(color = "#FF2E63")),
    values = c(("(Sal-CUMS-F)"))
    ) |> 
  opt_stylize(style = 1) 


```


Mapas de calor para otros grupos

```{r KetaminaCumsMapa}
#| echo: false
#| label: fig-KetaminaCumsMapa
#| fig-cap: "Mapas de Calor Ketamina-CUMS"
#| fig-subcap: 
#|   - "Prueba-1"
#|   - "Prueba-2"
#|   - "Prueba-Reversa"
#| layout-ncol: 3

Rtrack::plot_density(
  ket_cums_p1_metrics,
  title = "Ket-CUMS P1",
  col = viridis(300), # 738
  resolution = 900,
  feature.col = "#E87FB0",
  feature.lwd = 4,
  legend = F
)


Rtrack::plot_density(
  ket_cums_p2_metrics,
  title = "Ket-CUMS P-2",
  col = viridis(300), # 738
  resolution = 900,
  feature.col = "#E87FB0",
  feature.lwd = 4,
  legend = F
)


Rtrack::plot_density(
  ket_cums_rev_metrics,
  title = "Ket-CUMS Reversa",
  col = viridis(300), # 738
  resolution = 900,
  feature.col = "#E87FB0",
  feature.lwd = 4,
  legend = F
)



```

```{r SalinaCumsKMapa}
#| echo: false
#| label: fig-SalinaCumsKMapa
#| fig-cap: "Mapas de Calor Salina-CUMS-Ket"
#| fig-subcap: 
#|   - "Prueba-1"
#|   - "Prueba-2"
#|   - "Prueba-Reversa"
#| layout-ncol: 3
Rtrack::plot_density(
  sal_cums_k_p1_metrics,
  title = "Sal-CUMS-Ket P1",
  col = viridis(300), # 738
  resolution = 900,
  feature.col = "#E87FB0",
  feature.lwd = 4,
  legend = F
)


Rtrack::plot_density(
  sal_cums_k_p2_metrics,
  title = "Sal-CUMS-Ket P-2",
  col = viridis(300), # 738
  resolution = 900,
  feature.col = "#E87FB0",
  feature.lwd = 4,
  legend = F
)

Rtrack::plot_density(
  sal_cums_k_rev_metrics,
  title = "Sal-CUMS-K reversal",
  col = viridis(300), # 738
  resolution = 900,
  feature.col = "#E87FB0",
  feature.lwd = 4,
  legend = F
)

```